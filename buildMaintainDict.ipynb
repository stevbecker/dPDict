{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#intag#code#python\n",
      "#intag#aa#dp#dict\n",
      "#\n",
      "#2014-10-23\n",
      "#\n",
      "# buildMaintainDict.py\n",
      "\n",
      "\n",
      "\n",
      "import pymongo\n",
      "from pymongo import MongoClient\n",
      "import re\n",
      "import shutil\n",
      "import os.path\n",
      "import json\n",
      "from bson.json_util import dumps\n",
      "from sets import Set\n",
      "import collections\n",
      "\n",
      "from os.path import isdir, isfile, join\n",
      "from os import listdir\n",
      "\n",
      "import urllib\n",
      "import urllib2\n",
      "import xml.etree.ElementTree as ET\n",
      "from xml.etree.ElementTree import ParseError\n",
      "import time\n",
      "\n",
      "# codecs if for read and write files with unicode, encoding 'utf-8'\n",
      "import codecs\n",
      "\n",
      "\n",
      "rootpath = 'E:\\\\_BreatheWords\\\\'\n",
      "aggrePath = rootpath + '_aggregation\\\\'\n",
      "\n",
      "dictrootpath = 'E:\\\\_gwDict\\\\'\n",
      "recsrcpath = dictrootpath + 'recLib\\\\'\n",
      "dictpath = dictrootpath + 'MWLearnerMain\\\\'\n",
      "updatepath = dictrootpath + 'MWLearnerUpdate\\\\'\n",
      "addpath = dictrootpath + 'Added\\\\'\n",
      "#dictpath = dictrootpath + 'MWLearnerFrench\\\\'\n",
      "\n",
      "\n",
      "\n",
      "def connectDB(whichCollection):\n",
      "    #connect to MongoDB\n",
      "    client = MongoClient('localhost', 27017)\n",
      "    db = client.dpdb\n",
      "    if whichCollection == 'dpdict':\n",
      "        print '---Connect to collection: ', whichCollection\n",
      "        collectionName = db.dpdict\n",
      "    elif whichCollection == 'geweiDict':\n",
      "        print '---Connect to collection: ', whichCollection\n",
      "        collectionName = db.geweiDict\n",
      "    else:\n",
      "        print '---wrong collection!'\n",
      "    \n",
      "    return collectionName\n",
      "\n",
      "\n",
      "\n",
      "#------------------ functions: build sub dictionary ---------------------#\n",
      "### Functions:\n",
      "#\n",
      "# createDir(filePath)\n",
      "#\n",
      "# tidyWordList(filePath, wordListFile, excluListFile='excluWordsA.txt')\n",
      "# copyRec(filePath, wordListFile)\n",
      "#\n",
      "# buildWordListFromText(filePath, txtFile, excluListFile='excluWordsA.txt')    #use function tidyWordList\n",
      "# buildSubDict(filePath, wordListFile)  # use function copyRec\n",
      "#\n",
      "# Usage: first create a target directory, put the word list file or text file in it\n",
      "# e.g. the target directory is 'E:\\\\psalm\\\\', the text file is 'Psalms.txt'\n",
      "#    buildWordListFromText('E:\\\\psalm', 'Psalms')\n",
      "# then \n",
      "#    buildSubDict('E:\\\\psalm', 'Psalms_wordList_tidyExclu')\n",
      "#\n",
      "#\n",
      "##################################################\n",
      "#\n",
      "# buildDict_cp() #get list of common phrases\n",
      "# buildDictByLabel(label)\n",
      "#\n",
      "# they will create files in directory defined by global variable 'aggrePath'\n",
      "#\n",
      "\n",
      "\n",
      "\n",
      "def createDir(filePath):\n",
      "    #targetPath = rootpath + fileName.split('.')[0]\n",
      "    if not os.path.exists(filePath):\n",
      "        os.makedirs(filePath)    \n",
      "    return filePath\n",
      "\n",
      "\n",
      "def tidyWordList(filePath, wordListFile, excluListFile='_wordCourse\\\\excluWordlist10-500.txt'):\n",
      "    \"\"\" create three sorted files from a word list file in which one line is a word or a phrase:\n",
      "        one is original unique word list; \n",
      "        another includes words after excluded from exclusion word list;\n",
      "        the third one is words that are excluded.\n",
      "        don't include the suffixt '.txt' for 2nd argument wordListFile\n",
      "    \"\"\"\n",
      "    \n",
      "    targetPath = createDir(filePath) + '\\\\'\n",
      "    \n",
      "    excluWords = []\n",
      "    for line in open(excluListFile, 'r'):\n",
      "        excluWords.append(line.strip())   \n",
      "        \n",
      "    words = []\n",
      "    for line in open(targetPath + wordListFile + '.txt', 'r'):\n",
      "        words.append(line.strip())\n",
      "\n",
      "    foutputFreq = open(targetPath + wordListFile + '_tidyFreq.txt', 'w')        \n",
      "    # http://stackoverflow.com/questions/2161752/how-to-count-the-frequency-of-the-elements-in-a-list\n",
      "    # https://docs.python.org/2/library/collections.html#counter-objects\n",
      "    wordcnt = collections.Counter(words).most_common()\n",
      "    for item in wordcnt:\n",
      "        word, freq = item #tuple unpacking\n",
      "        foutputFreq.write(word + '\\t\\t' + str(freq) + '\\n')                     \n",
      "    foutputFreq.close()\n",
      "    \n",
      "        \n",
      "    uniqueWords = Set(words)\n",
      "    wordlist = sorted(uniqueWords, key=str.lower)\n",
      "    #print type(wordlist) #type: list\n",
      "    \n",
      "    foutput = open(targetPath + wordListFile + '_tidy.txt', 'w')\n",
      "    foutputExclu = open(targetPath + wordListFile + '_tidy_afterExcluded.txt' , 'w')\n",
      "    foutputInExclu = open(targetPath + wordListFile + '_tidy_Excluded.txt' , 'w')       \n",
      "    for item in wordlist:\n",
      "        foutput.write(\"%s\\n\" % item)\n",
      "        if item not in excluWords and item.lower() not in excluWords:\n",
      "            foutputExclu.write(\"%s\\n\" % item)\n",
      "        else:\n",
      "            foutputInExclu.write(\"%s\\n\" % item)\n",
      "    foutput.close()    \n",
      "    foutputExclu.close()\n",
      "    foutputInExclu.close()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def buildWordListFromText(filePath, txtFile, excluListFile='_wordCourse\\\\excluWordlist10-500.txt'):\n",
      "    \"\"\" build a word list from a text file.\n",
      "        The word list is not sorted and not unique. The words are all lowercased.\n",
      "        https://docs.python.org/2/howto/regex.html\n",
      "        don't include the suffixt '.txt' for 2nd argument wordListFile        \n",
      "    \"\"\"\n",
      "    targetPath = createDir(filePath)\n",
      "    \n",
      "    re_word = re.compile(r\"[\\w'-]+\")\n",
      "    \n",
      "    words = []\n",
      "    for line in open(targetPath + txtFile + '.txt', 'r'):\n",
      "        #[words.append(item.group()) for item in re_word.finditer(line) if item.group() != '-']\n",
      "        [words.append(item.group().lower()) for item in re_word.finditer(line) if item.group() != '-']\n",
      "    foutput = open(targetPath + txtFile + '_wordList.txt', 'w')\n",
      "    for word in words:\n",
      "        foutput.write(\"%s\\n\" % word)\n",
      "    foutput.close()\n",
      "    \n",
      "    tidyWordList(targetPath, txtFile + '_wordList', excluListFile)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def copyRec(filePath, wordListFile):\n",
      "    \"\"\"Simply copy recordings to filePath for words in wordListFile\n",
      "        don't include the suffixt '.txt' for 2nd argument wordListFile    \n",
      "        On Windows 8, if a word in wordListFile is 'abraham', and the recording file is 'Abraham.wav',\n",
      "        you will get a copy named 'abraham.wav'\n",
      "    \"\"\"\n",
      "    targetPath = createDir(filePath)\n",
      "    fnorec = open(targetPath + wordListFile + '_copyRec_noRec.txt', 'w')\n",
      "            \n",
      "    for line in open(targetPath + wordListFile + '.txt', 'r'):\n",
      "        item = line.strip()\n",
      "        srcwav = recsrcpath + item + '.wav'\n",
      "        srcmp3 = recsrcpath + item + '.mp3'\n",
      "        if os.path.isfile(srcwav):\n",
      "            shutil.copy(srcwav, targetPath)\n",
      "        elif os.path.isfile(srcmp3):\n",
      "            shutil.copy(srcmp3, targetPath)    \n",
      "        else:\n",
      "            fnorec.write(item + '\\n')\n",
      "            print 'in function copyRec, no rec files: ', srcwav, \", \", srcmp3\n",
      "    \n",
      "    fnorec.close()\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "def buildSubDict(filePath, wordListFile, recFlag=0):\n",
      "    \"\"\"For words in wordListFile, build their dictionary from geweiDict;\n",
      "        and copy recordings of them and their parent-entries or children-entries.\n",
      "        don't include the suffixt '.txt' for 2nd argument wordListFile \n",
      "        if recFlag == 0, copy no recording files\n",
      "    \"\"\"\n",
      "    \n",
      "    targetPath = createDir(filePath) + '\\\\'\n",
      "    print '---target path', targetPath\n",
      "    \n",
      "    if recFlag: copyRec(targetPath, wordListFile)\n",
      "    \n",
      "    #fdict = open(targetPath + wordListFile + '_subDict.txt', 'w')    \n",
      "    #fnotindict = open(targetPath + wordListFile + '_notIndict.txt', 'w')\n",
      "    fdict = codecs.open(targetPath + wordListFile + '_subDict.txt', encoding='utf-8', mode='w')    \n",
      "    fnotindict = codecs.open(targetPath + wordListFile + '_notIndict.txt', encoding='utf-8', mode='w')    \n",
      "\n",
      "    #connect to MongoDB\n",
      "    #client = MongoClient('localhost', 27017)\n",
      "    #db = client.dpdb \n",
      "    #gwdict = db.geweiDict    \n",
      "    gwdict = connectDB('geweiDict')\n",
      "    \n",
      "    words = []\n",
      "    fwordlist = codecs.open(targetPath + wordListFile + '.txt', encoding='utf-8')\n",
      "    #for line in open(targetPath + wordListFile + '.txt', 'r'):\n",
      "    for line in fwordlist:\n",
      "        item = line.strip()\n",
      "        \n",
      "        cnt = 1\n",
      "            \n",
      "        #results = dpdict.find({\"$or\": [{\"hw\":item},{\"infl\": item}, {\"idpvs\": item}]})\n",
      "        #case insensitive query\n",
      "        results = gwdict.find({\"$or\": [{\"hw\": re.compile('^' + re.escape(item) + '$', re.IGNORECASE)},\n",
      "                                       {\"infl\": re.compile('^' + re.escape(item) + '$', re.IGNORECASE)},\n",
      "                                       {\"idpvs\": re.compile('^' + re.escape(item) + '$', re.IGNORECASE)}]},\n",
      "                              {\"_id\":0, \"alles\":0, \"cr\":0})\n",
      "        \n",
      "        if results.count() == 0:\n",
      "            print '--not in dict--: ', item\n",
      "            fnotindict.write(item+'\\n')\n",
      "            continue\n",
      "    \n",
      "        for result in results:\n",
      "            print cnt, ': ', item\n",
      "            \n",
      "            word = result.get(\"hw\")\n",
      "            frword = result.get(\"hwfr\")\n",
      "            if frword == None:\n",
      "                #print word, ' --- is not a French word'\n",
      "                #continue #for build French words sub dict\n",
      "                words.append(word)\n",
      "            else:\n",
      "                print word, ' its French word is ... ', frword\n",
      "                words.append(frword)                \n",
      "            \n",
      "    \n",
      "            wsrcwav = recsrcpath + word + '.wav'\n",
      "            wsrcmp3 = recsrcpath + word + '.mp3'\n",
      "            \n",
      "            if word != item and recFlag:\n",
      "                if os.path.isfile(wsrcwav):\n",
      "                    shutil.copy(wsrcwav, targetPath)\n",
      "                elif os.path.isfile(wsrcmp3):\n",
      "                    shutil.copy(wsrcmp3, targetPath)\n",
      "    \n",
      "            \n",
      "            #print type(dpdict.find_one({\"hw\":word}))\n",
      "            #obj = dpdict.find_one({\"hw\":word})\n",
      "            #json.dump(str(obj), fdict, sort_keys=True, indent=4,separators=(',', ': '))\n",
      "            #print json.dumps(obj, sort_keys=True, indent=4,separators=(',', ': '))\n",
      "            #fdict.write(str(dpdict.find_one({\"hw\":word})))\n",
      "            \n",
      "            #print dumps(result, sort_keys=True, indent=4,separators=(',', ': '))\n",
      "            fdict.write(item + ' (' + word + ')\\n')\n",
      "            \n",
      "            #fdict.write(dumps(result, sort_keys=True, indent=4, separators=(',', ': ')))\n",
      "            \n",
      "            # ensure_ascii=False & .encode('utf8') will write to file 'caf\u00e9', not 'caf\\u00e9'\n",
      "            # but if open file with codecs encoding='utf-8', must remove .encode('utf8')\n",
      "            #fdict.write(dumps(result, sort_keys=True, indent=4, separators=(',', ': '), ensure_ascii=False).encode('utf8'))\n",
      "            \n",
      "            # after use codecs encoding='utf-8' open files:\n",
      "            fdict.write(dumps(result, sort_keys=True, indent=4, separators=(',', ': '), ensure_ascii=False))\n",
      "            \n",
      "            fdict.write(\"\\n\\n\")\n",
      "            \n",
      "            cnt += 1        \n",
      "            #break\n",
      "    \n",
      "    for word in words:\n",
      "        #fdict.write(word.encode('UTF-8') + '\\n')\n",
      "        fdict.write(word + '\\n')\n",
      "    fdict.close()    \n",
      "    fnotindict.close()    \n",
      "\n",
      "\n",
      "def buildDict4dP39195(filePath, wordListFile, recFlag=0):\n",
      "    \"\"\"For words in wordListFile, build their dictionary from geweiDict;\n",
      "        and copy recordings of them and their parent-entries or children-entries.\n",
      "        don't include the suffixt '.txt' for 2nd argument wordListFile \n",
      "        if recFlag == 0, copy no recording files\n",
      "    \"\"\"\n",
      "    \n",
      "    targetPath = createDir(filePath) + '\\\\'\n",
      "    print '---target path', targetPath\n",
      "    \n",
      "    if recFlag: copyRec(targetPath, wordListFile)\n",
      "    \n",
      "    #fdict = open(targetPath + wordListFile + '_subDict.txt', 'w')    \n",
      "    #fnotindict = open(targetPath + wordListFile + '_notIndict.txt', 'w')\n",
      "    fdict = codecs.open(targetPath + wordListFile + '_Dict.txt', encoding='utf-8', mode='w')    \n",
      "    #fnotindict = codecs.open(targetPath + wordListFile + '_notIndict.txt', encoding='utf-8', mode='w')    \n",
      "\n",
      "    #connect to MongoDB\n",
      "    #client = MongoClient('localhost', 27017)\n",
      "    #db = client.dpdb \n",
      "    #gwdict = db.geweiDict    \n",
      "    gwdict = connectDB('geweiDict')\n",
      "    \n",
      "    words = []\n",
      "    fwordlist = codecs.open(targetPath + wordListFile + '.txt', encoding='utf-8')\n",
      "    #for line in open(targetPath + wordListFile + '.txt', 'r'):\n",
      "\n",
      "    items = []\n",
      "    for line in fwordlist:\n",
      "        fdict.write(line)\n",
      "        items.append(line.strip())\n",
      "    fwordlist.close()\n",
      "    fdict.write(\"\\n\\n\")\n",
      "        \n",
      "\n",
      "    for item in items:\n",
      "        #item = line.strip()\n",
      "        \n",
      "        cnt = 1\n",
      "            \n",
      "        #results = dpdict.find({\"$or\": [{\"hw\":item},{\"infl\": item}, {\"idpvs\": item}]})\n",
      "        #case insensitive query\n",
      "        results = gwdict.find({\"$or\": [{\"hw\": re.compile('^' + re.escape(item) + '$', re.IGNORECASE)}]},\n",
      "                              {\"_id\":0, \"hw\":1, \"pos\":1, \"prn\":1, \"cp\":1, \"idpvs\":1, \"sublist\":1})\n",
      "                              #{\"_id\":0, \"alles\":0, \"cr\":0, \"hw\":0, \"id\":0, \"bw\":0, \"label\":0})\n",
      "        \n",
      "        if results.count() == 0:\n",
      "            print '--not in dict--: ', item\n",
      "            #fnotindict.write(item+'\\n')\n",
      "            continue\n",
      "    \n",
      "        for result in results:\n",
      "            print cnt, ': ', item\n",
      "            \n",
      "            word = result.get(\"hw\")\n",
      "            frword = result.get(\"hwfr\")\n",
      "            if frword == None:\n",
      "                #print word, ' --- is not a French word'\n",
      "                #continue #for build French words sub dict\n",
      "                words.append(word)\n",
      "            else:\n",
      "                print word, ' its French word is ... ', frword\n",
      "                words.append(frword)                \n",
      "            \n",
      "    \n",
      "            wsrcwav = recsrcpath + word + '.wav'\n",
      "            wsrcmp3 = recsrcpath + word + '.mp3'\n",
      "            \n",
      "            if word != item and recFlag:\n",
      "                if os.path.isfile(wsrcwav):\n",
      "                    shutil.copy(wsrcwav, targetPath)\n",
      "                elif os.path.isfile(wsrcmp3):\n",
      "                    shutil.copy(wsrcmp3, targetPath)\n",
      "    \n",
      "            \n",
      "            #print type(dpdict.find_one({\"hw\":word}))\n",
      "            #obj = dpdict.find_one({\"hw\":word})\n",
      "            #json.dump(str(obj), fdict, sort_keys=True, indent=4,separators=(',', ': '))\n",
      "            #print json.dumps(obj, sort_keys=True, indent=4,separators=(',', ': '))\n",
      "            #fdict.write(str(dpdict.find_one({\"hw\":word})))\n",
      "            \n",
      "            #print dumps(result, sort_keys=True, indent=4,separators=(',', ': '))\n",
      "            fdict.write(item + ' (' + word + ')\\n')\n",
      "            \n",
      "            #fdict.write(dumps(result, sort_keys=True, indent=4, separators=(',', ': ')))\n",
      "            \n",
      "            # ensure_ascii=False & .encode('utf8') will write to file 'caf\u00e9', not 'caf\\u00e9'\n",
      "            # but if open file with codecs encoding='utf-8', must remove .encode('utf8')\n",
      "            #fdict.write(dumps(result, sort_keys=True, indent=4, separators=(',', ': '), ensure_ascii=False).encode('utf8'))\n",
      "            \n",
      "            # after use codecs encoding='utf-8' open files:\n",
      "            fdict.write(dumps(result, sort_keys=True, indent=4, separators=(',', ': '), ensure_ascii=False))\n",
      "            \n",
      "            fdict.write(\"\\n\\n\")\n",
      "            \n",
      "            cnt += 1        \n",
      "            #break\n",
      "    \n",
      "    #fdict.seek(0,0)\n",
      "    for word in words:\n",
      "        #fdict.write(word.encode('UTF-8') + '\\n')\n",
      "        fdict.write(word + '\\n')\n",
      "    fdict.close()    \n",
      "    #fnotindict.close()    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def buildDict_cp():\n",
      "    \"\"\"get all common phrases from geweiDict\n",
      "    \"\"\"\n",
      "\n",
      "    fdict = open(aggrePath + 'subDict_cp.txt', 'w')\n",
      " \n",
      "    \n",
      "    #connect to MongoDB\n",
      "    #client = MongoClient('localhost', 27017)\n",
      "    #db = client.dpdb \n",
      "    #gwdict = db.geweiDict    \n",
      "    gwdict = connectDB('geweiDict')    \n",
      "    \n",
      "    results = gwdict.find({\"cp\": {\"$ne\": None}}, {\"_id\":0, \"hw\":1, \"cp\":1}).sort(\"hw\", 1)\n",
      "    #.limit(1000)\n",
      "    \n",
      "   \n",
      "    if results.count() == 0: print '--not cp in dict--'\n",
      "    \n",
      "    for result in results:\n",
      "        word = result.get(\"hw\")\n",
      "        cps = result.get(\"cp\")\n",
      "        totalcps = len(cps)\n",
      "        cnt = 1\n",
      "            \n",
      "        #print dumps(result, sort_keys=True, indent=4,separators=(',', ': '))\n",
      "        # Is 'ascii ignore' right for this case? may revise the codes!\n",
      "        fdict.write(word.encode('ascii', 'ignore') + ': ')\n",
      "        for item in cps:\n",
      "            if cnt == totalcps:\n",
      "                fdict.write(item.encode('ascii', 'ignore'))\n",
      "            elif cnt < totalcps:\n",
      "                fdict.write(item.encode('ascii', 'ignore') + ', ')\n",
      "            print item.encode('ascii', 'ignore')\n",
      "            cnt += 1\n",
      "        fdict.write('\\n')\n",
      "    \n",
      "    fdict.close()    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def buildDictByLabel(label):\n",
      "    \"\"\"get all words about a label from geweiDict\n",
      "    \"\"\"\n",
      "\n",
      "    fdict = open(aggrePath + 'subDict_' + label + '.txt', 'w')    \n",
      "\n",
      "    #connect to MongoDB\n",
      "    #client = MongoClient('localhost', 27017)\n",
      "    #db = client.dpdb \n",
      "    #gwdict = db.geweiDict    \n",
      "    gwdict = connectDB('geweiDict')\n",
      "\n",
      "    results = gwdict.find({\"label\": label}, {\"_id\":0}).sort(\"hw\", 1)    \n",
      "   \n",
      "    if results.count() == 0: print '--not cp in dict--'\n",
      "    \n",
      "    words = []\n",
      "    for result in results:\n",
      "        word = result.get(\"hw\")\n",
      "        words.append(word)\n",
      "            \n",
      "        fdict.write(word + '\\n')\n",
      "        fdict.write(dumps(result, sort_keys=True, indent=4,separators=(',', ': ')))\n",
      "        fdict.write(\"\\n\\n\")\n",
      "    \n",
      "    for word in words:\n",
      "        fdict.write(word + '\\n')\n",
      "    fdict.close()    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#------------------ functions: maintain dictionary ---------------------#\n",
      "\n",
      "\n",
      "def dumpDict():\n",
      "    \"\"\" dump from collection 'dpdict' of dpdb\n",
      "    \"\"\"\n",
      "    \n",
      "    dpdict = connectDB('dpdict')\n",
      "    # http://api.mongodb.org/python/current/api/pymongo/cursor.html\n",
      "    \n",
      "    #dump 84 French words\n",
      "    #results = dpdict.find({'fr': 'y'},{'_id':0}).sort('hw')\n",
      "    \n",
      "    #dump other 39111 words except French words\n",
      "    results = dpdict.find({'fr': {'$exists': None}},{'_id':0})\n",
      "    \n",
      "    cnt = 1\n",
      "    for result in results:\n",
      "        word = result.get('hw')\n",
      "        print cnt, ': ', word\n",
      "        fname = dictpath + word + '_' + str(cnt) + '.json'\n",
      "        if isfile(fname): print '---has existed---', fname\n",
      "        fdict = open(fname, 'w')\n",
      "        #fdict = open(dictpath + str(cnt) + '.' + word + '.json', 'w')\n",
      "        fdict.write(dumps(result, sort_keys=True, indent=4,separators=(',', ': ')))\n",
      "        fdict.close()\n",
      "        cnt += 1        \n",
      "        #if cnt > 10: break\n",
      "\n",
      "\n",
      "\n",
      "def loadOneFile(fname):\n",
      "    \"\"\" load one json file into collection 'geweiDict' of dpdb\n",
      "    \"\"\" \n",
      "    \n",
      "    gwdict = connectDB('geweiDict')\n",
      "    \n",
      "    #print fname\n",
      "    with open(fname, 'r') as fentry:\n",
      "        raw_doc = fentry.read()    \n",
      "    #print raw_doc, '\\n', type(raw_doc)\n",
      "    doc_id = gwdict.insert(json.loads(raw_doc))\n",
      "    print doc_id\n",
      "\n",
      "    \n",
      "def loadDict(pfname):\n",
      "    \"\"\" load one json file or all json files in a directory into collection 'geweiDict' of dpdb\n",
      "        pfname can be name of a file or a path\n",
      "    \"\"\"\n",
      "    \n",
      "    if isdir(pfname):\n",
      "        cnt = 1\n",
      "        files = [ f for f in listdir(pfname) if isfile(join(pfname,f)) ]\n",
      "        for file in files:\n",
      "            print cnt, '---', file\n",
      "            loadOneFile(pfname + file)\n",
      "            cnt += 1\n",
      "    elif isfile(pfname):\n",
      "        print pfname\n",
      "        loadOneFile(pfname)\n",
      "    else:\n",
      "        print '---in loadDict, check ', pfname\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# M-W Collegiate API key for way.g.wang@outlook.com\n",
      "ref5 = 'collegiate'\n",
      "key5 = '3976dd43-e75c-4ffc-ac79-893c46887efb'\n",
      "#stevbecker@outlook.com\n",
      "ref6 = 'collegiate'\n",
      "key6 = '7318e324-f426-4cbc-bfcb-f0f324fdc566'\n",
      "\n",
      "def grab_xml(word, ref, key):\n",
      "    #response = urllib2.urlopen('http://www.dictionaryapi.com/api/v1/references/learners/xml/decipher?\n",
      "    #                             key=8e5785eb-6777-4d84-8684-4e92a96733d6')\n",
      "    req = 'http://www.dictionaryapi.com/api/v1/references/' + ref + '/xml/' + urllib2.quote(word) + '?key=' + urllib2.quote(key)\n",
      "    print req\n",
      "    response = urllib2.urlopen(req)\n",
      "    return response.read()\n",
      "\n",
      "\n",
      "def pullDictFromMW(filepath, wordlist):\n",
      "    fwords = open(filepath + wordlist, 'r')\n",
      "    #fwordNoXML = open(filepath + 'fwordNoXML.txt', 'w')\n",
      "    \n",
      "    cnt = 0\n",
      "    for line in fwords:       \n",
      "        jsonBody = {}\n",
      "        \n",
      "        cnt += 1\n",
      "        #if cnt > 1: break \n",
      "            \n",
      "        word = line.strip()\n",
      "        print word, '---------\\n'\n",
      "\n",
      "        html = grab_xml(word, ref6, key6)\n",
      "        print html, '\\n'\n",
      "        \n",
      "        i = 0\n",
      "        try:\n",
      "            root = ET.fromstring(html)\n",
      "                \n",
      "            ewcnt = 0\n",
      "            for entry in root.iter('entry'):                    \n",
      "                eword = entry.find('ew').text               \n",
      "                if eword.lower() != word.lower(): continue\n",
      "                    \n",
      "                ewcnt += 1\n",
      "                print eword, ': ', ewcnt\n",
      "                if ewcnt == 1:\n",
      "                    fj = open(filepath + eword + '.json', 'w')\n",
      "                elif ewcnt > 1:\n",
      "                    fj = open(filepath + eword + '_' + str(ewcnt) + '.json', 'w')\n",
      "                \n",
      "\n",
      "                addhis = []\n",
      "                addhis.append(time.strftime(\"%Y%m%d\"))\n",
      "                addhis.append('MWCollegiate') #pull from M-W Collegiate API\n",
      "                jsonBody['addhis'] = addhis\n",
      "                jsonBody['hw'] = eword\n",
      "                \n",
      "                pron = entry.find('pr')\n",
      "                if pron != None: \n",
      "                    print pron.text                \n",
      "                    jsonBody['prn'] = pron.text\n",
      "\n",
      "                pos = entry.find('fl')\n",
      "                if pos != None: \n",
      "                    print pos.text                \n",
      "                    jsonBody['pos'] = pos.text\n",
      "                    \n",
      "                defis = []\n",
      "                for defi in entry.iter('dt'):\n",
      "                    #print defi.text\n",
      "                    for itext in defi.itertext():\n",
      "                        print '---itertext:', itext\n",
      "                        if len(itext) > 1: defis.append(itext)\n",
      "                if defis: jsonBody['sublist'] = defis                \n",
      "                \n",
      "                infls = []\n",
      "                for infl in entry.iter('ure'):\n",
      "                    print '===ure:', infl.text\n",
      "                    infls.append(infl.text.replace('*', ''))\n",
      "                for infl in entry.iter('if'):\n",
      "                    print '===if:', infl.text\n",
      "                    infls.append(infl.text.replace('*', ''))\n",
      "                if infls: jsonBody['infl'] = infls\n",
      "\n",
      "       \n",
      "                for sound in entry.iter('wav'):\n",
      "                    i += 1\n",
      "                    #http://media.merriam-webster.com/soundc11/h/heart001.wav\n",
      "                    \n",
      "                    sfname = sound.text\n",
      "                    print '------sfname=sound.text: ', sfname\n",
      "                    # must use word[0] because it's lowercase, not use eword[0] which may be uppercase\n",
      "                    if sfname[0].isdigit(): subdir = 'number'\n",
      "                    elif sfname.startswith('bix'): subdir = 'bix'\n",
      "                    elif sfname.startswith('gg'): subdir = 'gg'\n",
      "                    else: subdir = sfname[0]\n",
      "                \n",
      "                    wavurl = 'http://media.merriam-webster.com/soundc11/' + subdir + '/' + sound.text\n",
      "                    print wavurl\n",
      "            \n",
      "                    if i==1:\n",
      "                        #print eword + ': ' + wavurl + '---' + filepath + eword\n",
      "                        #pass\n",
      "                        urllib.urlretrieve(wavurl, filepath + eword + '.wav')\n",
      "                    else:\n",
      "                        #print sound.text\n",
      "                        pass\n",
      "                        ##urllib.urlretrieve(wavurl, filepath + 'subentry\\\\' + sound.text)\n",
      "                        \n",
      "                if jsonBody:\n",
      "                    print jsonBody\n",
      "                    json.dump(jsonBody, fj, sort_keys=True, indent=4, separators=(',', ': '))\n",
      "            \n",
      "                fj.close()                        \n",
      "                    \n",
      "        except ParseError:\n",
      "            print '---in ParseError'\n",
      "            continue\n",
      "        else:\n",
      "            print '---in else'\n",
      "            continue\n",
      "            \n",
      "        \n",
      "        #if i==0: fwordNoXMLorWav.write(line)     \n",
      "\n",
      "    fwords.close()\n",
      "    #fwordNoXMLorWav.close()\n",
      "\n",
      "\n",
      "#------------------ functions: aggregation and analysis ---------------------#\n",
      "\n",
      "def sentenceStats(filepath, wordlist):\n",
      "    fwords = open(filepath + wordlist + '.txt', 'r')\n",
      "    fstats = open(filepath + wordlist + '_cntES.txt', 'w')\n",
      "    \n",
      "    gwdict = connectDB('geweiDict')    \n",
      "    \n",
      "    for line in fwords:\n",
      "        word = line.strip()\n",
      "        results = gwdict.aggregate([\n",
      "                      {\"$match\": {\"hw\" : word}}, \n",
      "                      {\"$unwind\": \"$alles\"},\n",
      "                      {\"$project\": {\"count\":{\"$add\":1}}},\n",
      "                      {\"$group\": {\"_id\": \"null\", \"cntES\": {\"$sum\": \"$count\" }}}\n",
      "                    ])\n",
      "        #results is a dictionary with length 2 like \n",
      "        # {u'ok': 1.0, u'result': [{u'_id': u'null', u'cntES': 2}]} : there are 'alles'\n",
      "        # or\n",
      "        # {u'ok': 1.0, u'result': []} : there is no field 'alles' in documents \n",
      "        \n",
      "        \n",
      "        #print results, 'len: ', len(results)\n",
      "        result = results.get('result') # result is a list which may be empty\n",
      "        #print result\n",
      "        \n",
      "        if len(result) != 0:\n",
      "            cntES = result[0].get('cntES')\n",
      "            print word, ';', cntES\n",
      "            fstats.write(word + ';' + str(cntES) + '\\n')\n",
      "        else:\n",
      "            print word, ';0'\n",
      "            fstats.write(word + ';0\\n')\n",
      "    fwords.close()\n",
      "    fstats.close()\n",
      "\n",
      "\"\"\"\n",
      "    results = gwdict.aggregate([\n",
      "                  {\"$match\": {\"hw\" : \"make\"}}, \n",
      "                  {\"$unwind\": \"$alles\"},\n",
      "                  {\"$project\": {\"count\":{\"$add\":1}}},\n",
      "                  {\"$group\": {\"_id\": \"null\", \"cntES\": {\"$sum\": \"$count\" }}}\n",
      "                ])\n",
      "    print results\n",
      "    for item in results.get(\"result\"):\n",
      "        print item.get(\"cntES\")\n",
      "\n",
      "\n",
      "# this will get total of all 'alles': 164901\n",
      "    results = gwdict.aggregate([\n",
      "                  {\"$unwind\": \"$alles\"},\n",
      "                  {\"$project\": {\"count\":{\"$add\":1}}},\n",
      "                  {\"$group\": {\"_id\": \"null\", \"cntES\": {\"$sum\": \"$count\" }}}\n",
      "                ])\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "\"\"\"\n",
      ">>> db.things.aggregate([\n",
      "...         {\"$unwind\": \"$tags\"},\n",
      "...         {\"$group\": {\"_id\": \"$tags\", \"count\": {\"$sum\": 1}}},\n",
      "...         {\"$sort\": SON([(\"count\", -1), (\"_id\", -1)])}\n",
      "...     ])\n",
      "...\n",
      "\"\"\"\n",
      "#sentenceStats('E:\\\\_BreatheWords\\\\_wordCourse\\\\', '34212from39111')\n",
      "\n",
      "\n",
      "#------------------ functions: create excluded word lists of different levels ---------------------#\n",
      "\n",
      "def createExcludedWordlist(filepath, wordlist):\n",
      "    fwords = codecs.open(filepath + wordlist + '.txt', encoding='utf-8')\n",
      "    fexclu = codecs.open(filepath + wordlist + '_excluWordlist.txt', encoding='utf-8', mode='w')\n",
      "    \n",
      "    gwdict = connectDB('geweiDict')    \n",
      "    \n",
      "    cnt = 1\n",
      "    uniExclu = set()\n",
      "    for line in fwords:\n",
      "        word = line.strip()\n",
      "        uniExclu.add(word)\n",
      "        results = gwdict.find({\"hw\":word})\n",
      "        \n",
      "        for result in results:\n",
      "            if result.get(\"infl\"):\n",
      "                infls = set(result.get(\"infl\"))\n",
      "                for infl in infls:\n",
      "                    uniExclu.add(infl)\n",
      "        cnt += 1\n",
      "        #if cnt > 5: break\n",
      "\n",
      "    for item in sorted(uniExclu):\n",
      "        fexclu.write(item + '\\n')\n",
      "    \n",
      "    fwords.close()\n",
      "    fexclu.close()\n",
      "\n",
      "#createExcludedWordlist('E:\\\\_BreatheWords\\\\_wordCourse\\\\', '10-19')   \n",
      "    \n",
      "    \n",
      "\n",
      "#------------------ Function examples: build sub dictionary ---------------------#\n",
      "\n",
      "#createDir(rootpath + 'andrew')\n",
      "\n",
      "#tidyWordList(rootpath+'toefl', 'TOEFL', 'excluWordsAA.txt')\n",
      "#tidyWordList(rootpath+'ulysses', 'aboutUlysses', 'excluWordsAA.txt')\n",
      "\n",
      "#buildWordListFromText('E:\\\\psalm\\\\', 'Psalms')\n",
      "#buildWordListFromText(rootpath + 'ds4biz\\\\', 'DS4Business', 'excluWordsAA.txt')\n",
      "#buildWordListFromText(rootpath + '_gwdictLab\\\\', 'txt4Lab')\n",
      "\n",
      "\n",
      "#copyRec(rootpath + '50\\\\', '50States')\n",
      "#copyRec(rootpath + '_gwdictLab\\\\', 'copyRec')\n",
      "\n",
      "#buildSubDict(rootpath + 'ds4biz', 'DS4Business_wordList_tidyExclu')\n",
      "#buildSubDict('e:\\\\psalm', 'Psalms_wordList_tidyExclu')\n",
      "#buildSubDict(rootpath + '2997', '2997BasicWords')\n",
      "#buildSubDict(rootpath + '_gwdictLab', 'unicode')\n",
      "#buildSubDict(rootpath + 'french', '84french2en')\n",
      "#buildSubDict(rootpath + '_wordCourse', 'alles0_6573')\n",
      "\n",
      "\n",
      "#buildDict_cp()\n",
      "\n",
      "#buildDictByLabel('baseball')\n",
      "#buildDictByLabel('slang')\n",
      "\n",
      "\n",
      "\n",
      "#------------------ Function examples: maintain dictionary in geweiDict ---------------------#\n",
      "\n",
      "#dumpDict()\n",
      "\n",
      "#loadDict(updatepath)\n",
      "#loadDict(updatepath + 'meager_26608.json')\n",
      "\n",
      "#loadDict(addpath)\n",
      "#loadDict(addpath + 'iteration_2.json')\n",
      "#loadDict(\"E:\\\\_gwDict\\\\MWLearnerFrench2En\\\\El Nino_1.json\")\n",
      "\n",
      "\n",
      "#pullDictFromMW(rootpath + 'ulysses\\\\', 'aboutUlysses_tidy_notIndict.txt')\n",
      "\n",
      "\n",
      "\n",
      "#------------------ A typical usage of functions ---------------------#\n",
      "# in directory 'andrew', there's 'Andrew.txt' TED scripts\n",
      "# Step 0\n",
      "# notice: the function 'buildWordListFromText' has called function 'tidyWordList', so skip Step 1, go directly to Step 2\n",
      "#buildWordListFromText(rootpath + 'andrew\\\\', 'Andrew')\n",
      "#buildWordListFromText(rootpath + 'psalm\\\\1-10\\\\', 'Psalms1-10')\n",
      "#buildWordListFromText(rootpath + 'posts\\\\', 'sage')\n",
      "\n",
      "# (read The Most Dangerous Book: The Battle for James Joyce\u2019s Ulysses by Kevin Birmingham (Penguin 2014-06))\n",
      "# (tap in words I want to learn, saving them in a file 'aboutUlysses.txt' located in directory 'ulysses')\n",
      "\n",
      "# Step 1\n",
      "#tidyWordList(rootpath+'ulysses', 'aboutUlysses', 'excluWordsAA.txt')\n",
      "#tidyWordList(rootpath+'french', 'french2en', 'excluWordsAA.txt')\n",
      "#\n",
      "# Step 2\n",
      "#buildSubDict(rootpath + 'ulysses', 'aboutUlysses_tidy')\n",
      "#buildSubDict(rootpath + 'french', 'french2en_tidy')\n",
      "#buildSubDict(rootpath + 'andrew', 'Andrew_wordList_tidy_afterExcluded')\n",
      "#buildSubDict(rootpath + 'psalm\\\\1-10', 'Psalms1-10_wordList_tidy_afterExcluded')\n",
      "#buildSubDict(rootpath + 'toefl', 'TOEFL_notIndict')\n",
      "#buildSubDict(rootpath + 'posts', 'sage_wordList_tidy_afterExcluded')\n",
      "#\n",
      "#\n",
      "# (there are words 'heaventree, indecorous' not in 'geweiDict', so get them from M-W Collegiate API)\n",
      "# Step 3\n",
      "#pullDictFromMW(rootpath + 'ulysses\\\\', 'aboutUlysses_tidy_notIndict.txt')\n",
      "#pullDictFromMW(rootpath + '_gwdictCollegiate\\\\', 'french2en_tidy_noRec.txt')\n",
      "#pullDictFromMW(rootpath + '_gwdictCollegiate\\\\', 'Andrew_wordList_tidy_afterExcluded_notIndict.txt')\n",
      "#pullDictFromMW(rootpath + '_gwdictCollegiate\\\\', 'Psalms_wordList_tidyExclu_notIndict.txt')\n",
      "#pullDictFromMW(rootpath + '_gwdictCollegiate\\\\', 'TOEFL_notIndict.txt')\n",
      "#\n",
      "# (copy indecorous.wav to directory 'recLib')\n",
      "# (copy indecorous.json to direcotry 'Added')\n",
      "# Step 4\n",
      "#loadDict(addpath + 'indecorous.json')\n",
      "#loadDict(addpath + 'absurdist.json')\n",
      "#loadDict('E:\\\\_BreatheWords\\\\_gwdictadd\\\\')\n",
      "#\n",
      "# (merge indecorous.json to aboutUlysses_tidy_subDict.txt)\n",
      "# (or delete all files except aboutUlysses.txt, then repeat step 1, 2)\n",
      "\n",
      "\n",
      "# I have a text file or an unorganized word list;\n",
      "# I need a function to do these work:\n",
      "# 1. call buildWordListFromText, tidyWordList, buildSubDict\n",
      "\n",
      "def wordRunCourse(filePath, fileName, fileAttr='text', recFlag=0, subdictFlag=1, \n",
      "                  excluList='_wordCourse\\\\excluWordlist10-500.txt'):\n",
      "    #if it is a text file\n",
      "    if fileAttr == 'text':\n",
      "        buildWordListFromText(filePath, fileName, excluList)        \n",
      "    #if it is a wordlist file\n",
      "    else:\n",
      "        tidyWordList(filePath, fileName, excluList)\n",
      "        \n",
      "    if subdictFlag:\n",
      "        buildDict4dP39195(filePath, fileName + '_wordList_tidy_afterExcluded', recFlag)\n",
      "    elif recFlag:\n",
      "        copyRec(filePath, fileName + '_wordList_tidy_afterExcluded')\n",
      "\n",
      "#wordRunCourse(rootpath + 'posts\\\\', '20141023raceReportYum', recFlag=1, subdictFlag=0)\n",
      "#wordRunCourse('E:\\\\_dP39195\\\\JeffBezos\\\\', 'JeffBezos1', recFlag=1, excluList='E:\\\\_dP39195\\\\exclu\\\\exclu_1_1500.txt')\n",
      "\n",
      "def clearOutput():\n",
      "    print 'clear output'\n",
      "    \n",
      "#clearOutput()\n",
      "\n",
      "\n",
      "#2015-02-07\n",
      "#build a dictionary of some words for dP 39195\n",
      "#buildDict4dP39195('E:\\\\_dP39195\\\\34001-34110', '34001-34110', 1)\n",
      "\n",
      "#build a dictionary for reading. I've chosen some words for looking up--pre-wordlist\n",
      "#I have no a good excludedWordlist, so buildWordListFromText doesn't work well\n",
      "buildSubDict('E:\\\\_dP39195\\\\JeffBezos', 'JeffBezos1', 1)\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "---target path E:\\_dP39195\\JeffBezos\\\n",
        "in function copyRec, no rec files:  E:\\_gwDict\\recLib\\windmills.wav ,  E:\\_gwDict\\recLib\\windmills.mp3\n",
        "in function copyRec, no rec files:  E:\\_gwDict\\recLib\\chores.wav ,  E:\\_gwDict\\recLib\\chores.mp3\n",
        "in function copyRec, no rec files:  E:\\_gwDict\\recLib\\Airstream.wav ,  E:\\_gwDict\\recLib\\Airstream.mp3\n",
        "---Connect to collection:  geweiDict\n",
        "--not in dict--: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Baccalaureate\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " :  windmills\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " :  vaccinate\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " :  chores\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " :  Caravan\n",
        "2 :  Caravan\n",
        "--not in dict--: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Airstream\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " :  trailer\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " :  hitch\n",
        "2 :  hitch\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " :  roll\n",
        "2 :  roll\n",
        "3 :  roll\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " :  puff\n",
        "2 :  puff\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " :  poke\n",
        "2 :  poke\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " :  realm\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " :  gauge\n",
        "2 :  gauge\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " :  detriment\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " :  plod\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " :  synthesize\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " :  grad\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " :  tinfoil\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " :  entrap\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " :  inertia\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " :  dogma\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " :  wilt\n",
        "2 :  wilt\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " :  conviction\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " :  bluff\n",
        "2 :  bluff\n",
        "3 :  bluff\n",
        "4 :  bluff\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " :  swashbuckling\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " :  relentless\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " :  cynic\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " :  hazard\n",
        "2 :  hazard\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}