{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266\n",
      "92\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# feel a little weird, but it's much better than ugly 'dir > a text'\n",
    "\n",
    "# read images folders to create image files lists\n",
    "\n",
    "import codecs\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "n=3 # n folders and outfiles\n",
    "\n",
    "# add u will read unicode name like pi√±ata.gif correctly\n",
    "folder = [u\"E:\\\\dictIllustration\\\\mwl-358(266-92)\\\\mwl-single-266\\\\\",\n",
    "    u\"E:\\\\dictIllustration\\\\mwl-358(266-92)\\\\mwl-grpbw-92\\\\\",\n",
    "    u\"E:\\\\dictIllustration\\\\mwl-grpcolor-16\\\\\"]\n",
    "\n",
    "outfile = [\"E:\\\\1Now\\\\taglist\\\\mwlimgSingle.txt\", # black-and-white single images\n",
    "     \"E:\\\\1Now\\\\taglist\\\\mwlimgGrpbw.txt\", # black-and-white group images\n",
    "     \"E:\\\\1Now\\\\taglist\\\\mwlimgGrpcol.txt\"] # color pages\n",
    "\n",
    "cntx = [0, 0, 0] # how many files in each folder\n",
    "\n",
    "for i in range(0,n):\n",
    "    with codecs.open(outfile[i], 'w', 'utf-8') as f:\n",
    "        for finfolder in os.listdir(folder[i]):\n",
    "            if isfile(join(folder[i], finfolder)):\n",
    "                f.write(finfolder+'\\n')\n",
    "                cntx[i] += 1\n",
    "        f.close()\n",
    "for k in cntx:\n",
    "    print k\n",
    "\n",
    "# for i in os.listdir(x):\n",
    "#     if isfile(join(x, i)):\n",
    "#         print i, '...', join(x, i)\n",
    "#         cnt1 += 1\n",
    "#     else:\n",
    "#         print 'not a file: ', i\n",
    "#         cnt2 += 1\n",
    "# print 'number of files: ', cnt1, 'number of non-files: ', cnt2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    }
   ],
   "source": [
    "# create empty group images list files\n",
    "import codecs\n",
    "\n",
    "a = \"E:\\\\1Now\\\\taglist\\\\mwlimgGrpbw.txt\" # 90 empty files\n",
    "# a = \"E:\\\\1Now\\\\taglist\\\\mwlimgGrpcol.txt\" # 16 empty files\n",
    "\n",
    "outfolder = \"E:\\\\1Now\\\\taglist\\\\mwlimglist\\\\\"\n",
    "with codecs.open(a, 'r', 'utf-8') as f:\n",
    "    names = f.read().splitlines()\n",
    "    f.close()\n",
    "cnt = 0\n",
    "for name in names:\n",
    "    open(outfolder + name + '.txt', 'w')\n",
    "    cnt += 1\n",
    "print cnt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n",
      "['airplane.gif.txt', 'alligator.gif.txt', 'ape.gif.txt', 'bag.gif.txt', 'baking.gif.txt', 'ball.gif.txt', 'bat.gif.txt', 'bathroom.gif.txt', 'bear.gif.txt', 'beard.gif.txt', 'bed.gif.txt', 'bicycle.gif.txt', 'bird.gif.txt', 'birds c9.jpg.txt', 'boat.gif.txt', 'brass instrument.gif.txt', 'camera.gif.txt', 'camping.gif.txt', 'carpentry.gif.txt', 'car_rev.gif.txt', 'car_types.gif.txt', 'cat.gif.txt', 'chess.gif.txt', 'clothing c13.jpg.txt', 'clothing c14.jpg.txt', 'clothing c15.jpg.txt', 'clothing c16.jpg.txt', 'colors c1.jpg.txt', 'colors c2.jpg.txt', 'colors c3.jpg.txt', 'computer.gif.txt', 'construction.gif.txt', 'deer.gif.txt', 'dog.gif.txt', 'dolphin.gif.txt', 'door.gif.txt', 'engine.gif.txt', 'eye.gif.txt', 'face.gif.txt', 'family.gif.txt', 'fan.gif.txt', 'fish and shellfish c8.jpg.txt', 'fishing.gif.txt', 'flower.gif.txt', 'font.gif.txt', 'foot.gif.txt', 'frog.gif.txt', 'fruits c5.jpg.txt', 'gardening.gif.txt', 'gems and jewelry c11.jpg.txt', 'geometry.gif.txt', 'glove.gif.txt', 'grooming.gif.txt', 'gun.gif.txt', 'gym.gif.txt', 'hair.gif.txt', 'hand.gif.txt', 'hat.gif.txt', 'hook.gif.txt', 'horse.gif.txt', 'hospital.gif.txt', 'house.gif.txt', 'human.gif.txt', 'insects and arachnids c10.jpg.txt', 'keyboard instruments.gif.txt', 'kitchen.gif.txt', 'knob.gif.txt', 'landscapes c7.jpg.txt', 'lighting.gif.txt', 'living room.gif.txt', 'llama.gif.txt', 'mail.gif.txt', 'motorcycle.gif.txt', 'mouth.gif.txt', 'nuts.gif.txt', 'office.gif.txt', 'orchestra.gif.txt', 'pasta.gif.txt', 'patterns c12.jpg.txt', 'percussion.gif.txt', 'place setting.gif.txt', 'plants c6.jpg.txt', 'playground.gif.txt', 'playing card.gif.txt', 'plow.gif.txt', 'plumbing.gif.txt', 'position.gif.txt', 'racket.gif.txt', 'rodent.gif.txt', 'scuba.gif.txt', 'sewing.gif.txt', 'ship.gif.txt', 'shoe.gif.txt', 'skate.gif.txt', 'ski.gif.txt', 'street.gif.txt', 'stringed instrument.gif.txt', 'telephone.gif.txt', 'theater.gif.txt', 'truck.gif.txt', 'vegetables c4.jpg.txt', 'windmill.gif.txt', 'window.gif.txt', 'wolf.gif.txt', 'woodwind.gif.txt', 'zodiac.gif.txt']\n"
     ]
    }
   ],
   "source": [
    "a = os.listdir(\"E:\\\\1Now\\\\taglist\\\\mwlimglist\\\\\")\n",
    "print len(a)\n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\dictrawfile-test\\\n",
      "img group file \" airplane.gif.txt \":  [u'aileron', u'airplane', u'cockpit', u'fuselage', u'jet engine', u'nose', u'tail', u'wing']\n",
      "img group file \" alligator.gif.txt \":  [u'alligator', u'crocodile']\n",
      "img group file \" ape.gif.txt \":  [u'ape', u'chimpanzee', u'gibbon', u'gorilla', u'orangutan']\n",
      "img group file \" bag.gif.txt \":  [u'bag', u'carryall', u'clasp', u'duffel bag', u'garbage', u'grocery', u'handbag', u'handle', u'laundry', u'purse', u'strap', u'tote bag']\n",
      "img group file \" baking.gif.txt \":  [u'Danish', u'Danish pastry', u'English muffin', u'bagel', u'bake', u'bread', u'bun', u'cake', u'cookie', u'croissant', u'crust', u'cupcake', u'dinner', u'hamburger', u'hot dog', u'loaf', u'muffin', u'pie', u'pita', u'roll', u'scone', u'slice']\n",
      "img group file \" ball.gif.txt \":  [u'ball', u'baseball', u'basketball', u'cricket', u'football', u'golf ball', u'rugby', u'soccer', u'softball', u'tennis', u'volleyball']\n",
      "img group file \" bat.gif.txt \":  [u'baseball', u'bat', u'cricket']\n",
      "img group file \" bathroom.gif.txt \":  [u'bar', u'bath', u'bath mat', u'bathroom', u'bathtub', u'brush', u'cabinet', u'chest', u'curtain', u'facecloth', u'faucet', u'hamper', u'hand towel', u'medicine', u'mirror', u'plunger', u'scale', u'shower', u'showerhead', u'sink', u'tap', u'toilet', u'toilet paper', u'towel', u'towel rack', u'tub', u'washcloth', u'wastebasket', u'wastepaper basket']\n",
      "img group file \" bear.gif.txt \":  [u'bear', u'black bear', u'grizzly', u'grizzly bear', u'polar bear']\n",
      "img group file \" beard.gif.txt \":  [u'beard', u'goatee', u'mustache', u'sideburns', u'stubble']\n",
      "img group file \" bed.gif.txt \":  [u'bed', u'bedspread', u'blanket', u'box spring', u'bunk bed', u'comforter', u'double', u'headboard', u'mattress', u'pillow', u'pillowcase', u'sheet', u'single', u'sofa bed', u'spread', u'twin bed']\n",
      "img group file \" bicycle.gif.txt \":  [u'bicycle', u'bottle', u'brake', u'cable', u'chain', u'crank', u'crossbar', u'derailleur', u'front', u'gearshift', u'handlebar', u'lever', u'pedal', u'pump', u'rear', u'rim', u'saddle', u'seat', u'spoke', u'tire', u'water']\n",
      "img group file \" bird.gif.txt \":  [u'bill', u'bird', u'breast', u'tail', u'wing']\n",
      "img group file \" birds c9.jpg.txt \":  [u'Canada goose', u'bald eagle', u'bird', u'blue jay', u'bluebird', u'cardinal', u'chickadee', u'crow', u'duck', u'flamingo', u'goldfinch', u'goose', u'gull', u'hawk', u'heron', u'hummingbird', u'mallard', u'mockingbird', u'owl', u'parrot', u'peacock', u'pelican', u'pheasant', u'pigeon', u'robin', u'seagull', u'sparrow', u'starling', u'swallow', u'turkey', u'vulture', u'woodpecker', u'wren']\n",
      "img group file \" boat.gif.txt \":  [u'boat', u'bow', u'canoe', u'catamaran', u'gunwale', u'hull', u'kayak', u'keel', u'mast', u'motorboat', u'oar', u'outboard motor', u'paddle', u'rowboat', u'rudder', u'sail', u'sailboard', u'sailboat', u'stern', u'yacht']\n",
      "img group file \" brass instrument.gif.txt \":  [u'French horn', u'brass', u'instrument', u'trombone', u'trumpet', u'tuba', u'valve']\n",
      "img group file \" camera.gif.txt \":  [u'LCD', u'camera', u'flash', u'lens', u'monitor', u'viewfinder', u'zoom lens']\n",
      "img group file \" camping.gif.txt \":  [u'air bed', u'air mattress', u'backpack', u'camp', u'camping', u'canteen', u'daypack', u'lantern', u'sleeping bag', u'stove', u'tent']\n",
      "img group file \" carpentry.gif.txt \":  [u'Phillips screwdriver', u'belt', u'bit', u'blade', u'bolt', u'carpentry', u'chisel', u'chuck', u'circular saw', u'clamp', u'claw', u'drill', u'file', u'hacksaw', u'hammer', u'level', u'nail', u'nut', u'plane', u'pliers', u'ruler', u'sander', u'saw', u'screw', u'screwdriver', u'spirit level', u'square', u'tape measure', u'tool', u'utility knife', u'vise', u'washer', u'wrench']\n",
      "img group file \" car_rev.gif.txt \":  [u'CD', u'accelerator', u'air', u'antenna', u'axle', u'battery', u'box', u'brake', u'bumper', u'car', u'catalytic converter', u'clutch', u'dashboard', u'differential', u'disc brake', u'door', u'engine', u'exhaust', u'fan', u'fender', u'filter', u'fuel', u'gas', u'gas pedal', u'gauge', u'gearbox', u'gearshift', u'glove', u'glove compartment', u'grille', u'hand brake', u'handle', u'headlamp', u'headlight', u'headrest', u'hood', u'horn', u'hubcap', u'ignition', u'license plate', u'line', u'manifold', u'muffler', u'odometer', u'parking brake', u'parking light', u'pedal', u'player', u'radiator', u'radio', u'rearview mirror', u'seat belt', u'side-view mirror', u'speedometer', u'steering wheel', u'sunroof', u'tachometer', u'taillight', u'tailpipe', u'tank', u'tire', u'transmission', u'trunk', u'turn signal', u'vent', u'window', u'windshield', u'windshield wiper']\n",
      "img group file \" car_types.gif.txt \":  [u'SUV', u'car', u'convertible', u'hatchback', u'limousine', u'minivan', u'race car', u'sedan', u'sport-utility vehicle', u'sports car', u'station wagon']\n",
      "img group file \" cat.gif.txt \":  [u'cat', u'cheetah', u'cougar', u'domestic', u'jaguar', u'leopard', u'lion', u'lynx', u'mountain lion', u'puma', u'tiger']\n",
      "img group file \" chess.gif.txt \":  [u'bishop', u'castle', u'chess', u'chessboard', u'king', u'knight', u'pawn', u'queen', u'rook', u'square']\n",
      "img group file \" clothing c13.jpg.txt \":  [u'ankle sock', u'bathing suit', u'bikini', u'bottom', u'boxer', u'boxer shorts', u'bra', u'brassiere', u'brief', u'camisole', u'half', u'knee', u'leggings', u'leotard', u'panties', u'pantyhose', u'slip', u'sock', u'swimming trunks', u'swimsuit', u'tights', u'top', u'trunk', u'undershirt', u'waistband']\n",
      "img group file \" clothing c14.jpg.txt \":  [u'T-shirt', u'belt', u'blouse', u'blue jeans', u'capri pants', u'cuff', u'dress shirt', u'halter', u'jeans', u'mini', u'miniskirt', u'necktie', u'overall', u'pants', u'polo shirt', u'shirt', u'short', u'skirt', u'suspender', u'sweatpants', u'sweatshirt', u'tank top', u'tie', u'top', u'trousers']\n",
      "img group file \" clothing c15.jpg.txt \":  [u'button', u'cardigan', u'crease', u'cuff', u'dress', u'evening', u'evening gown', u'hood', u'jacket', u'lapel', u'overcoat', u'parka', u'pocket', u'pullover', u'raincoat', u'scarf', u'sleeve', u'spaghetti strap', u'sport', u'sport coat', u'sports coat', u'sports jacket', u'suit', u'sweater', u'turtleneck', u'vest', u'waist']\n",
      "img group file \" clothing c16.jpg.txt \":  [u'bow tie', u'cummerbund', u'dress', u'fly', u'gown', u'kilt', u'kimono', u'muumuu', u'pleat', u'sari', u'sarong', u'train', u'tuxedo', u'uniform', u'wedding']\n",
      "img group file \" colors c1.jpg.txt \":  [u'black', u'blue', u'brown', u'gray', u'green', u'orange', u'purple', u'red', u'white', u'yellow']\n",
      "img group file \" colors c2.jpg.txt \":  [u'amber', u'aqua', u'blue', u'bronze', u'buff', u'charcoal', u'cobalt blue', u'copper', u'cream', u'cyan', u'emerald', u'forest green', u'gold', u'green', u'indigo', u'ivory', u'jade', u'lemon', u'lemon yellow', u'lime green', u'mustard', u'navy', u'navy blue', u'olive', u'olive green', u'pea green', u'powder blue', u'royal blue', u'sea green', u'sky blue', u'slate blue', u'slate gray', u'taupe', u'teal', u'turquoise']\n",
      "img group file \" colors c3.jpg.txt \":  [u'amethyst', u'beige', u'brick red', u'brown', u'burgundy', u'cherry', u'chocolate', u'coral', u'crimson', u'fuchsia', u'khaki', u'lavender', u'lilac', u'magenta', u'mahogany', u'maroon', u'mauve', u'peach', u'pink', u'plum', u'red', u'rose', u'ruby', u'russet', u'saffron', u'salmon', u'salmon pink', u'scarlet', u'tan', u'tangerine', u'terra-cotta', u'vermilion', u'violet']\n",
      "img group file \" computer.gif.txt \":  [u'CD-ROM', u'computer', u'cursor', u'drive', u'icon', u'key', u'keyboard', u'monitor', u'mouse', u'power strip', u'screen', u'speaker', u'taskbar', u'toolbar', u'tower', u'window']\n",
      "img group file \" construction.gif.txt \":  [u'backhoe', u'bulldozer', u'cement mixer', u'construction', u'forklift', u'front loader', u'front-end loader', u'truck']\n",
      "img group file \" deer.gif.txt \":  [u'caribou', u'deer', u'elk', u'moose', u'reindeer', u'wapiti', u'white-tailed deer']\n",
      "img group file \" dog.gif.txt \":  [u'Chihuahua', u'German shepherd', u'Labrador retriever', u'Rottweiler', u'Shetland sheepdog', u'Yorkshire terrier', u'beagle', u'boxer', u'cocker spaniel', u'dachshund', u'dog', u'golden retriever', u'husky', u'poodle', u'pug', u'sheltie']\n",
      "img group file \" dolphin.gif.txt \":  [u'dolphin', u'porpoise']\n",
      "img group file \" door.gif.txt \":  [u'door', u'doorframe', u'doorjamb', u'doorknob', u'hinge', u'keyhole', u'lock', u'panel']\n",
      "img group file \" engine.gif.txt \":  [u'alternator', u'camshaft', u'combustion chamber', u'crankcase', u'crankshaft', u'cylinder', u'distributor', u'engine', u'fuel', u'inject', u'piston', u'spark plug', u'valve']\n",
      "img group file \" eye.gif.txt \":  [u'eye', u'eyelash', u'eyelid', u'iris', u'pupil', u'white']\n",
      "img group file \" face.gif.txt \":  [u'cheek', u'chin', u'ear', u'earlobe', u'eye', u'eyebrow', u'face', u'forehead', u'hair', u'jaw', u'lip', u'mouth', u'nose', u'nostril', u'temple']\n",
      "img group file \" family.gif.txt \":  [u'aunt', u'brother', u'brother-in-law', u'cousin', u'daughter', u'daughter-in-law', u'family', u'father', u'father-in-law', u'female', u'granddaughter', u'grandfather', u'grandmother', u'grandson', u'husband', u'male', u'married', u'mother', u'mother-in-law', u'nephew', u'niece', u'sister', u'sister-in-law', u'son', u'son-in-law', u'spouse', u'uncle', u'wife']\n",
      "img group file \" fan.gif.txt \":  [u'ceiling', u'electric', u'fan']\n",
      "img group file \" fish and shellfish c8.jpg.txt \":  [u'barracuda', u'bass', u'bluefish', u'catfish', u'clam', u'crab', u'crawfish', u'crayfish', u'eel', u'fish', u'flounder', u'haddock', u'lobster', u'mackerel', u'marlin', u'mussel', u'oyster', u'piranha', u'ray', u'salmon', u'scallop', u'shark', u'shellfish', u'shrimp', u'sunfish', u'trout', u'tuna']\n",
      "img group file \" fishing.gif.txt \":  [u'creel', u'fishing', u'line', u'net', u'reel', u'rod', u'wader']\n",
      "img group file \" flower.gif.txt \":  [u'flower', u'ovary', u'pistil', u'stamen']\n",
      "img group file \" font.gif.txt \":  [u'Roman', u'bold', u'font', u'italic', u'sans serif', u'serif']\n",
      "img group file \" foot.gif.txt \":  [u'ankle', u'arch', u'ball', u'foot', u'heel', u'instep', u'of', u'the', u'toe', u'toenail']\n",
      "img group file \" frog.gif.txt \":  [u'frog', u'toad']\n",
      "img group file \" fruits c5.jpg.txt \":  [u'apple', u'apricot', u'avocado', u'banana', u'bananas', u'berry', u'blackberry', u'blueberry', u'bunch', u'cantaloupe', u'cherry', u'citrus', u'coconut', u'core', u'cranberry', u'fig', u'fruit', u'gooseberry', u'grape', u'grapefruit', u'honeydew melon', u'kiwi', u'kiwifruit', u'lemon', u'lime', u'mango', u'melon', u'of', u'orange', u'peach', u'pear', u'peel', u'pineapple', u'pit', u'plum', u'raspberry', u'rind', u'section', u'seed', u'segment', u'slice', u'stem', u'strawberry', u'tropical', u'watermelon']\n",
      "img group file \" gardening.gif.txt \":  [u'cart', u'garden', u'hoe', u'hose', u'leaf', u'pruner', u'pruning shears', u'rake', u'seedling', u'shed', u'spade', u'sprinkler', u'toolshed', u'tray', u'trowel', u'watering can']\n",
      "img group file \" gems and jewelry c11.jpg.txt \":  [u'amethyst', u'aquamarine', u'band', u'bangle', u'bead', u'bracelet', u'brooch', u'cameo', u'chain', u'charm', u'clasp', u'cuff link', u'diamond', u'earring', u'emerald', u'engagement', u'garnet', u'gem', u'jade', u'jewelry', u'lapis lazuli', u'locket', u'necklace', u'onyx', u'opal', u'pearl', u'pendant', u'peridot', u'pin', u'ring', u'ruby', u'sapphire', u'signet ring', u'stud', u'topaz', u'turquoise', u'wedding', u'wedding ring']\n",
      "img group file \" geometry.gif.txt \":  [u'angle', u'arc', u'base', u'circle', u'circumference', u'cone', u'cube', u'cylinder', u'diameter', u'geometry', u'height', u'hexagon', u'octagon', u'pentagon', u'polygon', u'pyramid', u'radius', u'rectangle', u'solid', u'sphere', u'square', u'triangle']\n",
      "img group file \" glove.gif.txt \":  [u'baseball', u'cricket', u'glove', u'hockey', u'ice', u'winter', u'work']\n",
      "img group file \" grooming.gif.txt \":  [u'barrette', u'blow-dryer', u'bobby pin', u'clip', u'clipper', u'comb', u'compact', u'dental floss', u'deodorant', u'dish', u'electric', u'eye shadow', u'face', u'groom', u'hair', u'hairbrush', u'lipstick', u'mascara', u'mirror', u'nail', u'nail file', u'nail polish', u'powder', u'razor', u'razor blade', u'scrunchie', u'shaver', u'soap', u'toothbrush', u'toothpaste', u'tweezers']\n",
      "img group file \" gun.gif.txt \":  [u'assault rifle', u'barrel', u'gun', u'machine gun', u'muzzle', u'pistol', u'rifle', u'shotgun', u'stock', u'trigger']\n",
      "img group file \" gym.gif.txt \":  [u'ball', u'bar', u'barbell', u'bench', u'chin-up', u'dumbbell', u'exercise', u'exercise bike', u'free', u'gym', u'mat', u'pull-up', u'rowing machine', u'stair-climber', u'stationary bike', u'treadmill', u'weight']\n",
      "img group file \" hair.gif.txt \":  [u'Afro', u'bangs', u'braid', u'buzz cut', u'cornrows', u'crew cut', u'dreadlocks', u'hair', u'part', u'pigtails', u'ponytail']\n",
      "img group file \" hand.gif.txt \":  [u'fingernail', u'forefinger', u'hand', u'index finger', u'knuckle', u'little finger', u'middle finger', u'palm', u'pinkie', u'ring finger', u'thumb', u'thumbnail', u'wrist']\n",
      "img group file \" hat.gif.txt \":  [u'baseball cap', u'beret', u'bill', u'brim', u'cap', u'cowboy hat', u'crown', u'fedora', u'hard hat', u'hat', u'hunting', u'knit', u'panama hat', u'sombrero', u'sun hat', u'visor']\n",
      "img group file \" hook.gif.txt \":  [u'coat', u'fishhook', u'hook', u'picture']\n",
      "img group file \" horse.gif.txt \":  [u'bit', u'bridle', u'crop', u'flank', u'hock', u'hoof', u'horse', u'mane', u'muzzle', u'rein', u'saddle', u'stirrup', u'tail', u'withers']\n",
      "img group file \" hospital.gif.txt \":  [u'IV', u'bed', u'bedpan', u'chart', u'control', u'crutch', u'drip', u'hospital', u'table', u'wheelchair']\n",
      "img group file \" house.gif.txt \":  [u'chimney', u'deck', u'door', u'doorstep', u'dormer', u'downspout', u'drainpipe', u'drive', u'driveway', u'eaves', u'fence', u'gable', u'garage', u'gutter', u'house', u'lawn', u'mailbox', u'porch', u'post', u'rail', u'railing', u'roof', u'shutter', u'step', u'walk', u'walkway', u'window']\n",
      "img group file \" human.gif.txt \":  [u'abdomen', u'ankle', u'appendix', u'arm', u'armpit', u'back', u'backbone', u'belly button', u'biceps', u'bladder', u'breast', u'breastbone', u'buttock', u'calf', u'chest', u'clavicle', u'collarbone', u'colon', u'diaphragm', u'elbow', u'esophagus', u'femur', u'fibula', u'foot', u'forearm', u'gallbladder', u'groin', u'hair', u'hand', u'head', u'heart', u'hip', u'hip bone', u'human', u'humerus', u'jawbone', u'kidney', u'knee', u'kneecap', u'large intestine', u'leg', u'liver', u'lung', u'mandible', u'navel', u'neck', u'nipple', u'pancreas', u'patella', u'pelvis', u'radius', u'rectum', u'rib', u'shin', u'shoulder', u'shoulder blade', u'skeleton', u'skull', u'small intestine', u'spinal column', u'spine', u'spleen', u'sternum', u'stomach', u'thigh', u'thighbone', u'tibia', u'ulna', u'upper', u'vertebra', u'waist', u'wrist']\n",
      "img group file \" insects and arachnids c10.jpg.txt \":  [u'Japanese beetle', u'ant', u'arachnid', u'bumblebee', u'butterfly', u'caterpillar', u'chrysalis', u'cicada', u'cockroach', u'cricket', u'daddy longlegs', u'dragonfly', u'earwig', u'egg', u'fly', u'grasshopper', u'honeybee', u'insect', u'mantis', u'mayfly', u'mosquito', u'moth', u'praying mantis', u'roach', u'scorpion', u'spider', u'spider web', u'tarantula', u'termite', u'wasp', u'web']\n",
      "img group file \" keyboard instruments.gif.txt \":  [u'harpsichord', u'instrument', u'keyboard', u'organ', u'pedal', u'piano', u'pipe']\n",
      "img group file \" kitchen.gif.txt \":  [u'baking sheet', u'blender', u'bottle', u'burner', u'cabinet', u'can opener', u'coffeemaker', u'colander', u'cookbook', u'cookie sheet', u'counter', u'cupboard', u'cutting board', u'dish detergent', u'dish rack', u'dish towel', u'dishcloth', u'dishwasher', u'double boiler', u'faucet', u'food processor', u'freezer', u'fridge', u'frying pan', u'grater', u'kettle', u'kitchen', u'lid', u'measure', u'measuring cup', u'microwave', u'microwave oven', u'mixer', u'mixing bowl', u'opener', u'oven', u'paper', u'pot', u'potholder', u'range', u'refrigerator', u'rolling pin', u'saucepan', u'skillet', u'spatula', u'sponge', u'spoon', u'stove', u'tap', u'teakettle', u'toaster', u'toaster oven', u'towel', u'whisk']\n",
      "img group file \" knob.gif.txt \":  [u'cabinet', u'doorknob', u'high', u'keyhole', u'knob', u'low', u'medium', u'off', u'stove']\n",
      "img group file \" landscapes c7.jpg.txt \":  [u'bay', u'beach', u'butte', u'cliff', u'desert', u'dune', u'field', u'forest', u'horizon', u'island', u'lake', u'landscape', u'mesa', u'mountain', u'ocean', u'peak', u'peninsula', u'plateau', u'range', u'river', u'sand dune', u'sea', u'surf', u'the', u'valley', u'waterfall']\n",
      "img group file \" lighting.gif.txt \":  [u'chandelier', u'desk', u'floor lamp', u'fluorescent', u'lamp', u'lampshade', u'light', u'lighting', u'sconce', u'table', u'track lighting']\n",
      "img group file \" living room.gif.txt \":  [u'DVD', u'TV', u'bookcase', u'coffee table', u'couch', u'cushion', u'end table', u'fireplace', u'lamp', u'living room', u'magazine', u'mantel', u'mantelpiece', u'player', u'rack', u'recliner', u'rocker', u'rocking chair', u'rug', u'sofa', u'speaker', u'stereo', u'television', u'throw pillow']\n",
      "img group file \" llama.gif.txt \":  [u'alpaca', u'llama']\n",
      "img group file \" mail.gif.txt \":  [u'address', u'envelope', u'greeting card', u'letter', u'mail', u'manila', u'package', u'parcel', u'postage stamp', u'postcard', u'postmark', u'return address', u'stamp']\n",
      "img group file \" motorcycle.gif.txt \":  [u'moped', u'motor scooter', u'motorcycle', u'scooter']\n",
      "img group file \" mouth.gif.txt \":  [u'gum', u'lip', u'mouth', u'tongue', u'tooth']\n",
      "img group file \" nuts.gif.txt \":  [u'Brazil nut', u'almond', u'cashew', u'chestnut', u'filbert', u'hazelnut', u'nuts', u'pecan', u'pistachio', u'walnut']\n",
      "img group file \" office.gif.txt \":  [u'bulletin board', u'computer', u'copier', u'desk', u'drawer', u'fax', u'file cabinet', u'filing cabinet', u'in-box', u'machine', u'office', u'out-box', u'partition', u'phone', u'photocopier', u'printer', u'shredder', u'telephone', u'wastebasket', u'wastepaper basket']\n",
      "img group file \" orchestra.gif.txt \":  [u'French horn', u'bassoon', u'cello', u'clarinet', u'conductor', u'double bass', u'first', u'flute', u'harp', u'oboe', u'orchestra', u'percussion', u'second', u'trombone', u'trumpet', u'tuba', u'viola', u'violin']\n",
      "img group file \" pasta.gif.txt \":  [u'lasagna', u'macaroni', u'pasta', u'ravioli', u'spaghetti', u'tortellini']\n",
      "img group file \" patterns c12.jpg.txt \":  [u'bathrobe', u'belt', u'checked', u'clothing', u'floral', u'hem', u'long johns', u'long underwear', u'nightgown', u'paisley', u'pajamas', u'pattern', u'pinstripe', u'plaid', u'polka dot', u'robe', u'solid', u'striped']\n",
      "img group file \" percussion.gif.txt \":  [u'bass', u'bongo', u'conga', u'cymbal', u'drum', u'gong', u'kettledrum', u'percussion', u'snare drum', u'tambourine', u'timpani', u'xylophone']\n",
      "img group file \" place setting.gif.txt \":  [u'bowl', u'bread', u'butter', u'cup', u'dish', u'fork', u'glass', u'knife', u'mill', u'napkin', u'pepper', u'pitcher', u'place mat', u'place setting', u'plate', u'ring', u'salt shaker', u'saucer', u'soup', u'spoon', u'tablecloth', u'water glass', u'wine']\n",
      "img group file \" plants c6.jpg.txt \":  [u'African violet', u'English ivy', u'arbor', u'basil', u'birdbath', u'bonsai', u'branch', u'bud', u'bulb', u'bush', u'cactus', u'carnation', u'chrysanthemum', u'cilantro', u'daffodil', u'dill', u'evergreen', u'fence', u'fern', u'flower', u'flower bed', u'fuchsia', u'garden', u'geranium', u'hedge', u'herb', u'houseplant', u'hyacinth', u'iris', u'ivy', u'lawn', u'leaf', u'lily', u'limb', u'mint', u'morning glory', u'mum', u'needle', u'orchid', u'oregano', u'palm', u'pansy', u'parsley', u'path', u'petal', u'philodendron', u'pinecone', u'plant', u'poinsettia', u'root', u'rose', u'rosemary', u'sage', u'shrub', u'stalk', u'stem', u'sunflower', u'thorn', u'thyme', u'tree', u'trunk', u'tulip', u'twig', u'vine', u'weed', u'yard']\n",
      "img group file \" playground.gif.txt \":  [u'play structure', u'playground', u'sandbox', u'seesaw', u'slide', u'swing', u'teeter-totter']\n",
      "img group file \" playing card.gif.txt \":  [u'ace', u'club', u'diamond', u'heart', u'jack', u'king', u'playing card', u'queen', u'spade', u'ten']\n",
      "img group file \" plow.gif.txt \":  [u'plow', u'snowplow']\n",
      "img group file \" plumbing.gif.txt \":  [u'drainpipe', u'elbow', u'line', u'pipe', u'plumbing', u'supply', u'trap', u'valve', u'water']\n",
      "img group file \" position.gif.txt \":  [u'crouch', u'kneel', u'leaning', u'lying', u'position', u'sitting', u'slouch', u'squat', u'standing']\n",
      "img group file \" racket.gif.txt \":  [u'badminton', u'birdie', u'racket', u'shuttlecock', u'squash', u'tennis']\n",
      "img group file \" rodent.gif.txt \":  [u'beaver', u'chipmunk', u'gerbil', u'groundhog', u'guinea pig', u'mouse', u'muskrat', u'porcupine', u'prairie dog', u'rat', u'rodent', u'squirrel', u'woodchuck']\n",
      "img group file \" scuba.gif.txt \":  [u'flipper', u'hose', u'mask', u'scuba', u'scuba diving', u'snorkel', u'tank', u'wet suit']\n",
      "img group file \" sewing.gif.txt \":  [u'crochet', u'hook', u'knitting needle', u'measuring tape', u'needle', u'of', u'pin', u'pincushion', u'sewing', u'spool', u'tape measure', u'thimble', u'thread', u'yarn']\n",
      "img group file \" ship.gif.txt \":  [u'cargo', u'container ship', u'cruise', u'cruise ship', u'freighter', u'liner', u'ship', u'tanker']\n",
      "img group file \" shoe.gif.txt \":  [u'boot', u'buckle', u'clog', u'cowboy boot', u'flip-flop', u'heel', u'high', u'lace', u'moccasin', u'pump', u'sandal', u'shoe', u'shoelace', u'shoestring', u'slipper', u'sneaker', u'sole', u'strap', u'thong', u'toe', u'tongue', u'wingtip', u'work']\n",
      "img group file \" skate.gif.txt \":  [u'blade', u'brake', u'figure skate', u'hockey skate', u'in-line skate', u'lace', u'roller skate', u'skate', u'wheel']\n",
      "img group file \" ski.gif.txt \":  [u'binding', u'ski', u'ski boot', u'ski pole']\n",
      "img group file \" stalactite and stalagmite.gif.txt \":  [u'stalactite', u'stalagmite']\n",
      "img group file \" street.gif.txt \":  [u'crosswalk', u'curb', u'lamp', u'parking meter', u'pedestrian', u'pedestrian crossing', u'sidewalk', u'sign', u'signal', u'stoplight', u'street', u'streetlight', u'traffic light']\n",
      "img group file \" stringed instrument.gif.txt \":  [u'bass', u'bow', u'cello', u'double bass', u'guitar', u'harp', u'stringed instrument', u'viola', u'violin']\n",
      "img group file \" telephone.gif.txt \":  [u'base', u'cell phone', u'coin', u'cordless', u'handset', u'keypad', u'pay phone', u'phone', u'slot', u'telephone']\n",
      "img group file \" tepee.gif.txt \":  [u'tepee', u'wigwam']\n",
      "img group file \" theater.gif.txt \":  [u'aisle', u'balcony', u'box', u'curtain', u'orchestra', u'pit', u'stage', u'theater']\n",
      "img group file \" truck.gif.txt \":  [u'dump truck', u'garbage truck', u'pickup', u'semi', u'semitrailer', u'tanker', u'tow truck', u'tractor-trailer', u'truck']\n",
      "img group file \" vegetables c4.jpg.txt \":  [u'Swiss chard', u'acorn squash', u'and', u'artichoke', u'asparagus', u'bean', u'beet', u'broccoli', u'brussels sprout', u'butternut squash', u'cabbage', u'carrot', u'cauliflower', u'celery', u'chard', u'clove', u'cob', u'collard greens', u'corn', u'cucumber', u'eggplant', u'family', u'floret', u'garlic', u'green', u'green bean', u'green onion', u'head', u'husk', u'iceberg lettuce', u'kale', u'kernel', u'leaf', u'leafy', u'leek', u'lettuce', u'mushroom', u'on', u'onion', u'parsnip', u'pea', u'pepper', u'pod', u'potato', u'pumpkin', u'radish', u'romaine', u'root vegetable', u'scallion', u'shallot', u'snow pea', u'spinach', u'squash', u'stalk', u'summer squash', u'sweet potato', u'the', u'tomato', u'turnip', u'vegetable', u'wax bean', u'yam', u'zucchini']\n",
      "img group file \" windmill.gif.txt \":  [u'vane', u'wind turbine', u'windmill']\n",
      "img group file \" window.gif.txt \":  [u'bay window', u'blind', u'casement', u'curtain', u'double-hung window', u'pane', u'picture window', u'sash', u'shade', u'sill', u'valance', u'window', u'window shade', u'windowpane', u'windowsill']\n",
      "img group file \" wolf.gif.txt \":  [u'coyote', u'wolf']\n",
      "img group file \" woodwind.gif.txt \":  [u'bassoon', u'clarinet', u'flute', u'oboe', u'piccolo', u'recorder', u'saxophone', u'woodwind']\n",
      "img group file \" zodiac.gif.txt \":  [u'Aquarius', u'Aries', u'Capricorn', u'Gemini', u'Leo', u'Libra', u'Pisces', u'Sagittarius', u'Scorpio', u'Taurus', u'Virgo', u'cancer', u'zodiac']\n",
      "1 --- {'prn': [\"'e~,ple!n\"], 'hw': 'airplane'}\n",
      "airplane  has a group image:  airplane.gif\n",
      "2 --- {'prn': [\"'braUn\"], 'hw': 'brown'}\n",
      "brown  has a group image:  colors c1.jpg\n",
      "brown  has a group image:  colors c3.jpg\n",
      "3 --- {'prn': [\"'braUn!S\"], 'hw': 'brown'}\n",
      "brown  has a group image:  colors c1.jpg\n",
      "brown  has a group image:  colors c3.jpg\n",
      "4 --- {'hw': 'brown'}\n",
      "brown  has a group image:  colors c1.jpg\n",
      "brown  has a group image:  colors c3.jpg\n",
      "5 --- {'prn': [\"'kA:k,p!t\"], 'hw': 'cockpit'}\n",
      "cockpit  has a group image:  airplane.gif\n",
      "6 --- {'prn': [\"'g^v~m.nt\", \",g^v~n'mEntl-\", \",g^v~n'mEntl-i\"], 'hw': 'government'}\n",
      "7 --- {'prn': [\"!n'kA~n.t\"], 'hw': 'incarnate'}\n",
      "is a homograph\n",
      "8 --- {'prn': [\"!n'kA~,ne!t\"], 'hw': 'incarnate'}\n",
      "is a homograph\n",
      "9 --- {'prn': [\"'mEdl-\"], 'hw': 'medal'}\n",
      "medal  has a single image:  medal.gif\n",
      "10 --- {'hw': 'medal'}\n",
      "medal  has a single image:  medal.gif\n",
      "11 --- {'prn': [\"r!'voUlt\"], 'hw': 'revolt'}\n",
      "12 --- {'hw': 'revolt'}\n",
      "total words:  12 , French words:  0 , begin with a dash: 0 , begin with a ':  0\n"
     ]
    }
   ],
   "source": [
    "# mwaled\n",
    "#buildJSON20151109\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import shutil\n",
    "import codecs\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "#connect to MongoDB\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client.dpdb  # database: dpdb\n",
    "\n",
    "\n",
    "#mypath = os.getcwd() + \"\\\\rawfile\"\n",
    "testflag = 1 # if it is a test: 1-yes, 0-no\n",
    "\n",
    "if testflag == 1:\n",
    "    mypath = \"E:\\\\dictrawfile-test\\\\\"\n",
    "    geweiDict = db.geweiDictTest\n",
    "elif testflag == 0:\n",
    "    mypath = \"E:\\\\dictrawfile-39195\\\\\"\n",
    "    geweiDict = db.geweiDict201511 # collection (table): geweiDict201511\n",
    "print mypath\n",
    "\n",
    "\n",
    "def a_has_id(tag):\n",
    "    return tag.has_attr('id')\n",
    "\n",
    "def a_has_href(tag):\n",
    "    return tag.has_attr('href')\n",
    "\n",
    "tlpath = 'E:\\\\1Now\\\\taglist\\\\'\n",
    "\n",
    "# 2939 basic words\n",
    "bws = []\n",
    "with codecs.open(tlpath + '2939bw.txt', 'r', 'utf-8') as f:\n",
    "    bws = f.read().splitlines()\n",
    "    f.close()\n",
    "\n",
    "\n",
    "tfiles = ['wordRoot.txt', 'prefix.txt', 'suffix.txt']\n",
    "topics = []\n",
    "for tfile in tfiles:\n",
    "    topic = {}\n",
    "    with codecs.open('E:\\\\1Now\\\\taglist\\\\' + tfile, 'r', 'utf-8') as f:\n",
    "        twords = f.read().splitlines()\n",
    "        f.close()\n",
    "    topic['words'] = twords\n",
    "    topic['topic'] = tfile.split('.')[0]\n",
    "    topics.append(topic)\n",
    "\n",
    "    \n",
    "# homographs\n",
    "with codecs.open(tlpath + 'homog.txt', 'r', 'utf-8') as f:\n",
    "    homogs = f.read().splitlines()\n",
    "    f.close()\n",
    "    \n",
    "    \n",
    "# imgages in mwaled\n",
    "# 266 gif (single word images)\n",
    "with codecs.open(tlpath + 'mwlimgSingle.txt', 'r', 'utf-8') as f:\n",
    "    imgSingles = f.read().splitlines()\n",
    "    f.close()\n",
    "\n",
    "# 16 jpg (color pages)\n",
    "# 92 gif (black-and-white group words images)\n",
    "imgLists = os.listdir(tlpath + \"mwlimgGrpwl\\\\\")\n",
    "imgGrps = []\n",
    "for imgList in imgLists:\n",
    "    imgGrp = {}\n",
    "    with codecs.open(tlpath + \"mwlimgGrpwl\\\\\" + imgList, 'r', 'utf-8') as f:\n",
    "        twords = f.read().splitlines()\n",
    "        f.close()\n",
    "    if twords:\n",
    "        print 'img group file \"', imgList, '\": ', twords\n",
    "        imgGrp['words'] = twords\n",
    "        imgGrp['img'] = imgList.split('.')[0] + '.' + imgList.split('.')[1]\n",
    "        imgGrps.append(imgGrp)\n",
    "    \n",
    "    \n",
    "labels = ('US', 'chiefly US', 'Brit', 'chiefly Brit', 'slang', 'offensive', 'obscene', 'impolite', \n",
    "          'informal', 'formal', 'literary', 'old-fashioned', 'humorous', 'technical', \n",
    "          'disapproving', 'approving', 'medical', 'law', 'baseball', 'mathematics', 'sports', \n",
    "          'grammar', 'trademark', 'old-fashioned')\n",
    "\n",
    "#map IPA image symbols to my ASCII IPA symbols\n",
    "ipa_to_alpha = {\n",
    "    '22089': 'Z', #ZH -> Z\n",
    "    '22212': 'Z', #ZH -> Z\n",
    "    '22369': 'Z', #ZH -> Z\n",
    "    '22077': 'z',\n",
    "    '22200': 'y',\n",
    "    '22047': 'w',\n",
    "    '22005': 'v',\n",
    "    '22218': 'u-Y',\n",
    "    '22167': 'u-B',\n",
    "    '22170': 'u-b',\n",
    "    '22203': 'u-b',\n",
    "    '22137': 'u-A',\n",
    "    '22140': 'u-a',\n",
    "    '22254': 'u-2',\n",
    "    '22152': 'u-1',\n",
    "    '22242': 'u-1',\n",
    "    '22263': 'u-1',\n",
    "    '22294': 'u-1',\n",
    "    '22312': 'u-1',\n",
    "    '22339': 'u-_',\n",
    "    '22185': 'u-^',\n",
    "    '22309': 'u-#',\n",
    "    '22321': 'u-#',\n",
    "    '22029': 'U', # u -> U\n",
    "    '22074': 'u',\n",
    "    '22342': 'U', # u -> U\n",
    "    '22101': 'th', # TH -> th\n",
    "    '22206': 'th', # TH -> th\n",
    "    '22366': 'th', # TH -> th\n",
    "    '22038': 't',\n",
    "    '22044': 'S', # SH -> S\n",
    "    '22209': 'S', # SH -> S\n",
    "    '22363': 'S', # SH -> S\n",
    "    '22014': 's',\n",
    "    '22050': 'r',\n",
    "    '22092': 'p',\n",
    "    '22281': 'p',\n",
    "    '22026': 'o',\n",
    "    '22068': 'N', # NG -> N\n",
    "    '22360': 'N', # NG -> N\n",
    "    '21981': 'n',\n",
    "    '22080': 'n-', # n -> n-\n",
    "    '22357': 'n-', # n -> n-\n",
    "    '22035': 'm',\n",
    "    '22227': 'm',\n",
    "    '22023': 'l',\n",
    "    '22053': 'l-', # l -> l-\n",
    "    '22354': 'l-', # l -> l-\n",
    "    '22008': 'k',\n",
    "    '22071': 'dZ', # JH -> dZ\n",
    "    '22351': 'dZ', # JH -> dZ\n",
    "    '22062': 'j',\n",
    "    '21966': '!', # i -> !\n",
    "    '22032': 'i',\n",
    "    '22333': '!', # i -> !\n",
    "    '22065': 'h',\n",
    "    '22110': 'h',\n",
    "    '22086': 'g',\n",
    "    '22083': 'f',\n",
    "    '21996': '~', # ER -> ~\n",
    "    '22266': '~', # ER -> ~\n",
    "    '22330': '~', # ER -> ~\n",
    "    '21963': 'e',\n",
    "    '22059': 'E', # e -> E\n",
    "    '22269': 'E', # e -> E\n",
    "    '22345': 'E', # e -> E\n",
    "    '22131': 'TH', # DH -> TH\n",
    "    '22116': 'dd', # no change but what 'dd' means?\n",
    "    '21999': 'd',\n",
    "    '22104': 'tS', # CH -> tS\n",
    "    '22348': 'tS', # CH -> tS\n",
    "    '22119': 'b-a',\n",
    "    '22128': 'b-a',\n",
    "    '22011': 'b',    \n",
    "    '22056': '^', # AH -> ^\n",
    "    '22327': '^', # AH -> ^\n",
    "    '21975': '.', # AH -> .\n",
    "    '22272': '.', # AH -> .\n",
    "    '22324': '.', # AH -> .  \n",
    "    '21984': '@', # AE -> @\n",
    "    '21990': 'A', # a -> A\n",
    "    '22020': 'a',\n",
    "    '22257': 'A', # a -> A\n",
    "    '22336': 'A', # a -> A\n",
    "    '22041': 'u-~', # ~ -> u-~\n",
    "    '22002': ',', # ` -> , secondary stress\n",
    "    '21993': ':', # _ -> :\n",
    "    '22260': ':', # _ -> :\n",
    "    '21960': \"'\", # ^ -> ' primary stress\n",
    "    '22149': ';',\n",
    "    '21957': '/',\n",
    "    '21978': '', # , -> null\n",
    "    '21969': '#',\n",
    "    '21972': '#',\n",
    "    '21987': '#',\n",
    "    '22017': '#',\n",
    "    '22095': '#',\n",
    "    '22098': '#',\n",
    "    '22107': '#',\n",
    "    '22113': '#',\n",
    "    '22122': '#',\n",
    "    '22125': '#',\n",
    "    '22134': '#',\n",
    "    '22143': '#',\n",
    "    '22146': '#',\n",
    "    '22155': '#',\n",
    "    '22158': '#',\n",
    "    '22161': '#',\n",
    "    '22164': '#',\n",
    "    '22173': '#',\n",
    "    '22176': '#',\n",
    "    '22179': '#',\n",
    "    '22182': '#',\n",
    "    '22188': '#',\n",
    "    '22191': '#',\n",
    "    '22194': '#',\n",
    "    '22197': '#',\n",
    "    '22215': '#',\n",
    "    '22221': '#',\n",
    "    '22224': '#',\n",
    "    '22230': '#',\n",
    "    '22233': '#',\n",
    "    '22236': '#',\n",
    "    '22239': '#',\n",
    "    '22245': '#',\n",
    "    '22248': '#',\n",
    "    '22251': '#',\n",
    "    '22275': '#',\n",
    "    '22278': '#',\n",
    "    '22284': '#',\n",
    "    '22287': '#',\n",
    "    '22291': '#',\n",
    "    '22297': '#',\n",
    "    '22300': '#',\n",
    "    '22303': '#',\n",
    "    '22306': '#',\n",
    "    '22315': '#',\n",
    "    '22318': '#',\n",
    "    '22372': '#'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "onlyfiles = [ f for f in os.listdir(mypath) if isfile(join(mypath,f)) ]\n",
    "\n",
    "cnt = 0  #total words\n",
    "cnt_f = 0 #number of foreign words (French, Spanish)\n",
    "cnt_d = 0 #number of words beginning with a dash\n",
    "cnt_sq = 0 #number of words beginning with a single quote\n",
    "\n",
    "kk = 0\n",
    "for fname in onlyfiles:\n",
    "    jsonBody = {}\n",
    "    \n",
    "    if testflag == 0: fj = codecs.open('E:\\\\dictjson\\\\' + fname + '.json', 'w', 'utf-8')\n",
    "    #print fj\n",
    "    \n",
    "    with open(mypath + fname, 'r') as fentry:    \n",
    "    #with codecs.open('E:\\\\dictrawfile-39195\\\\' + fname, 'r', 'utf-8') as fentry: #don't work somehow\n",
    "        raw_doc = fentry.read()\n",
    "        fentry.close()\n",
    "    #fentry = open('declare.axb8472', 'r')\n",
    "    #hw_doc = fentry.read()\n",
    "        \n",
    "    \n",
    "    #get IPA symbols\n",
    "    #first find the pair of slashes used to mark the beginning and end of a pronunciation\n",
    "    #image21955.gif, image21956.gif, image21957.gif -- images of a slash '/'\n",
    "    patt = '<img hspace=\"0\" align=\"middle\" losrc=\"Images\\/image21955\\.gif\" src=\"Images\\/image21956\\.gif\" hisrc=\"Images\\/image21957\\.gif\"\\/>'\n",
    "    pattern = patt + '(.*?)' + patt\n",
    "    #print pattern\n",
    "    ipa = re.compile(pattern, re.DOTALL)\n",
    "\n",
    "    flag_brit = 0 #suppose there is no British pronunciation\n",
    "    my_pronun = []\n",
    "    for sounds in ipa.findall(raw_doc):\n",
    "        i = 0\n",
    "        for sound in sounds.split('<i>Brit</i>'):\n",
    "            i += 1\n",
    "            ipa_soup = BeautifulSoup(sound)\n",
    "            if i == 1: cmu = ''\n",
    "            elif i == 2: #'Brit'\n",
    "                flag_brit = 1 #there is British pronunciation\n",
    "                break #skip British pronunciation\n",
    "            for symbol in ipa_soup.find_all('img'):\n",
    "                key = symbol['hisrc'][12:-4]\n",
    "                if key in ipa_to_alpha: cmu += ipa_to_alpha[key]\n",
    "                else: cmu += key\n",
    "            #print cmu\n",
    "            #print \"---\\n\"   \n",
    "            my_pronun.append(cmu)\n",
    "    #print my_pronun\n",
    "    if my_pronun: jsonBody['prn'] = my_pronun\n",
    "    if flag_brit == 1: jsonBody['prn_brit'] = 'y'\n",
    "        \n",
    "    \n",
    "    #after getting IPA, remove all image tags    \n",
    "    hw_doc = re.sub(r\"(<img[^>]*\\/>)\", \"\", raw_doc)\n",
    "    #remove Unicode 'middle dot' u+00B7\n",
    "    hw_doc = re.sub(u\"\\u00B7\", \"\", hw_doc)\n",
    "    #print hw_doc\n",
    "    #continue\n",
    "    \n",
    "    #fentry.close() # move up\n",
    "\n",
    "    soup = BeautifulSoup(hw_doc)\n",
    "    \n",
    "    #get headword\n",
    "    headword = soup.find('idx:orth')\n",
    "    #if headword[0] == \"'\": headword = \"\\\\\" + headword\n",
    "    if headword: \n",
    "        hw = headword['value']\n",
    "        #jsonBody['hw'] = headword['value']\n",
    "        jsonBody['hw'] = hw\n",
    "        kk += 1\n",
    "        print kk, '---', jsonBody\n",
    "    else:\n",
    "        print fname, \": no headword\"\n",
    "        break\n",
    "        \n",
    "    \n",
    "    #check if it is in 3,000 basic English words by 'u' (not accurate when there's a usage section)    \n",
    "    basic_word = soup.find('u')\n",
    "    bwflag = 0\n",
    "    if basic_word and hw in bws:\n",
    "        bwflag = 1\n",
    "        #jsonBody['bw'] = 1    \n",
    "    #print jsonBody\n",
    "    \n",
    "\n",
    "    #special words\n",
    "    frflag = 0\n",
    "    dashflag = 0\n",
    "    squote = 0 \n",
    "    if fname[0] == '.':\n",
    "        cnt_f += 1\n",
    "        frflag = 1\n",
    "        #jsonBody[\"fr\"] = \"y\" #is it a foreign word? yes\n",
    "    elif fname[0] == '-':\n",
    "        cnt_d += 1\n",
    "        dashflag = 1\n",
    "        #jsonBody[\"dash\"] = \"y\" # begin with a dash\n",
    "    elif fname[0] == \"'\":\n",
    "        cnt_sq += 1\n",
    "        squote = 1\n",
    "        #jsonBody[\"sq\"] = \"y\" #begin with a single quote '\n",
    "    \n",
    "    \n",
    "    #get inflection\n",
    "    infl = []\n",
    "    for it in soup.find_all('idx:iform'):\n",
    "        infl.append(it['value'])\n",
    "        #print infl\n",
    "    if infl: jsonBody['infl'] = infl\n",
    "\n",
    "    #get id\n",
    "    aid = soup.find(a_has_id)\n",
    "    #print type(aid)\n",
    "    if aid: jsonBody['id'] = aid['id']\n",
    "\n",
    "    #get part of speech\n",
    "    #<i><font color=\"#999999\">noun</font></i>\n",
    "    pos = soup.find(color=\"#999999\")\n",
    "    if pos: jsonBody['pos'] = pos.get_text()\n",
    "\n",
    "        \n",
    "    # if headword in homograph list, generate \"homog\" key and value    \n",
    "    homogflag = 0\n",
    "    if hw in homogs:\n",
    "        print 'is a homograph'\n",
    "        homogflag = 1\n",
    "        jsonBody['homog'] = headword['value'] + \" \" + pos.get_text() # not to append suffix, may wav or mp3\n",
    " \n",
    "    # if head word is related to images\n",
    "    hwimg = []\n",
    "    hwimgtag = []\n",
    "    for imgSig in imgSingles:\n",
    "        if hw == imgSig.split('.')[0]:\n",
    "            hwimg.append(imgSig)\n",
    "            hwimgtag.append('imgmwl')\n",
    "            print hw, ' has a single image: ', imgSig\n",
    "    for imgGrp in imgGrps:\n",
    "        if hw in imgGrp['words']:\n",
    "            hwimg.append(imgGrp['img'])\n",
    "            hwimgtag.append('imgmwlG')          \n",
    "            print hw, ' has a group image: ', imgGrp['img']\n",
    "    if hwimg:\n",
    "        jsonBody['img'] = hwimg\n",
    "        \n",
    "        \n",
    "    #get labels\n",
    "    label = []\n",
    "    label = soup.find_all(text=labels)\n",
    "    #some labels are not captured in tags, so use regex to get them\n",
    "    if soup.find(text=re.compile(\"figuratively\")): label.append(\"figuratively\")\n",
    "    if soup.find(text=re.compile(\"informal\")): label.append(\"informal\")\n",
    "    #no 'see color picture' in mobi file\n",
    "    #if soup.find_all(text=re.compile(\"see color picture\")): label.append(\"color picture\")\n",
    "    if label: jsonBody['label'] = label\n",
    "\n",
    "    #get common phrases\n",
    "    cplist = []\n",
    "    for item in soup.find_all('span'):\n",
    "        if item.parent.name == 'font': cplist.append(item.get_text())\n",
    "    if cplist: jsonBody['cp'] = cplist\n",
    "\n",
    "    #get all example sentences\n",
    "    examples = []\n",
    "    for it in soup.find_all(color=\"#002984\"):\n",
    "        examples.append(it.get_text())\n",
    "    if examples:\n",
    "        jsonBody['alles'] = examples        \n",
    "\n",
    "        totales = len(examples)        \n",
    "\n",
    "        if totales >= 100: nes = \"100+\"\n",
    "        elif totales >= 50: nes = \"50-99\"\n",
    "        elif totales >= 10: nes = \"10-49\"\n",
    "        elif totales >=  3: nes = \"3-9\"\n",
    "        elif totales >=  2: nes = \"2\"\n",
    "        elif totales >=  1: nes = \"1\"\n",
    "    else: nes = \"0\"\n",
    "        \n",
    "        \n",
    "    #get all idioms & phrasal verbs, including common phrases\n",
    "    idpvs = []\n",
    "    #get sub head words\n",
    "    subhw = []\n",
    "    for item in soup.find_all('span'):\n",
    "        #print item.parent.name, \"---\", item.get_text()\n",
    "        if item.parent.name != 'idx:entry':\n",
    "            if ' ' in item.get_text(): idpvs.append(item.get_text())\n",
    "            else: subhw.append(item.get_text())\n",
    "#             elif item.get_text()[0] == hw[0]: \n",
    "#                 # check if the first letters of hw and subhw are same, good for revolt, but \n",
    "#  not good for 334 words like 20/20, twenty-twenty, impressionism and Impressionism\n",
    "#                 subhw.append(item.get_text())\n",
    "    if idpvs: jsonBody['idpvs'] = idpvs\n",
    "    if subhw: jsonBody['subhw'] = subhw\n",
    "                \n",
    "\n",
    "    #check if head word or sub head words are in some topic word lists\n",
    "    tag = []\n",
    "    tag.append('mwl')\n",
    "    tag.append('es' + nes)    \n",
    "    for topic in topics:\n",
    "        if hw in topic['words']: tag.append(topic['topic'])\n",
    "    if homogflag == 1: tag.append('homog')\n",
    "    if bwflag == 1: tag.append('bw2939')\n",
    "    if frflag == 1: tag.append('fr')\n",
    "    if dashflag == 1: tag.append('dash')\n",
    "    if squote == 1: tag.append('squote')\n",
    "    if hwimgtag: tag += hwimgtag\n",
    "            \n",
    "# only check word in hw, don't check in subhw\n",
    "# will use mwaled77 to get a word's head word which is used to check what tags are.\n",
    "#         elif subhw:\n",
    "#             for csubhw in subhw:\n",
    "#                 if csubhw in topic['words']: tag.append(topic['topic'])\n",
    "    if tag: jsonBody['tag'] = tag\n",
    "        \n",
    "                \n",
    "    #get cross references\n",
    "    cr = {}\n",
    "    for link in soup.find_all(a_has_href):\n",
    "        if link: cr[link.get('href').replace('#','')] = link.get_text().strip()\n",
    "    if cr: jsonBody['cr'] = cr\n",
    "\n",
    "        \n",
    "    #construct definitions & examples\n",
    "    sublist = []\n",
    "    i = 1 #cross reference counter\n",
    "    \n",
    "    # remove j that is not necessary\n",
    "    #j = 1 #idioms & phrasal verbs counter \n",
    "\n",
    "    for it in soup.find_all('blockquote'):\n",
    "        #print it.parent.parent.name, \">>\", it.parent.name, \"---\", it, \"\\n\"\n",
    "        if(it.parent.name=='idx:entry'):\n",
    "            examp = []\n",
    "            defi = it.get_text()\n",
    "            if defi==\" \": continue\n",
    "            for e in it.find_all(color=\"#002984\"):\n",
    "                examp.append(e.get_text())\n",
    "                defi = defi.replace(e.get_text(),\"\")\n",
    "            #print defi\n",
    "            #print examp\n",
    "\n",
    "            subentry = {}\n",
    "            # def is a key word of Python\n",
    "            subentry['defi'] = defi\n",
    "            subentry['es'] = examp\n",
    "            #print subentry\n",
    "            #print sublist                \n",
    "\n",
    "            if subentry: sublist.append(subentry)\n",
    "        \n",
    "        #idioms & phrasal verbs\n",
    "        if(it.parent.name=='div' and it.parent.parent.name!='blockquote'):\n",
    "            subentry = {}\n",
    "            \n",
    "            #just use 'idpv' as key\n",
    "            subentry['idpv'] = it.get_text()\n",
    "            #subentry['idpv'+str(j)] = it.get_text()\n",
    "            #j += 1\n",
    " \n",
    "            #print subentry\n",
    "            if subentry: sublist.append(subentry)\n",
    "\n",
    "            \n",
    "    if sublist: jsonBody['sublist'] = sublist\n",
    "    if jsonBody:\n",
    "        #print jsonBody\n",
    "        cnt += 1\n",
    "        \n",
    "        #dump json into a file\n",
    "        if testflag == 0: json.dump(jsonBody, fj, indent=4, sort_keys=True)\n",
    "        \n",
    "        # insert into MongoDB database\n",
    "        doc_id = geweiDict.insert(jsonBody)\n",
    "        #print doc_id \n",
    "        if testflag == 0: shutil.move(mypath + fname, \"E:\\\\dictprocessed\\\\\"+fname)\n",
    "    if testflag == 0: fj.close()\n",
    "\n",
    "print 'total words: ', cnt, ', French words: ', cnt_f, \", begin with a dash:\", cnt_d, \", begin with a ': \", cnt_sq\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "ta = \"a, b, c\"\n",
    "tb = 'dd'\n",
    "print ta.split(',')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acaWriting.txt', 'airTravel.txt', 'bodyPart.txt', 'campus.txt', 'economics.txt', 'emotion.txt', 'employment.txt', 'environment.txt', 'family.txt', 'health.txt', 'job.txt', 'legal.txt', 'list.txt', 'nonCount.txt', 'personality.txt', 'sport.txt', 'timeAdv.txt', 'timePeriod.txt', 'weather.txt']\n"
     ]
    }
   ],
   "source": [
    "with open('core3000\\\\topic.txt', 'r') as f:\n",
    "    lines = f.read().splitlines()\n",
    "print lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "914\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "\n",
    "tfiles = ['acaWriting.txt', 'airTravel.txt', 'bodyPart.txt', 'campus.txt', 'economics.txt', 'emotion.txt', \n",
    "          'employment.txt', 'environment.txt', 'family.txt', 'health.txt', 'job.txt', 'legal.txt', \n",
    "          'nonCount.txt', 'personality.txt', 'sport.txt', 'timeAdv.txt', 'timePeriod.txt', 'weather.txt']\n",
    "topics = []\n",
    "cnt = 0\n",
    "for tfile in tfiles:\n",
    "    topic = {}\n",
    "    with codecs.open('core3000\\\\' + tfile, 'r', 'utf-8') as f:\n",
    "        twords = f.read().splitlines()\n",
    "        cnt += len(twords)\n",
    "        f.close()\n",
    "    topic['words'] = twords\n",
    "    topic['topic'] = tfile.split('.')[0]\n",
    "    topics.append(topic)\n",
    "#print topics    \n",
    "print cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "fcore = codecs.open('core3000\\\\core3140.txt', 'w', 'utf-8')\n",
    "with codecs.open('core3000\\\\core3000raw20151123.txt', 'r', 'utf-8') as f:\n",
    "    lines = f.read().splitlines()\n",
    "\n",
    "cnt = 0    \n",
    "uCore = set()\n",
    "\n",
    "for line in lines:    \n",
    "    uCore.add(line.split('\\t')[0])\n",
    "uCoreSorted = sorted(uCore)    \n",
    "for word in uCoreSorted:\n",
    "    cnt += 1\n",
    "    fcore.write(word+'\\n')\n",
    "    #print cnt, ': ', word\n",
    "fcore.close()    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'decompose'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a6d700773372>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecompose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'decompose'"
     ]
    }
   ],
   "source": [
    "print(soup.img.decompose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpdict.find({\"label\":\"mathematics\"}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpdict.find({\"label\":\"slang\"}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpdict.find({\"label\":\"offensive\"}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "807"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpdict.find({\"label\":\"chiefly US\"}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2615"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpdict.find({\"label\":\"Brit\"}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2027"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.dpdict.find({\"label\":\"US\"}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-208-11f5d97b9c3b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-208-11f5d97b9c3b>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    db.dpdict.find({cp: {$exists: true}}).count()\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "db.dpdict.find({cp: {$exists: true}}).count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': ObjectId('537e93cd8707ee3128063ada'),\n",
       " u'alles': [u'I saw your doppelg\\xe4nger [=(more commonly) double] yesterday.',\n",
       "  u'In the story, the character is haunted by a doppelg\\xe4nger.'],\n",
       " u'fr': u'y',\n",
       " u'hw': u'doppelg\\xe4nger',\n",
       " u'idpvs': [u'dop\\xb7pel\\xb7gang\\xb7er'],\n",
       " u'infl': {u'1np1': u'doppelg\\xe4ngers', u'1ns1': u'doppelg\\xe4nger'},\n",
       " u'label': [u'literary'],\n",
       " u'pos': u'or',\n",
       " u'sublist': [{u'def': u'1 : someone who looks like someone else  ',\n",
       "   u'es': [u'I saw your doppelg\\xe4nger [=(more commonly) double] yesterday.']},\n",
       "  {u'def': u'2 literary : a ghost that looks like a living person ',\n",
       "   u'es': [u'In the story, the character is haunted by a doppelg\\xe4nger.']}]}"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpdict.find_one({'hw': u'doppelg\\xe4nger'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.cursor.Cursor at 0x7993630>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpdict.find({\"id\":\"filepos18005907\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<img hspace=\"0\" align=\"middle\" losrc=\"Images\\/image21955\\.gif\" src=\"Images\\/image21956\\.gif\" hisrc=\"Images\\/image21957\\.gif\"\\/>(.*?)<img hspace=\"0\" align=\"middle\" losrc=\"Images\\/image21955\\.gif\" src=\"Images\\/image21956\\.gif\" hisrc=\"Images\\/image21957\\.gif\"\\/>\n",
      "---\n",
      "\n",
      "Images/image21960.gif\n",
      "Images/image22005.gif\n",
      "Images/image21984.gif\n",
      "Images/image22014.gif\n",
      "Images/image22038.gif\n",
      "Images/image21978.gif\n",
      "---\n",
      "\n",
      "Images/image21960.gif\n",
      "Images/image22005.gif\n",
      "Images/image21990.gif\n",
      "Images/image21993.gif\n",
      "Images/image22014.gif\n",
      "Images/image22038.gif\n",
      "---\n",
      "\n",
      "Images/image21960.gif\n",
      "Images/image22005.gif\n",
      "Images/image21984.gif\n",
      "Images/image22014.gif\n",
      "Images/image22038.gif\n",
      "Images/image21981.gif\n",
      "Images/image21975.gif\n",
      "Images/image22014.gif\n",
      "Images/image21978.gif\n",
      "---\n",
      "\n",
      "Images/image21960.gif\n",
      "Images/image22005.gif\n",
      "Images/image21990.gif\n",
      "Images/image21993.gif\n",
      "Images/image22014.gif\n",
      "Images/image22038.gif\n",
      "Images/image21981.gif\n",
      "Images/image21975.gif\n",
      "Images/image22014.gif\n"
     ]
    }
   ],
   "source": [
    "comment = re.compile(r'/\\*(.*?)\\*/', re.DOTALL)\n",
    "patt = '<img hspace=\"0\" align=\"middle\" losrc=\"Images\\/image21955\\.gif\" src=\"Images\\/image21956\\.gif\" hisrc=\"Images\\/image21957\\.gif\"\\/>'\n",
    "pattern = patt + '(.*?)' + patt\n",
    "print pattern\n",
    "ipa = re.compile(pattern, re.DOTALL)\n",
    "text1 = '/* this is a comment */'\n",
    "text2 = '''/* this is a\n",
    "        multiline comment */\n",
    "        '''\n",
    "text3 = '''<idx:entry scriptable=\"yes\"><idx:orth value=\"vast\"><idx:infl>  <idx:iform name=\"1.adj.pos.1\" value=\"vast\"/></idx:infl><idx:infl>  <idx:iform name=\"2.n.s.1\" value=\"vast\"/>  <idx:iform name=\"2.n.p.1\" value=\"vasts\"/></idx:infl></idx:orth><a id=\"filepos83514877\" /><span><font size=\"3\"><b><u>vast</u></span> <img hspace=\"0\" align=\"middle\" losrc=\"Images/image21955.gif\" src=\"Images/image21956.gif\" hisrc=\"Images/image21957.gif\"/><img hspace=\"0\" align=\"middle\" losrc=\"Images/image21958.gif\" src=\"Images/image21959.gif\" hisrc=\"Images/image21960.gif\"/><img hspace=\"0\" align=\"middle\" losrc=\"Images/image22003.gif\" src=\"Images/image22004.gif\" hisrc=\"Images/image22005.gif\"/><img hspace=\"0\" align=\"middle\" losrc=\"Images/image21982.gif\" src=\"Images/image21983.gif\" hisrc=\"Images/image21984.gif\"/><img hspace=\"0\" align=\"middle\" losrc=\"Images/image22012.gif\" src=\"Images/image22013.gif\" hisrc=\"Images/image22014.gif\"/><img hspace=\"0\" align=\"middle\" losrc=\"Images/image22036.gif\" src=\"Images/image22037.gif\" hisrc=\"Images/image22038.gif\"/><img hspace=\"0\" align=\"middle\" losrc=\"Images/image21976.gif\" src=\"Images/image21977.gif\" hisrc=\"Images/image21978.gif\"/> <i>Brit</i> <img hspace=\"0\" align=\"middle\" losrc=\"Images/image21958.gif\" src=\"Images/image21959.gif\" hisrc=\"Images/image21960.gif\"/><img hspace=\"0\" align=\"middle\" losrc=\"Images/image22003.gif\" src=\"Images/image22004.gif\" hisrc=\"Images/image22005.gif\"/><img hspace=\"0\" align=\"middle\" losrc=\"Images/image21988.gif\" src=\"Images/image21989.gif\" hisrc=\"Images/image21990.gif\"/><img hspace=\"0\" align=\"middle\" losrc=\"Images/image21991.gif\" src=\"Images/image21992.gif\" hisrc=\"Images/image21993.gif\"/><img hspace=\"0\" align=\"middle\" losrc=\"Images/image22012.gif\" src=\"Images/image22013.gif\" hisrc=\"Images/image22014.gif\"/><img hspace=\"0\" align=\"middle\" losrc=\"Images/image22036.gif\" src=\"Images/image22037.gif\" hisrc=\"Images/image22038.gif\"/><img hspace=\"0\" align=\"middle\" losrc=\"Images/image21955.gif\" src=\"Images/image21956.gif\" hisrc=\"Images/image21957.gif\"/> <i><font color=\"#999999\">adj</font></i>, <b>vastÁ©çr</b>, <b>-est</b> [<i>more <img hspace=\"0\" align=\"middle\" losrc=\"Images/image22039.gif\" src=\"Images/image22040.gif\" hisrc=\"Images/image22041.gif\"/>; most <img hspace=\"0\" align=\"middle\" losrc=\"Images/image22039.gif\" src=\"Images/image22040.gif\" hisrc=\"Images/image22041.gif\"/></i>]<blockquote align=\"left\"> <b>:</b> very great in size, amount, or extent <blockquote align=\"left\"><font color=\"#002984\">She has a <i>vast</i> amount of knowledge on this subject.</font></blockquote> <blockquote align=\"left\"><font color=\"#002984\"><i>vast</i> quantities of information</font></blockquote> <blockquote align=\"left\"><font color=\"#002984\">The policy is supported by the <i>vast</i> majority of citizens.</font></blockquote> <blockquote align=\"left\"><font color=\"#002984\">a <i>vast</i> expanse of land</font></blockquote></blockquote> <img hspace=\"0\" vspace=\"0\" align=\"middle\" src=\"Images/image21970.gif\"/><div align=\"left\"><blockquote><span><font size=\"3\"><b>vastÁ©ïy</span> <i><font color=\"#999999\">adv</font></i> <blockquote><font color=\"#002984\">His background is <i>vastly</i> different from mine.</font></blockquote> <blockquote><font color=\"#002984\">They <i>vastly</i> increased spending.</font></blockquote></blockquote> </div>\n",
    "\n",
    "<img hspace=\"0\" vspace=\"0\" align=\"middle\" src=\"Images/image21970.gif\"/><div align=\"left\"><blockquote><span><font size=\"3\"><b>vastÁ©òess</span> \n",
    "\n",
    "<img hspace=\"0\" align=\"middle\" losrc=\"Images/image21955.gif\" src=\"Images/image21956.gif\" hisrc=\"Images/image21957.gif\"/>\n",
    "<img hspace=\"0\" align=\"middle\" losrc=\"Images/image21958.gif\" src=\"Images/image21959.gif\" hisrc=\"Images/image21960.gif\"/>\n",
    "<img hspace=\"0\" align=\"middle\" losrc=\"Images/image22003.gif\" src=\"Images/image22004.gif\" hisrc=\"Images/image22005.gif\"/>\n",
    "<img hspace=\"0\" align=\"middle\" losrc=\"Images/image21982.gif\" src=\"Images/image21983.gif\" hisrc=\"Images/image21984.gif\"/>\n",
    "<img hspace=\"0\" align=\"middle\" losrc=\"Images/image22012.gif\" src=\"Images/image22013.gif\" hisrc=\"Images/image22014.gif\"/>\n",
    "<img hspace=\"0\" align=\"middle\" losrc=\"Images/image22036.gif\" src=\"Images/image22037.gif\" hisrc=\"Images/image22038.gif\"/>\n",
    "<img hspace=\"0\" align=\"middle\" losrc=\"Images/image21979.gif\" src=\"Images/image21980.gif\" hisrc=\"Images/image21981.gif\"/>\n",
    "<img hspace=\"0\" align=\"middle\" losrc=\"Images/image21973.gif\" src=\"Images/image21974.gif\" hisrc=\"Images/image21975.gif\"/>\n",
    "<img hspace=\"0\" align=\"middle\" losrc=\"Images/image22012.gif\" src=\"Images/image22013.gif\" hisrc=\"Images/image22014.gif\"/>\n",
    "<img hspace=\"0\" align=\"middle\" losrc=\"Images/image21976.gif\" src=\"Images/image21977.gif\" hisrc=\"Images/image21978.gif\"/>\n",
    " <i>Brit</i> \n",
    " <img hspace=\"0\" align=\"middle\" losrc=\"Images/image21958.gif\" src=\"Images/image21959.gif\" hisrc=\"Images/image21960.gif\"/>\n",
    " <img hspace=\"0\" align=\"middle\" losrc=\"Images/image22003.gif\" src=\"Images/image22004.gif\" hisrc=\"Images/image22005.gif\"/>\n",
    " <img hspace=\"0\" align=\"middle\" losrc=\"Images/image21988.gif\" src=\"Images/image21989.gif\" hisrc=\"Images/image21990.gif\"/>\n",
    " <img hspace=\"0\" align=\"middle\" losrc=\"Images/image21991.gif\" src=\"Images/image21992.gif\" hisrc=\"Images/image21993.gif\"/>\n",
    " <img hspace=\"0\" align=\"middle\" losrc=\"Images/image22012.gif\" src=\"Images/image22013.gif\" hisrc=\"Images/image22014.gif\"/>\n",
    " <img hspace=\"0\" align=\"middle\" losrc=\"Images/image22036.gif\" src=\"Images/image22037.gif\" hisrc=\"Images/image22038.gif\"/>\n",
    " <img hspace=\"0\" align=\"middle\" losrc=\"Images/image21979.gif\" src=\"Images/image21980.gif\" hisrc=\"Images/image21981.gif\"/>\n",
    " <img hspace=\"0\" align=\"middle\" losrc=\"Images/image21973.gif\" src=\"Images/image21974.gif\" hisrc=\"Images/image21975.gif\"/>\n",
    " <img hspace=\"0\" align=\"middle\" losrc=\"Images/image22012.gif\" src=\"Images/image22013.gif\" hisrc=\"Images/image22014.gif\"/>\n",
    "<img hspace=\"0\" align=\"middle\" losrc=\"Images/image21955.gif\" src=\"Images/image21956.gif\" hisrc=\"Images/image21957.gif\"/> \n",
    "\n",
    "\n",
    "<i><font color=\"#999999\">noun</font></i> [<i>noncount</i>] <blockquote><font color=\"#002984\">the <i>vastness</i> of the desert/ocean</font></blockquote></blockquote></div></idx:entry><div><img hspace=\"0\" vspace=\"0\" align=\"middle\" src=\"Images/image21971.gif\"/></div><div><table width=\"100%\" bgcolor=\"#7593CD\"><tr><th widht=\"100%\" height=\"2px\"/></tr></table></div><div><img hspace=\"0\" vspace=\"0\" align=\"middle\" src=\"Images/image21972.gif\"/></div> \n",
    " \n",
    " '''\n",
    "#comment.findall(text1)\n",
    "#comment.findall(text2)\n",
    "for sounds in ipa.findall(text3):\n",
    "    for sound in sounds.split('<i>Brit</i>'):\n",
    "        print \"---\\n\"\n",
    "        soup = BeautifulSoup(sound)\n",
    "        for symbol in soup.find_all('img'):\n",
    "            print symbol['hisrc']\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vowels\n",
    "\n",
    "@  √¶ ask bat glad\n",
    "\n",
    "a:   …ë: cot bomb caught paw\n",
    "\n",
    "e    …õ bet fed\n",
    "\n",
    ".    …ô about banana collide\n",
    "\n",
    "i  i very any thirty\n",
    "\n",
    "i:   i: eat bead bee\n",
    "\n",
    "!    …™ id bid pit\n",
    "\n",
    "u    ä foot should put\n",
    "\n",
    "u:  u: boot two coo\n",
    "\n",
    "^    å under putt bud\n",
    "\n",
    "~   …ö merge bird further\n",
    "\n",
    "ei   e…™ eight wade bay\n",
    "\n",
    "ai   a…™ ice bite tie\n",
    "\n",
    "au   a ä out gown plow\n",
    "\n",
    "oi    o…™ oyster coil boy\n",
    "\n",
    "ou   o ä oat own zone blow\n",
    "\n",
    "a~  …ë…ö car heart bizarre\n",
    "\n",
    "e~  e…ö bare fair wear\n",
    "\n",
    "i~   i…ö near deer mere pier\n",
    "\n",
    "o~   o…ö boar port door shore\n",
    "\n",
    "u~   u…ö boor tour insure\n",
    "\n",
    "\n",
    "Consonants\n",
    "\n",
    "b   b baby labor cab\n",
    "\n",
    "d   d day kid\n",
    "\n",
    "dZ    § just badger fudge\n",
    "\n",
    "TH  √∞ then either bathe\n",
    "\n",
    "f   f foe tough buff\n",
    "\n",
    "g   g go dagger bag\n",
    "\n",
    "h   h hot ahead\n",
    "\n",
    "j   j yes vineyard\n",
    "\n",
    "k   k lacquer flock skin\n",
    "\n",
    "l   l law hollow\n",
    "\n",
    "l-   lÃü pedal battle final\n",
    "\n",
    "m   m mat hemp hammer rim\n",
    "\n",
    "n   n new tent tenor run\n",
    "\n",
    "n-   nÃ© button satin kitten\n",
    "\n",
    "N   ≈ã rung hang swinger\n",
    "\n",
    "p   p lapse top lip speed\n",
    "\n",
    "r   r rope arrive\n",
    "\n",
    "s   s sad mist kiss\n",
    "\n",
    "S    É shoe mission slush\n",
    "\n",
    "t   t mat stick late\n",
    "\n",
    "(t ∞ toe attack)\n",
    "\n",
    "(…æ later catty riddle)\n",
    "\n",
    "tS   t É batch nature\n",
    "\n",
    "(t É ∞ choose chin achieve)\n",
    "\n",
    "th   Œ∏ thin ether bath\n",
    "\n",
    "v   v vat never cave\n",
    "\n",
    "w   w wet software\n",
    "\n",
    "z   z zoo easy buzz\n",
    "\n",
    "Z    í vision azure beige\n",
    "\n",
    "Other Symbols\n",
    "\n",
    "'   ' penmanship\n",
    ",  Àå penmanship\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "#connect to MongoDB\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client.dpdb\n",
    "dpdict = db.dpdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'His outburst seemed incongruous to those who know him well.', u'The style of the porch is incongruous with [=does not match] the style of the house overall.', u'The modern sculpture seems incongruous [=out of place] among all the antiques.']\n",
      "[{u'def': u' : strange because of not agreeing with what is usual or expected   ', u'es': [u'His outburst seemed incongruous to those who know him well.', u'The style of the porch is incongruous with [=does not match] the style of the house overall.', u'The modern sculpture seems incongruous [=out of place] among all the antiques.']}, {u'idpv1': u'in\\xb7con\\xb7gru\\xb7i\\xb7ty noun, pl -ties [count, noncount]'}, {u'idpv2': u'in\\xb7con\\xb7gru\\xb7ous\\xb7ly adv'}]\n"
     ]
    }
   ],
   "source": [
    "words = dpdict.find({\"hw\":\"incongruous\"})\n",
    "for word in words:\n",
    "    print word.get(\"alles\")\n",
    "    print word.get(\"sublist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
