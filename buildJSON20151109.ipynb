{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\dictrawfile-39195\n",
      "1 --- {'prn': [\"'kA:zk.z\"], 'hw': \"'cause\"}\n",
      "2 --- {'prn': ['.dtd;d'], 'hw': \"'d\"}\n",
      "3 --- {'prn': ['.m'], 'hw': \"'em\"}\n",
      "4 --- {'hw': \"'ll\"}\n",
      "5 --- {'prn': ['.nn-'], 'hw': \"'n'\"}\n",
      "6 --- {'prn': [\"'ni:th\"], 'hw': \"'neath\"}\n",
      "7 --- {'prn': ['sptkfth;.zszSZtSdZ;z'], 'hw': \"'s\"}\n",
      "8 --- {'hw': \"'til\"}\n",
      "9 --- {'prn': [\"'t!zt.z\"], 'hw': \"'tis\"}\n",
      "10 --- {'prn': [\"'tw^z\"], 'hw': \"'twas\"}\n",
      "11 --- {'prn': ['v.v'], 'hw': \"'ve\"}\n",
      "12 --- {'prn': ['sptkfth;.zszSZtSdZ;z'], 'hw': \"-'s\"}\n",
      "13 --- {'hw': '-ability'}\n",
      "14 --- {'hw': '-able'}\n",
      "15 --- {'prn': ['!dZ'], 'hw': '-age'}\n",
      "16 --- {'hw': '-al'}\n",
      "17 --- {'hw': '-al'}\n",
      "18 --- {'hw': '-an'}\n",
      "19 --- {'hw': '-an'}\n",
      "20 --- {'prn': ['.ns'], 'hw': '-ance'}\n",
      "21 --- {'prn': ['.nsi'], 'hw': '-ancy'}\n",
      "22 --- {'prn': ['.nt'], 'hw': '-ant'}\n",
      "23 --- {'hw': '-ant'}\n",
      "24 --- {'prn': ['~'], 'hw': '-ar'}\n",
      "25 --- {'hw': '-ary'}\n",
      "26 --- {'hw': '-ary'}\n",
      "27 --- {'hw': '-ation'}\n",
      "28 --- {'hw': '-ative'}\n",
      "29 --- {'hw': '-backed'}\n",
      "30 --- {'prn': [\"'sEntr!k\"], 'hw': '-centric'}\n",
      "31 --- {'prn': ['si'], 'hw': '-cy'}\n",
      "32 --- {'prn': ['d.m'], 'hw': '-dom'}\n",
      "33 --- {'hw': '-ean'}\n",
      "34 --- {'prn': ['.d!dtd;tpktSfthsS;d;'], 'hw': '-ed'}\n",
      "35 --- {'prn': ['i'], 'hw': '-ee'}\n",
      "36 --- {'prn': ['i~'], 'hw': '-eer'}\n",
      "37 --- {'prn': ['.n'], 'hw': '-en'}\n",
      "38 --- {'hw': '-en'}\n",
      "39 --- {'prn': ['.ns'], 'hw': '-ence'}\n",
      "40 --- {'prn': ['.nsi'], 'hw': '-ency'}\n",
      "41 --- {'prn': ['~'], 'hw': '-er'}\n",
      "42 --- {'prn': ['~', 'i~j~', 'j~'], 'hw': '-er'}\n",
      "43 --- {'prn': ['.ri'], 'hw': '-ery'}\n",
      "44 --- {'prn': ['.z!zszStS;zv'], 'hw': '-es'}\n",
      "45 --- {'hw': '-es'}\n",
      "46 --- {'prn': ['.st!st'], 'hw': '-est'}\n",
      "47 --- {'hw': '-eth'}\n",
      "48 --- {'hw': '-ette'}\n",
      "49 --- {'hw': '-ey'}\n",
      "50 --- {'prn': [',fe!st'], 'hw': '-faced'}\n",
      "51 --- {'prn': [',faj~d'], 'hw': '-fired'}\n",
      "52 --- {'prn': [',foUld'], 'hw': '-fold'}\n",
      "53 --- {'prn': ['f.l'], 'hw': '-ful'}\n",
      "54 --- {'prn': ['fUl'], 'hw': '-ful'}\n",
      "55 --- {'prn': ['fa!'], 'hw': '-fy'}\n",
      "56 --- {'hw': '-goer'}\n",
      "57 --- {'hw': '-going'}\n",
      "58 --- {'prn_brit': 'y', 'prn': [',gr@f'], 'hw': '-graph'}\n",
      "59 --- {'prn': ['gr.fi'], 'hw': '-graphy'}\n",
      "60 --- {'prn': ['#,hUd'], 'hw': '-hood'}\n",
      "61 --- {'hw': '-ian'}\n",
      "62 --- {'hw': '-ibility'}\n",
      "63 --- {'hw': '-ible'}\n",
      "64 --- {'prn': ['!k'], 'hw': '-ic'}\n",
      "65 --- {'hw': '-ic'}\n",
      "66 --- {'prn': ['!k.l'], 'hw': '-ical'}\n",
      "67 --- {'prn': ['!ks'], 'hw': '-ics'}\n",
      "68 --- {'prn': ['a!d'], 'hw': '-ide'}\n",
      "69 --- {'prn': ['i'], 'hw': '-ie'}\n",
      "70 --- {'hw': '-ier'}\n",
      "71 --- {'prn': ['.,fa!'], 'hw': '-ify'}\n",
      "72 --- {'prn': ['!N!n'], 'hw': '-ing'}\n",
      "73 --- {'hw': '-ing'}\n",
      "74 --- {'hw': '-ion'}\n",
      "75 --- {'hw': '-ise'}\n",
      "76 --- {'hw': '-ish'}\n",
      "77 --- {'prn': ['!z.m'], 'hw': '-ism'}\n",
      "78 --- {'prn': ['!st'], 'hw': '-ist'}\n",
      "79 --- {'hw': '-ist'}\n",
      "80 --- {'prn': ['!st!k', '!st!k.l'], 'hw': '-istic'}\n",
      "81 --- {'prn': ['a!t'], 'hw': '-ite'}\n",
      "82 --- {'prn': ['a!t.s'], 'hw': '-itis'}\n",
      "83 --- {'prn': ['.ti'], 'hw': '-ity'}\n",
      "84 --- {'prn': ['!v'], 'hw': '-ive'}\n",
      "85 --- {'prn': ['a!z'], 'hw': '-ize'}\n",
      "86 --- {'prn': ['l.s'], 'hw': '-less'}\n",
      "87 --- {'prn': ['l.t'], 'hw': '-let'}\n",
      "88 --- {'prn': [',la!k'], 'hw': '-like'}\n",
      "89 --- {'prn': ['l!N'], 'hw': '-ling'}\n",
      "90 --- {'prn': [',l!vd'], 'hw': '-lived'}\n",
      "91 --- {'hw': '-logy'}\n",
      "92 --- {'prn': ['li'], 'hw': '-ly'}\n",
      "93 --- {'hw': '-ly'}\n",
      "94 --- {'prn': ['m.nt'], 'hw': '-ment'}\n",
      "95 --- {'hw': '-meter'}\n",
      "96 --- {'prn': ['moUst'], 'hw': '-most'}\n",
      "97 --- {'prn': [',maUTHd'], 'hw': '-mouthed'}\n",
      "98 --- {'hw': '-nd'}\n",
      "99 --- {'prn': ['n.s'], 'hw': '-ness'}\n",
      "100 --- {'prn': ['#,n!k'], 'hw': '-nik'}\n",
      "101 --- {'prn': ['~'], 'hw': '-or'}\n",
      "102 --- {'hw': '-ory'}\n",
      "103 --- {'hw': '-ory'}\n",
      "104 --- {'prn': ['.s'], 'hw': '-ous'}\n",
      "105 --- {'prn': [',faj.l'], 'hw': '-phile'}\n",
      "106 --- {'prn': [\"'f!lij.\"], 'hw': '-philia'}\n",
      "107 --- {'prn': [',foUb'], 'hw': '-phobe'}\n",
      "108 --- {'prn': [\"'foUbij.\"], 'hw': '-phobia'}\n",
      "109 --- {'prn': [\"'foUb!k\"], 'hw': '-phobic'}\n",
      "110 --- {'prn': [',foUn'], 'hw': '-phone'}\n",
      "111 --- {'prn': [',pu:'], 'hw': '-poo'}\n",
      "112 --- {'hw': '-rd'}\n",
      "113 --- {'hw': '-ry'}\n",
      "114 --- {'hw': '-s'}\n",
      "115 --- {'hw': '-s'}\n",
      "116 --- {'prn': [',S!p'], 'hw': '-ship'}\n",
      "117 --- {'prn': [',SoUld~d'], 'hw': '-shouldered'}\n",
      "118 --- {'prn': ['s.m'], 'hw': '-some'}\n",
      "119 --- {'hw': '-some'}\n",
      "120 --- {'prn': [',spi:k'], 'hw': '-speak'}\n",
      "121 --- {'hw': '-st'}\n",
      "122 --- {'prn': ['st~'], 'hw': '-ster'}\n",
      "123 --- {'hw': '-th'}\n",
      "124 --- {'prn': [\"'toUd\"], 'hw': '-toed'}\n",
      "125 --- {'hw': '-ure'}\n",
      "126 --- {'prn': ['w~d', 'w~dz'], 'hw': '-ward'}\n",
      "127 --- {'hw': '-ward'}\n",
      "128 --- {'prn': [',wa!z'], 'hw': '-wise'}\n",
      "129 --- {'prn': ['i'], 'hw': '-y'}\n",
      "130 --- {'prn': ['i'], 'hw': '-y'}\n",
      "131 --- {'hw': '-y'}\n",
      "132 --- {'hw': '-yer'}\n",
      "133 --- {'prn': [\"i'kle~\"], 'hw': u'\\xe9clair'}\n",
      "134 --- {'prn': [\"e!'lA:n\"], 'hw': u'\\xe9lan'}\n",
      "135 --- {'prn': [\"El'ni:nyoU\"], 'hw': u'El Ni\\xf1o'}\n",
      "136 --- {'prn': [\"'Em!,gre!\"], 'hw': u'\\xe9migr\\xe9'}\n",
      "137 --- {'prn': [\"'A:n,tre!\"], 'hw': u'entr\\xe9e'}\n",
      "138 --- {'prn_brit': 'y', 'prn': [\",EkspoU'ze!\"], 'hw': u'expos\\xe9'}\n",
      "139 --- {'prn': [\",fi:,A:n'se!fi'A:n,se!\"], 'hw': u'fianc\\xe9'}\n",
      "140 --- {'prn': [\",fi:,A:n'se!fi'A:n,se!\"], 'hw': u'fianc\\xe9e'}\n",
      "141 --- {'prn': [\"flAm'be!\"], 'hw': u'flamb\\xe9'}\n",
      "142 --- {'prn_brit': 'y', 'prn': [\",@pl.'ke!\"], 'hw': u'appliqu\\xe9'}\n",
      "143 --- {'hw': u'fra\\xeeche'}\n",
      "144 --- {'prn': [\",A:,pre!'ski:\"], 'hw': u'apr\\xe8s-ski'}\n",
      "145 --- {'prn': [\"gru'je~\"], 'hw': u'Gruy\\xe8re'}\n",
      "146 --- {'prn': [\"h.'b!tS.,we!\"], 'hw': u'habitu\\xe9'}\n",
      "147 --- {'prn_brit': 'y', 'prn': [\",@t.'Se!\"], 'hw': u'attach\\xe9'}\n",
      "148 --- {'hw': u'attach\\xe9 case'}\n",
      "149 --- {'prn': [\",hA:l.'pe!njoU\"], 'hw': u'jalape\\xf1o'}\n",
      "150 --- {'prn': [\"lA'me!\"], 'hw': u'lam\\xe9'}\n",
      "151 --- {'prn': [\"'m@kr.,me!\"], 'hw': u'macram\\xe9'}\n",
      "152 --- {'prn_brit': 'y', 'prn': [\"mAn'ke!\"], 'hw': u'manqu\\xe9'}\n",
      "153 --- {'prn': [\"m.,tiri'El\"], 'hw': u'mat\\xe9riel'}\n",
      "154 --- {'prn': [\"me!'lA:ndZ\"], 'hw': u'm\\xe9lange'}\n",
      "155 --- {'prn': [\"me!'nA:ZA'trwA:\", \"me!'nA:ZA'trwA:\"], 'hw': u'm\\xe9nage \\xe0 trois'}\n",
      "156 --- {'prn': [\"'mE,tje!\"], 'hw': u'm\\xe9tier'}\n",
      "157 --- {'prn': [\"'ne!\"], 'hw': u'n\\xe9e'}\n",
      "158 --- {'prn_brit': 'y', 'prn': [\"u'tre!\"], 'hw': u'outr\\xe9'}\n",
      "159 --- {'prn_brit': 'y', 'prn': [\",pe!p~m.'Se!\"], 'hw': u'papier-m\\xe2ch\\xe9'}\n",
      "160 --- {'prn_brit': 'y', 'prn': [\"p@'se!\"], 'hw': u'pass\\xe9'}\n",
      "161 --- {'prn_brit': 'y', 'prn': [\"pA'te!\"], 'hw': u'p\\xe2t\\xe9'}\n",
      "162 --- {'prn': [\"pi,Esd.r.,zi:'stA:ns\", \"pi,Esd.r.,zi:'stA:ns\"], 'hw': u'pi\\xe8ce de r\\xe9sistance'}\n",
      "163 --- {'prn': [\"'pi:nj.koU'lA:d.\"], 'hw': u'pi\\xf1a colada'}\n",
      "164 --- {'prn': [\"pin'jA:t.\"], 'hw': u'pi\\xf1ata'}\n",
      "165 --- {'prn': [\"pre!'si:\", \"pre!'si:z\", \"pre!'si:z\"], 'hw': u'pr\\xe9cis'}\n",
      "166 --- {'prn': [\"'proUt.,Ze!\"], 'hw': u'prot\\xe9g\\xe9'}\n",
      "167 --- {'prn': [\"'proUt.,Ze!\"], 'hw': u'prot\\xe9g\\xe9e'}\n",
      "168 --- {'prn': [\",re!,zoUn'dEtr.\", \",re!,zoUnz'dEtr.\"], 'hw': u\"raison d'\\xeatre\"}\n",
      "169 --- {'prn_brit': 'y', 'prn': [\"r.,Se~'Se!\"], 'hw': u'recherch\\xe9'}\n",
      "170 --- {'prn': [\",bEt'nwA~\", \",bEt'nwA~z\"], 'hw': u'b\\xeate noire'}\n",
      "171 --- {'prn_brit': 'y', 'prn': [\"'rEz.,me!\"], 'hw': u'r\\xe9sum\\xe9'}\n",
      "172 --- {'prn': [\"r!'ske!\"], 'hw': u'risqu\\xe9'}\n",
      "173 --- {'prn_brit': 'y', 'prn': [\"roU'ze!\"], 'hw': u'ros\\xe9'}\n",
      "174 --- {'prn_brit': 'y', 'prn': [\"sA'te!\"], 'hw': u'saut\\xe9'}\n",
      "175 --- {'hw': u'saut\\xe9'}\n",
      "176 --- {'prn': [\"'se!,A:ns\"], 'hw': u's\\xe9ance'}\n",
      "177 --- {'prn_brit': 'y', 'prn': [\"blA'ze!\"], 'hw': u'blas\\xe9'}\n",
      "178 --- {'prn': [\"su'fle!\"], 'hw': u'souffl\\xe9'}\n",
      "179 --- {'prn': [\"'su:p,sA:n\"], 'hw': u'soup\\xe7on'}\n",
      "180 --- {'prn': [\",tEt.'tEt\"], 'hw': u't\\xeate-\\xe0-t\\xeate'}\n",
      "181 --- {'prn': [\",boUn@p.'ti:\"], 'hw': u'bon app\\xe9tit'}\n",
      "182 --- {'prn': [\"tu'Se!\"], 'hw': u'touch\\xe9'}\n",
      "183 --- {'hw': u'transport caf\\xe9'}\n",
      "184 --- {'prn': [\"'u:b~\"], 'hw': u'\\xfcber-'}\n",
      "185 --- {'prn_brit': 'y', 'prn': [\"v!'ku:nj.\"], 'hw': u'vicu\\xf1a'}\n",
      "186 --- {'prn': [\"vwA'lA:\"], 'hw': u'voil\\xe0'}\n",
      "187 --- {'hw': u'br\\xfbl\\xe9e'}\n",
      "188 --- {'prn_brit': 'y', 'prn': [\"k@'fe!\"], 'hw': u'caf\\xe9'}\n",
      "189 --- {'prn': [\"'k@n.pi'k@n.,pe!\"], 'hw': u'canap\\xe9'}\n",
      "190 --- {'prn': [\",kA:zs.'lEbr.\", \",kAz:s.'lEbr.\"], 'hw': u'cause c\\xe9l\\xe8bre'}\n",
      "191 --- {'hw': u'c\\xe9l\\xe8bre'}\n",
      "192 --- {'prn': [\"SA~,Ze!d.'fe~\", \"SA~,Ze!d.'fe~\"], 'hw': u\"charg\\xe9 d'affaires\"}\n",
      "193 --- {'prn_brit': 'y', 'prn': [\"S@'toU\", \"S@'toUz\"], 'hw': u'ch\\xe2teau'}\n",
      "194 --- {'prn': [\"kli'Se!'kli:,Se!\", \"kli'Se!d\"], 'hw': u'clich\\xe9'}\n",
      "195 --- {'prn': [\"k.'mju:n.,ke!\"], 'hw': u'communiqu\\xe9'}\n",
      "196 --- {'prn': [',A:,lA:'], 'hw': u'\\xe0 la'}\n",
      "197 --- {'prn': [\",A:l.'kA~t\"], 'hw': u'\\xe0 la carte'}\n",
      "198 --- {'prn': [\",A:l.'moUd\"], 'hw': u'\\xe0 la mode'}\n",
      "199 --- {'prn_brit': 'y', 'prn': [\",kA:ns.'me!\"], 'hw': u'consomm\\xe9'}\n",
      "200 --- {'prn': [\",ku:d.'grA:s\", \",ku:d.'grA:s\"], 'hw': u'coup de gr\\xe2ce'}\n",
      "201 --- {'prn': [\",ku:,de!'tA:\", \",ku:,de!'tA:\"], 'hw': u\"coup d'\\xe9tat\"}\n",
      "202 --- {'prn': [\"'krES\"], 'hw': u'cr\\xe8che'}\n",
      "203 --- {'prn': [\",krEmAN'gle!z\"], 'hw': u'cr\\xe8me anglaise'}\n",
      "204 --- {'prn': [\",krEmbru'le!\"], 'hw': u'cr\\xe8me br\\xfbl\\xe9e'}\n",
      "205 --- {'prn': [\",krEm,ker.'mEl\"], 'hw': u'cr\\xe8me caramel'}\n",
      "206 --- {'prn': [\"'krEmd.lA'krEm\"], 'hw': u'cr\\xe8me de la cr\\xe8me'}\n",
      "207 --- {'prn_brit': 'y', 'prn': [\"'krEmd.'mEnth\"], 'hw': u'cr\\xe8me de menthe'}\n",
      "208 --- {'prn': [\"'krEm'frES\"], 'hw': u'cr\\xe8me fra\\xeeche'}\n",
      "209 --- {'prn': [\",kru:d!'te!\"], 'hw': u'crudit\\xe9s'}\n",
      "210 --- {'prn_brit': 'y', 'prn': [\"'sa!b~k@'fe!\"], 'hw': u'cybercaf\\xe9'}\n",
      "211 --- {'prn': [\"de!,kA:l.'tA:Z\", \"de!,kA:l'te!\"], 'hw': u'd\\xe9colletage'}\n",
      "212 --- {'prn': [\",de!,ZA:'vu:\"], 'hw': u'd\\xe9j\\xe0 vu'}\n",
      "213 --- {'prn': [\"de!'tA:nt\"], 'hw': u'd\\xe9tente'}\n",
      "214 --- {'prn': [\"d.,vo~'se!\"], 'hw': u'divorc\\xe9'}\n",
      "215 --- {'prn': [\"d.,vo~'se!\"], 'hw': u'divorc\\xe9e'}\n",
      "216 --- {'prn': [\"'dA:p.l,g@Ng~\"], 'hw': u'doppelg\\xe4nger'}\n",
      "217 --- {'prn': [\"'thri:'di:\"], 'hw': '3-D'}\n",
      "218 --- {'prn': [\"'fo~'e!tS\"], 'hw': '4-H'}\n",
      "219 --- {'prn': [\",fo~,oU,w^n'ke!\"], 'hw': '401(k)'}\n",
      "220 --- {'prn': [\"'fo~ba!,fo~\"], 'hw': '4x4'}\n",
      "221 --- {'prn': [\",e!t'h^ndr.d#\"], 'hw': '800 number'}\n",
      "222 --- {'prn': ['.'], 'hw': 'a-'}\n",
      "223 --- {'hw': 'a-'}\n",
      "224 --- {'prn': [\"'e!,bA:m\"], 'hw': 'A-bomb'}\n",
      "225 --- {'prn': [\"'e!,la!n\"], 'hw': 'A-line'}\n",
      "226 --- {'prn': [\"'e!,l!st\"], 'hw': 'A-list'}\n",
      "227 --- {'prn': [\",e!oU'ke!\"], 'hw': 'A-OK'}\n",
      "228 --- {'prn': [\"'e!\"], 'hw': 'a'}\n",
      "229 --- {'prn': [\".'e!\", \".n'@n\"], 'hw': 'a'}\n",
      "230 --- {'hw': 'a.m.'}\n",
      "231 --- {'prn': [\",e!,En'^TH~\"], 'hw': 'A. N. Other'}\n",
      "232 --- {'prn': [\"'e!'w^n\"], 'hw': 'A1'}\n",
      "233 --- {'hw': 'AA'}\n",
      "234 --- {'hw': 'AAA'}\n",
      "235 --- {'prn': [\"'A:\"], 'hw': 'aah'}\n",
      "236 --- {'hw': 'aah'}\n",
      "237 --- {'prn': [\"'A~d,vA~k\"], 'hw': 'aardvark'}\n",
      "238 --- {'hw': 'AARP'}\n",
      "239 --- {'hw': 'ab.'}\n",
      "240 --- {'prn': [\"'@b\"], 'hw': 'ab'}\n",
      "241 --- {'prn': [\".'b@k\"], 'hw': 'aback'}\n",
      "242 --- {'prn': [\"'@b.k.s\", '#,sa!'], 'hw': 'abacus'}\n",
      "243 --- {'prn': [\",@b.'loUni\"], 'hw': 'abalone'}\n",
      "244 --- {'prn': [\".'b@nd.n\", \".'b@nd.nm.nt\"], 'hw': 'abandon'}\n",
      "245 --- {'hw': 'abandon'}\n",
      "246 --- {'prn': [\".'b@nd.nd\"], 'hw': 'abandoned'}\n",
      "247 --- {'prn': [\".'be!s\"], 'hw': 'abase'}\n",
      "248 --- {'prn': [\".'b@St\"], 'hw': 'abashed'}\n",
      "249 --- {'prn': [\".'be!t\", \".'be!tm.nt\"], 'hw': 'abate'}\n",
      "250 --- {'prn': [\"'@b.,twA~\"], 'hw': 'abattoir'}\n",
      "251 --- {'prn': [\"'@b.s\"], 'hw': 'abbess'}\n",
      "252 --- {'prn': [\"'@bi\"], 'hw': 'abbey'}\n",
      "253 --- {'prn': [\"'@b.t\"], 'hw': 'abbot'}\n",
      "254 --- {'hw': 'abbr'}\n",
      "255 --- {'prn': [\".'bri:vi,e!t\"], 'hw': 'abbreviate'}\n",
      "256 --- {'prn': [\".,bri:vi'e!S.n\"], 'hw': 'abbreviation'}\n",
      "257 --- {'prn': [\",e!,bi'si:\"], 'hw': 'ABC'}\n",
      "258 --- {'hw': 'ABC'}\n",
      "259 --- {'prn': [\"'@bd!,ke!t\", \",@bd!'ke!S.n\"], 'hw': 'abdicate'}\n",
      "260 --- {'prn': [\"'@bd.m.n\", \"@b'dA:m.nl-\"], 'hw': 'abdomen'}\n",
      "261 --- {'prn': [\"@b'd^kt\", \",@b,d^k'ti:\", \"@b'd^kS.n\", \"@b'd^kt~\"], 'hw': 'abduct'}\n",
      "262 --- {'prn': [\".'bEd\"], 'hw': 'abed'}\n",
      "263 --- {'prn': [\".'ber.nt\"], 'hw': 'aberrant'}\n",
      "264 --- {'prn': [\",@b.'re!S.n\"], 'hw': 'aberration'}\n",
      "265 --- {'prn': [\".'bEt\"], 'hw': 'abet'}\n",
      "266 --- {'prn': [\".'bej.ns\"], 'hw': 'abeyance'}\n",
      "267 --- {'prn': [\".b'ho~\", \".b'hor.ns\"], 'hw': 'abhor'}\n",
      "268 --- {'prn': [\".b'hor.nt\"], 'hw': 'abhorrent'}\n",
      "269 --- {'prn': [\".'ba!d\"], 'hw': 'abide'}\n",
      "270 --- {'prn': [\".'ba!d!N\"], 'hw': 'abiding'}\n",
      "271 --- {'prn': [\".'b!l.ti\"], 'hw': 'ability'}\n",
      "272 --- {'prn': [\"'@b,dZEkt\", \"'@b,dZEktli\"], 'hw': 'abject'}\n",
      "273 --- {'prn': [\"@b'dZu~\"], 'hw': 'abjure'}\n",
      "274 --- {'prn': [\".'ble!z\"], 'hw': 'ablaze'}\n",
      "275 --- {'prn': [\",e!b.l'bA:did\"], 'hw': 'able-bodied'}\n",
      "276 --- {'prn': [\"'e!b.l\"], 'hw': 'able'}\n",
      "277 --- {'prn': [\".'blu:S.n\"], 'hw': 'ablution'}\n",
      "278 --- {'prn': [\"'e!b.li\"], 'hw': 'ably'}\n",
      "279 --- {'prn': [\"@b'no~m.l\"], 'hw': 'abnormal'}\n",
      "280 --- {'prn': [\",@bn~'m@l.ti\"], 'hw': 'abnormality'}\n",
      "281 --- {'prn': [\".'bo~d\"], 'hw': 'aboard'}\n",
      "282 --- {'hw': 'aboard'}\n",
      "283 --- {'prn': [\".'boUd\"], 'hw': 'abode'}\n",
      "284 --- {'hw': 'abode'}\n",
      "285 --- {'prn': [\".'bA:l!S\"], 'hw': 'abolish'}\n",
      "286 --- {'prn': [\",@b.'l!Sn-\"], 'hw': 'abolition'}\n",
      "287 --- {'prn': [\",@b.'l!Sn-!st\"], 'hw': 'abolitionist'}\n",
      "288 --- {'prn': [\".'bA:m.n.b.l\", \".'bA:m.n.bli\"], 'hw': 'abominable'}\n",
      "289 --- {'hw': 'abominable snowman'}\n",
      "290 --- {'prn': [\".'bA:m.,ne!t\"], 'hw': 'abominate'}\n",
      "291 --- {'prn': [\".,bA:m.'ne!S.n\"], 'hw': 'abomination'}\n",
      "292 --- {'prn': [\",@b.'r!dZ.nl-\"], 'hw': 'aboriginal'}\n",
      "293 --- {'hw': 'aboriginal'}\n",
      "294 --- {'prn': [\",@b.'r!dZ.ni\"], 'hw': 'aborigine'}\n",
      "295 --- {'prn': [\".'bo~t\"], 'hw': 'abort'}\n",
      "296 --- {'prn': [\".'bo~S.n\"], 'hw': 'abortion'}\n",
      "297 --- {'prn': [\".'bo~S.n!st\"], 'hw': 'abortionist'}\n",
      "298 --- {'prn': [\".'bo~t!v\"], 'hw': 'abortive'}\n",
      "299 --- {'prn': [\".'baUnd\"], 'hw': 'abound'}\n",
      "300 --- {'prn': [\".'baUt'fe!s\"], 'hw': 'about-face'}\n",
      "301 --- {'prn': [\".'baUt't~n\"], 'hw': 'about-turn'}\n",
      "302 --- {'prn': [\".'baUt\"], 'hw': 'about'}\n",
      "303 --- {'hw': 'about'}\n",
      "304 --- {'hw': 'about'}\n",
      "305 --- {'prn': [\".'b^v\"], 'hw': 'above'}\n",
      "306 --- {'hw': 'above'}\n",
      "307 --- {'hw': 'above'}\n",
      "308 --- {'prn': [\".'b^v,bo~d\"], 'hw': 'aboveboard'}\n",
      "309 --- {'prn': [\".'b^v,graUnd\"], 'hw': 'aboveground'}\n",
      "310 --- {'prn': [\",@br.k.'d@br.\"], 'hw': 'abracadabra'}\n",
      "311 --- {'prn': [\".'bre!d\"], 'hw': 'abrade'}\n",
      "312 --- {'prn': [\".'bre!Z.n\"], 'hw': 'abrasion'}\n",
      "313 --- {'prn': [\".'bre!s!v\"], 'hw': 'abrasive'}\n",
      "314 --- {'hw': 'abrasive'}\n",
      "315 --- {'prn': [\".'brEst\"], 'hw': 'abreast'}\n",
      "316 --- {'prn': [\".'br!dZ\", \".'br!dZm.nt\"], 'hw': 'abridge'}\n",
      "317 --- {'prn': [\".'brA:d\"], 'hw': 'abroad'}\n",
      "318 --- {'prn': [\"'@br.,ge!t\", \",@br.'ge!S.n\"], 'hw': 'abrogate'}\n",
      "319 --- {'prn': [\".'br^pt\"], 'hw': 'abrupt'}\n",
      "320 --- {'hw': 'abs'}\n",
      "321 --- {'hw': 'ABS'}\n",
      "322 --- {'prn': [\"'@b,sEs\", \"'@b,sEst\"], 'hw': 'abscess'}\n",
      "323 --- {'prn': [\"@b'skA:nd\"], 'hw': 'abscond'}\n",
      "324 --- {'prn': [\"'@b,se!l\"], 'hw': 'abseil'}\n",
      "325 --- {'prn': [\"'@bs.ns\"], 'hw': 'absence'}\n",
      "326 --- {'prn': [\"'@bs.nt\"], 'hw': 'absent'}\n",
      "327 --- {'prn': [\"@b'sEnt\"], 'hw': 'absent'}\n",
      "328 --- {'prn': [\"'@bs.nt\"], 'hw': 'absent'}\n",
      "329 --- {'prn': [\",@bs.n'ti:\"], 'hw': 'absentee'}\n",
      "330 --- {'prn': [\",@bs.n'ti:,!z.m\"], 'hw': 'absenteeism'}\n",
      "331 --- {'hw': 'absentee ballot'}\n",
      "332 --- {'hw': 'absentee landlord'}\n",
      "333 --- {'hw': 'absentia'}\n",
      "334 --- {'prn': [\",@bs.nt'ma!nd.d\"], 'hw': 'absentminded'}\n",
      "335 --- {'prn': [\"'@b,s!nth\"], 'hw': 'absinthe'}\n",
      "336 --- {'prn': [\"'@bs.,lu:t\"], 'hw': 'absolute'}\n",
      "337 --- {'prn': [\"'@bs.,lu:tli\"], 'hw': 'absolutely'}\n",
      "338 --- {'hw': 'absolute zero'}\n",
      "339 --- {'prn': [\",@bs.'lu:S.n\"], 'hw': 'absolution'}\n",
      "340 --- {'prn': [\".b'zA:lv\"], 'hw': 'absolve'}\n",
      "341 --- {'prn': [\".b'so~b\", \".b'so~b.b.l\", \".b'so~pS.n\"], 'hw': 'absorb'}\n",
      "342 --- {'prn': [\".b'so~b.nt\", \".b'so~b.nsi\"], 'hw': 'absorbent'}\n",
      "343 --- {'prn': [\".b'ste!n\"], 'hw': 'abstain'}\n",
      "344 --- {'prn': [\"@b'sti:mij.s\"], 'hw': 'abstemious'}\n",
      "345 --- {'prn': [\".b'stEnS.n\"], 'hw': 'abstention'}\n",
      "346 --- {'prn': [\"'@bst.n.ns\", \"'@bst.n.nt\"], 'hw': 'abstinence'}\n",
      "347 --- {'prn': [\"@b'str@kt'@b,str@kt\", \"@b'str@ktli\", \"@b'str@ktn.s\"], 'hw': 'abstract'}\n",
      "in audiofile\n",
      "348 --- {'prn': [\"'@b,str@kt\"], 'hw': 'abstract'}\n",
      "in audiofile\n",
      "349 --- {'prn': [\"@b'str@kt\"], 'hw': 'abstract'}\n",
      "in audiofile\n",
      "350 --- {'prn': [\"@b'str@kt.d\"], 'hw': 'abstracted'}\n",
      "351 --- {'prn': [\"@b'str@kS.n\"], 'hw': 'abstraction'}\n",
      "352 --- {'prn': [\".b'stru:s\"], 'hw': 'abstruse'}\n",
      "353 --- {'prn': [\".b's~d\", \".b's~d.ti\"], 'hw': 'absurd'}\n",
      "354 --- {'prn': [\".'b^nd.ns\"], 'hw': 'abundance'}\n",
      "355 --- {'prn': [\".'b^nd.nt\"], 'hw': 'abundant'}\n",
      "356 --- {'prn': [\".'bju:z\"], 'hw': 'abuse'}\n",
      "in audiofile\n",
      "357 --- {'prn': [\".'bju:s\"], 'hw': 'abuse'}\n",
      "in audiofile\n",
      "358 --- {'prn': [\".'bju:s!v\"], 'hw': 'abusive'}\n",
      "359 --- {'prn': [\".'b^t\", \".'b^t~\"], 'hw': 'abut'}\n",
      "360 --- {'prn': [\".'b^tm.nt\"], 'hw': 'abutment'}\n",
      "361 --- {'prn': [\".'b^z\"], 'hw': 'abuzz'}\n",
      "362 --- {'prn': [\".'b!zm.l\"], 'hw': 'abysmal'}\n",
      "363 --- {'prn': [\".'b!s\"], 'hw': 'abyss'}\n",
      "364 --- {'hw': 'AC'}\n",
      "365 --- {'prn': [\".'ke!S.\"], 'hw': 'acacia'}\n",
      "366 --- {'prn': [\",@k.'di:mij.\"], 'hw': 'academia'}\n",
      "367 --- {'prn': [\",@k.'dEm!k\", \",@k.'dEm!kli\"], 'hw': 'academic'}\n",
      "368 --- {'hw': 'academic'}\n",
      "369 --- {'hw': 'academic year'}\n",
      "370 --- {'prn': [\".'k@d.mi\"], 'hw': 'academy'}\n",
      "371 --- {'hw': 'Academy Award'}\n",
      "372 --- {'prn': [\"@k'si:d\"], 'hw': 'accede'}\n",
      "373 --- {'prn': [\"!k'sEl.,re!t\"], 'hw': 'accelerate'}\n",
      "374 --- {'prn': [\"!k,sEl.'re!S.n\"], 'hw': 'acceleration'}\n",
      "375 --- {'prn': [\"!k'sEl.,re!t~\"], 'hw': 'accelerator'}\n",
      "376 --- {'prn_brit': 'y', 'prn': [\"'@k,sEnt\"], 'hw': 'accent'}\n",
      "377 --- {'prn_brit': 'y', 'prn': [\"'@k,sEnt\"], 'hw': 'accent'}\n",
      "378 --- {'hw': 'accented'}\n",
      "379 --- {'prn': [\"@k'sEntS.,we!t\", \"!k,sEntS.'we!S.n\"], 'hw': 'accentuate'}\n",
      "380 --- {'hw': 'accent mark'}\n",
      "381 --- {'prn': [\"!k'sEpt\", \"!k'sEpt~\"], 'hw': 'accept'}\n",
      "382 --- {'prn': [\"!k'sEpt.b.#\", \"!k,sEpt.'b!l.ti\", \"!k'sEpt.bli\"], 'hw': 'acceptable'}\n",
      "383 --- {'prn': [\"!k'sEpt.ns\"], 'hw': 'acceptance'}\n",
      "384 --- {'prn': [\"'@k,sEs\"], 'hw': 'access'}\n",
      "385 --- {'hw': 'access'}\n",
      "386 --- {'prn': [\"!k'sEs.b.l\", \"!k,sEs.'b!l.ti\", \"!k'sEs.bli\"], 'hw': 'accessible'}\n",
      "387 --- {'prn': [\"!k'sES.n\"], 'hw': 'accession'}\n",
      "388 --- {'prn': [\"!k'sEs.,ra!z\"], 'hw': 'accessorize'}\n",
      "389 --- {'prn': [\"!k'sEs.ri\"], 'hw': 'accessory'}\n",
      "390 --- {'hw': 'access time'}\n",
      "391 --- {'hw': 'accident-prone'}\n",
      "392 --- {'prn': [\"'@ks.d.nt\"], 'hw': 'accident'}\n",
      "393 --- {'prn': [\",@ks.'dEntl-\", \",@ks.'dEntl-i\"], 'hw': 'accidental'}\n",
      "394 --- {'prn': [\".'kle!m\"], 'hw': 'acclaim'}\n",
      "395 --- {'hw': 'acclaim'}\n",
      "396 --- {'prn': [\",@kl.'me!S.n\"], 'hw': 'acclamation'}\n",
      "397 --- {'prn_brit': 'y', 'prn': [\"'@kl.,me!t\", \",@kl.'me!S.n\"], 'hw': 'acclimate'}\n",
      "398 --- {'prn_brit': 'y', 'prn': [\".'kla!m.,ta!z\", \".,kla!m.t.'ze!S.n\"], 'hw': 'acclimatize'}\n",
      "399 --- {'prn': [\"'@k.,le!d\"], 'hw': 'accolade'}\n",
      "400 --- {'prn': [\".'kA:m.,de!t\"], 'hw': 'accommodate'}\n",
      "401 --- {'hw': 'accommodating'}\n",
      "402 --- {'prn': [\".,kA:m.'de!S.n\"], 'hw': 'accommodation'}\n",
      "403 --- {'prn': [\".'k^mp.nim.nt\"], 'hw': 'accompaniment'}\n",
      "404 --- {'prn': [\".'k^mp.n!st\"], 'hw': 'accompanist'}\n",
      "405 --- {'prn': [\".'k^mp.ni\"], 'hw': 'accompany'}\n",
      "406 --- {'hw': 'accompli'}\n",
      "407 --- {'prn': [\".'kA:mpl.s\"], 'hw': 'accomplice'}\n",
      "408 --- {'prn': [\".'kA:mpl!S\", \".'khAmpl!S.b.#\"], 'hw': 'accomplish'}\n",
      "409 --- {'hw': 'accomplished'}\n",
      "410 --- {'prn': [\".'kA:mpl!Sm.nt\"], 'hw': 'accomplishment'}\n",
      "411 --- {'prn': [\".'ko~d\"], 'hw': 'accord'}\n",
      "412 --- {'hw': 'accord'}\n",
      "413 --- {'prn': [\".'ko~dn-s\"], 'hw': 'accordance'}\n",
      "414 --- {'prn': [\".'ko~d!Nli\"], 'hw': 'accordingly'}\n",
      "415 --- {'hw': 'according to'}\n",
      "416 --- {'prn': [\".'ko~dij.n\", \".'ko~dij.n!st\"], 'hw': 'accordion'}\n",
      "417 --- {'prn': [\".'kA:st\"], 'hw': 'accost'}\n",
      "418 --- {'prn': [\".'kaUnt\"], 'hw': 'account'}\n",
      "419 --- {'hw': 'account'}\n",
      "420 --- {'prn': [\".'kaUnt.b.l\", \".,kh@Unt.'b!l.ddi\"], 'hw': 'accountable'}\n",
      "421 --- {'prn': [\".'kaUntn-t\"], 'hw': 'accountant'}\n",
      "422 --- {'prn': [\".'kaUnt!N\"], 'hw': 'accounting'}\n",
      "423 --- {'prn': [\".'ku:t~d\"], 'hw': 'accoutred'}\n",
      "424 --- {'prn': [\".'ku:tr.m.nt.'ku:t~m.nt\"], 'hw': 'accoutrement'}\n",
      "425 --- {'prn': [\".'krEd.t\", \".,krEd.'te!S.n\"], 'hw': 'accredit'}\n",
      "426 --- {'prn': [\".'kri:S.n\"], 'hw': 'accretion'}\n",
      "427 --- {'prn': [\".'kru:\", \".'kru:w.l\"], 'hw': 'accrue'}\n",
      "428 --- {'prn': [\".'kju:mj.,le!t\", \".,kju:mj.'le!S.n\"], 'hw': 'accumulate'}\n",
      "429 --- {'prn': [\".'kju:mj.l.t!v\"], 'hw': 'accumulative'}\n",
      "430 --- {'prn': [\"'@kj.r.si\"], 'hw': 'accuracy'}\n",
      "431 --- {'prn': [\"'@kj.r.t\"], 'hw': 'accurate'}\n",
      "432 --- {'prn': [\".'k~st.'k~s.d\"], 'hw': 'accursed'}\n",
      "433 --- {'prn': [\",@kj.'ze!S.n\"], 'hw': 'accusation'}\n",
      "434 --- {'prn': [\".'khju:z.t!v\"], 'hw': 'accusative'}\n",
      "435 --- {'prn_brit': 'y', 'prn': [\".'kju:z.,tori\"], 'hw': 'accusatory'}\n",
      "436 --- {'prn': [\".'kju:z\", \".'khju:z!Nli\"], 'hw': 'accuse'}\n",
      "437 --- {'hw': 'accused'}\n",
      "438 --- {'prn': [\".'k^st.m\"], 'hw': 'accustom'}\n",
      "439 --- {'prn': [\".'k^st.md\"], 'hw': 'accustomed'}\n",
      "440 --- {'prn': [\"'e!s\"], 'hw': 'ace'}\n",
      "441 --- {'hw': 'ace'}\n",
      "442 --- {'prn': [\".'s~b!k\", \".'s~b!kli\"], 'hw': 'acerbic'}\n",
      "443 --- {'prn': [\".,si:t.'m!n.f.n\"], 'hw': 'acetaminophen'}\n",
      "444 --- {'prn': [\".'sEtl-.n\"], 'hw': 'acetylene'}\n",
      "445 --- {'prn': [\"'e!k\"], 'hw': 'ache'}\n",
      "446 --- {'prn': [\"'e!ki\"], 'hw': 'ache'}\n",
      "447 --- {'prn': [\".'tSi:v\", \".'tSi:v.b.#\"], 'hw': 'achieve'}\n",
      "448 --- {'prn': [\".'tSi:vm.nt\"], 'hw': 'achievement'}\n",
      "449 --- {'prn': [\".'tSi:v~\"], 'hw': 'achiever'}\n",
      "450 --- {'prn': [\".'k!liz#\"], 'hw': \"Achilles' heel\"}\n",
      "451 --- {'hw': 'Achilles tendon'}\n",
      "452 --- {'prn': [\".'tSu:\"], 'hw': 'achoo'}\n",
      "453 --- {'prn': [\"'@s.d\"], 'hw': 'acid'}\n",
      "454 --- {'prn': [\".'s!d.ti\"], 'hw': 'acid'}\n",
      "455 --- {'prn': [\".'s!d!k\"], 'hw': 'acidic'}\n",
      "456 --- {'prn': [\".'s!d.,fa!\", \".,s!d.f.'ke!S.n\"], 'hw': 'acidify'}\n",
      "457 --- {'hw': 'acid rain'}\n",
      "458 --- {'hw': 'acid test'}\n",
      "459 --- {'prn': [\"!k'nA:l!dZ\"], 'hw': 'acknowledge'}\n",
      "460 --- {'prn': [\"!k'nA:l!dZm.nt\"], 'hw': 'acknowledgment'}\n",
      "461 --- {'prn': [\"'@kmi\"], 'hw': 'acme'}\n",
      "462 --- {'prn': [\"'@kni\"], 'hw': 'acne'}\n",
      "463 --- {'prn': [\"'@k.,la!t\"], 'hw': 'acolyte'}\n",
      "464 --- {'prn': [\"'e!,ko~n\"], 'hw': 'acorn'}\n",
      "465 --- {'hw': 'acorn squash'}\n",
      "466 --- {'prn': [\".'ku:st!k\", \".'ku:st!k.l\", \".'ku:st!kli\"], 'hw': 'acoustic'}\n",
      "467 --- {'prn': [\".'ku:st!ks\"], 'hw': 'acoustics'}\n",
      "468 --- {'prn': [\".'kwe!nt\"], 'hw': 'acquaint'}\n",
      "469 --- {'prn': [\".'kwe!ntn-s\"], 'hw': 'acquaintance'}\n",
      "470 --- {'hw': 'acquainted'}\n",
      "471 --- {'prn': [\",@kwi'Es\", \",@kwi'Esn-s\"], 'hw': 'acquiesce'}\n",
      "472 --- {'prn': [\",@kwi'Esn-t\"], 'hw': 'acquiescent'}\n",
      "473 --- {'prn': [\".'kwaj~\"], 'hw': 'acquire'}\n",
      "474 --- {'hw': 'acquired immune deficiency syndrome'}\n",
      "475 --- {'prn': [\",@kw.'z!S.n\"], 'hw': 'acquisition'}\n",
      "476 --- {'prn': [\".'kw!z.t!v\"], 'hw': 'acquisitive'}\n",
      "477 --- {'prn': [\".'kw!t\"], 'hw': 'acquit'}\n",
      "478 --- {'prn': [\".'kw!tl-\"], 'hw': 'acquittal'}\n",
      "479 --- {'prn': [\"'e!k~\"], 'hw': 'acre'}\n",
      "480 --- {'prn': [\"'e!k.r!dZ\"], 'hw': 'acreage'}\n",
      "481 --- {'prn': [\"'@kr.d\"], 'hw': 'acrid'}\n",
      "482 --- {'prn': [\",@kr.'moUnij.s\"], 'hw': 'acrimonious'}\n",
      "483 --- {'prn_brit': 'y', 'prn': [\"'@kr.,moUni\"], 'hw': 'acrimony'}\n",
      "484 --- {'prn': [\"'@kr.,b@t\", \",@kr.'b@t!k\", \",@kr.'b@t!kli\"], 'hw': 'acrobat'}\n",
      "485 --- {'prn': [\",@kr.'b@t!ks\"], 'hw': 'acrobatics'}\n",
      "486 --- {'prn': [\"'@kr.,n!m\"], 'hw': 'acronym'}\n",
      "487 --- {'hw': 'across-the-board'}\n",
      "488 --- {'prn': [\".'khrA:s\"], 'hw': 'across'}\n",
      "489 --- {'hw': 'across'}\n",
      "490 --- {'prn': [\".'kr!l!k\"], 'hw': 'acrylic'}\n",
      "491 --- {'prn': [\"'@kt\"], 'hw': 'act'}\n",
      "492 --- {'hw': 'act'}\n",
      "493 --- {'hw': 'ACT'}\n",
      "494 --- {'prn': [\"'@kt!N\"], 'hw': 'acting'}\n",
      "495 --- {'hw': 'acting'}\n",
      "496 --- {'hw': 'action-packed'}\n",
      "497 --- {'prn': [\"'@kS.n\"], 'hw': 'action'}\n",
      "498 --- {'prn': [\"'@kS.n.b.l\"], 'hw': 'actionable'}\n",
      "499 --- {'hw': 'action figure'}\n",
      "500 --- {'hw': 'action replay'}\n",
      "501 --- {'hw': 'action verb'}\n",
      "502 --- {'prn': [\"'@kt.,ve!t\", \",@kt.'ve!S.n\"], 'hw': 'activate'}\n",
      "503 --- {'prn': [\"'@kt!v\"], 'hw': 'active'}\n",
      "504 --- {'prn': [\"'@kt!v!st\", \"'@kt!,v!z.m\"], 'hw': 'activist'}\n",
      "505 --- {'prn': [\"@k't!v.ti\"], 'hw': 'activity'}\n",
      "506 --- {'prn': [\"'@kt~\"], 'hw': 'actor'}\n",
      "507 --- {'prn': [\"'@ktr.s\"], 'hw': 'actress'}\n",
      "508 --- {'prn': [\"'@ktS.w.l\"], 'hw': 'actual'}\n",
      "509 --- {'prn': [\",@ktS.'w@l.ti\"], 'hw': 'actuality'}\n",
      "510 --- {'prn': [\"'@ktS.w.li\"], 'hw': 'actually'}\n",
      "511 --- {'prn_brit': 'y', 'prn': [\"'@ktS.,weri\", \",@ktS.'werij.#\"], 'hw': 'actuary'}\n",
      "512 --- {'prn': [\"'@ktS.,we!t\"], 'hw': 'actuate'}\n",
      "513 --- {'prn': [\".'kju:w.ti\"], 'hw': 'acuity'}\n",
      "514 --- {'prn': [\".'kju:m.n\"], 'hw': 'acumen'}\n",
      "515 --- {'prn': [\"'@kj.,prES~\"], 'hw': 'acupressure'}\n",
      "516 --- {'prn': [\"'@kj.,p^NktS~\", \"'@kj.,p^NktS.r!st\"], 'hw': 'acupuncture'}\n",
      "517 --- {'prn': [\".'kju:t\"], 'hw': 'acute'}\n",
      "518 --- {'prn': [\"'@d'l!b\"], 'hw': 'ad-lib'}\n",
      "519 --- {'prn': [\"'@d\"], 'hw': 'ad'}\n",
      "520 --- {'hw': 'AD'}\n",
      "521 --- {'prn': [\"'@d!dZ\"], 'hw': 'adage'}\n",
      "522 --- {'prn': [\".'dA:dZijoU\"], 'hw': 'adagio'}\n",
      "523 --- {'hw': 'adagio'}\n",
      "524 --- {'hw': \"Adam's apple\"}\n",
      "525 --- {'prn': [\"'@d.m\"], 'hw': 'Adam'}\n",
      "526 --- {'prn': [\"'@d.m.nt\"], 'hw': 'adamant'}\n",
      "527 --- {'prn': [\".'d@pt\"], 'hw': 'adapt'}\n",
      "528 --- {'prn': [\".'d@pt.b.l\", \".,d@pt.'b!l.ti\"], 'hw': 'adaptable'}\n",
      "529 --- {'prn': [\",@,d@p'te!S.n\"], 'hw': 'adaptation'}\n",
      "530 --- {'prn': [\".'d@pt~\"], 'hw': 'adapter'}\n",
      "531 --- {'prn': [\"'@d,A:n\"], 'hw': 'add-on'}\n",
      "532 --- {'prn': [\"'@d\"], 'hw': 'add'}\n",
      "533 --- {'hw': 'ADD'}\n",
      "534 --- {'prn': [\".'dEnd.m\", \"#'dEnd.\"], 'hw': 'addendum'}\n",
      "535 --- {'prn': [\"'@d~\"], 'hw': 'adder'}\n",
      "536 --- {'prn': [\"'@d!kt\"], 'hw': 'addict'}\n",
      "537 --- {'prn': [\".'d!kt.d\"], 'hw': 'addicted'}\n",
      "538 --- {'prn': [\".'d!kS.n\"], 'hw': 'addiction'}\n",
      "539 --- {'prn': [\".'d!kt!v\"], 'hw': 'addictive'}\n",
      "540 --- {'prn': [\".'d!S.n\"], 'hw': 'addition'}\n",
      "541 --- {'prn': [\".'d!S.nl-\", \".'d!S.nl-i\"], 'hw': 'additional'}\n",
      "542 --- {'prn': [\"'@d.t!v\"], 'hw': 'additive'}\n",
      "543 --- {'prn': [\"'@dl-\"], 'hw': 'addle'}\n",
      "544 --- {'prn': [\".'drEs\"], 'hw': 'address'}\n",
      "545 --- {'prn': [\".'drEs'@,drEs\"], 'hw': 'address'}\n",
      "546 --- {'prn': [\",@,drE'si:\"], 'hw': 'addressee'}\n",
      "547 --- {'hw': 'address book'}\n",
      "548 --- {'prn_brit': 'y', 'prn': [\".'du:s\"], 'hw': 'adduce'}\n",
      "549 --- {'prn': [\"'@d.,no!dz\", \",@d.'no!dl-\"], 'hw': 'adenoids'}\n",
      "550 --- {'prn': [\".'dEpt\"], 'hw': 'adept'}\n",
      "551 --- {'prn': [\"'@,dEpt\"], 'hw': 'adept'}\n",
      "552 --- {'prn': [\"'@d!kw.t\", \"'@d!kw.si\"], 'hw': 'adequate'}\n",
      "553 --- {'prn': [\"@d'hi~\"], 'hw': 'adhere'}\n",
      "554 --- {'prn': [\"@d'hir.ns\"], 'hw': 'adherence'}\n",
      "555 --- {'prn': [\"@d'hir.nt\"], 'hw': 'adherent'}\n",
      "556 --- {'prn': [\"@d'hi:Z.n\"], 'hw': 'adhesion'}\n",
      "557 --- {'prn': [\"@d'hi:s!v\"], 'hw': 'adhesive'}\n",
      "558 --- {'hw': 'adhesive'}\n",
      "559 --- {'prn': [\".'du:.'dju:\"], 'hw': 'adieu'}\n",
      "560 --- {'prn': [\".'du:.'dju:\"], 'hw': 'adieu'}\n",
      "561 --- {'prn_brit': 'y', 'prn': [\",A:di'oUs\"], 'hw': 'adios'}\n",
      "562 --- {'hw': 'adj'}\n",
      "563 --- {'prn': [\".'dZe!sn-t\"], 'hw': 'adjacent'}\n",
      "564 --- {'prn': [\"'@dZ!kt!v\", \",@dZ!k'ta!v.l\"], 'hw': 'adjective'}\n",
      "565 --- {'prn': [\".'dZo!n\"], 'hw': 'adjoin'}\n",
      "566 --- {'prn': [\".'dZ~n\", \".'dZ~nm.nt\"], 'hw': 'adjourn'}\n",
      "567 --- {'prn': [\".'dZ^dZ\"], 'hw': 'adjudge'}\n",
      "568 --- {'prn': [\".'dZu:d!,ke!t\", \".,dZu:d!'ke!S.n\", \".'dZu:d!,ke!t~\"], 'hw': 'adjudicate'}\n",
      "569 --- {'prn': [\"'@,dZ^Nkt\"], 'hw': 'adjunct'}\n",
      "570 --- {'hw': 'adjunct'}\n",
      "571 --- {'prn': [\".'dZu~\"], 'hw': 'adjure'}\n",
      "572 --- {'prn': [\".'dZ^st\", \".'dZ^st.b.l\"], 'hw': 'adjust'}\n",
      "573 --- {'prn': [\".'dZ^stm.nt\"], 'hw': 'adjustment'}\n",
      "574 --- {'prn': [\"'@dZ.t.nt\"], 'hw': 'adjutant'}\n",
      "575 --- {'prn': [\"'@d,m@n\", '#,mEn'], 'hw': 'adman'}\n",
      "576 --- {'prn': [\"'@d,m!n\"], 'hw': 'admin'}\n",
      "577 --- {'prn': [\".d'm!n!st~\"], 'hw': 'administer'}\n",
      "578 --- {'prn': [\".d,m!n.'stre!S.n\"], 'hw': 'administration'}\n",
      "579 --- {'prn': [\".d'm!n.,stre!t!v\"], 'hw': 'administrative'}\n",
      "580 --- {'prn': [\".d'm!n.,stre!t~\"], 'hw': 'administrator'}\n",
      "581 --- {'prn': [\"'@dmr.b.l\", \"'@dmr.bli\"], 'hw': 'admirable'}\n",
      "582 --- {'prn': [\"'@dmr.l\"], 'hw': 'admiral'}\n",
      "583 --- {'prn': [\"'@dmr.lti\"], 'hw': 'Admiralty'}\n",
      "584 --- {'prn': [\",@dm.'re!S.n\"], 'hw': 'admiration'}\n",
      "585 --- {'prn': [\".d'maj~\", \".d'ma!r!Nli\"], 'hw': 'admire'}\n",
      "586 --- {'prn': [\".d'm!s.b.l\"], 'hw': 'admissible'}\n",
      "587 --- {'prn': [\".d'm!S.n\"], 'hw': 'admission'}\n",
      "588 --- {'prn': [\".d'm!t\", \".d'm!t.dli\"], 'hw': 'admit'}\n",
      "589 --- {'prn': [\".d'm!tn-s\"], 'hw': 'admittance'}\n",
      "590 --- {'prn': [\"@d'm!kstS~\"], 'hw': 'admixture'}\n",
      "591 --- {'prn': [\"@d'mA:n!S\", \"@d'mA:n!Sm.nt\"], 'hw': 'admonish'}\n",
      "592 --- {'prn_brit': 'y', 'prn': [\",@dm.'n!S.n\", \".d'mA:n.,thori\"], 'hw': 'admonition'}\n",
      "593 --- {'prn': [\".'du:\"], 'hw': 'ado'}\n",
      "594 --- {'prn': [\".'doUbi\"], 'hw': 'adobe'}\n",
      "595 --- {'prn': [\",@d.'lEsn-s\"], 'hw': 'adolescence'}\n",
      "596 --- {'prn': [\",@d.'lEsn-t\"], 'hw': 'adolescent'}\n",
      "597 --- {'prn': [\".'dA:pt\"], 'hw': 'adopt'}\n",
      "598 --- {'prn': [\".'dA:pS.n\"], 'hw': 'adoption'}\n",
      "599 --- {'prn': [\".'dA:pt!v\"], 'hw': 'adoptive'}\n",
      "600 --- {'prn': [\".'dor.b.l\", \".'dor.bli\"], 'hw': 'adorable'}\n",
      "601 --- {'prn': [\",@d.'re!S.n\"], 'hw': 'adoration'}\n",
      "602 --- {'prn': [\".'do~\"], 'hw': 'adore'}\n",
      "603 --- {'prn': [\".'do~n\"], 'hw': 'adorn'}\n",
      "604 --- {'prn': [\".'do~nm.nt\"], 'hw': 'adornment'}\n",
      "605 --- {'prn': [\".'drEn.l.n\"], 'hw': 'adrenaline'}\n",
      "606 --- {'prn': [\".'dr!ft\"], 'hw': 'adrift'}\n",
      "607 --- {'prn': [\".'dro!t\"], 'hw': 'adroit'}\n",
      "608 --- {'prn': [\",@dZ.'le!S.n\"], 'hw': 'adulation'}\n",
      "609 --- {'prn': [\".'d^lt'@,d^lt\"], 'hw': 'adult'}\n",
      "610 --- {'prn': [\".'d^lt,hUd\"], 'hw': 'adult'}\n",
      "611 --- {'prn': [\".'d^lt.,re!t\", \".,d^lt.'re!S.n\"], 'hw': 'adulterate'}\n",
      "612 --- {'prn': [\".'d^lt~r~\"], 'hw': 'adulterer'}\n",
      "613 --- {'prn': [\".'d^lt.r.s\"], 'hw': 'adulteress'}\n",
      "614 --- {'prn': [\".'d^lt.ri\", \".'d^lt.r.s\"], 'hw': 'adultery'}\n",
      "615 --- {'hw': 'adult education'}\n",
      "616 --- {'hw': 'adv'}\n",
      "617 --- {'prn_brit': 'y', 'prn': [\".d'v@ns\"], 'hw': 'advance'}\n",
      "618 --- {'hw': 'advance'}\n",
      "619 --- {'hw': 'advance'}\n",
      "620 --- {'prn_brit': 'y', 'prn': [\".d'v@nst\"], 'hw': 'advanced'}\n",
      "621 --- {'hw': 'Advanced level'}\n",
      "622 --- {'prn_brit': 'y', 'prn': [\".d'v@nsm.nt\"], 'hw': 'advancement'}\n",
      "623 --- {'prn_brit': 'y', 'prn': [\".d'v@nt!dZ\"], 'hw': 'advantage'}\n",
      "624 --- {'prn_brit': 'y', 'prn': [\".d'v@nt!dZd\"], 'hw': 'advantaged'}\n",
      "625 --- {'prn': [\",@d,v@n'te!dZ.s\"], 'hw': 'advantageous'}\n",
      "626 --- {'prn': [\"'@d,vEnt\"], 'hw': 'advent'}\n",
      "627 --- {'prn': [\".d'vEntS~\"], 'hw': 'adventure'}\n",
      "628 --- {'prn': [\".d'vEntS~r~\"], 'hw': 'adventurer'}\n",
      "629 --- {'prn': [\".d'vEntS~s.m\"], 'hw': 'adventuresome'}\n",
      "630 --- {'hw': 'adventure playground'}\n",
      "631 --- {'prn': [\".d'vEntS.,r!z.m\", \".d'vEntS.r!st\"], 'hw': 'adventurism'}\n",
      "632 --- {'prn': [\".d'vEntS.r.s\"], 'hw': 'adventurous'}\n",
      "633 --- {'prn': [\"'@d,v~b\", \"@d'v~bij.l\"], 'hw': 'adverb'}\n",
      "634 --- {'prn': [\",@dv~'serij.l\"], 'hw': 'adversarial'}\n",
      "635 --- {'prn_brit': 'y', 'prn': [\"'@dv~,seri\"], 'hw': 'adversary'}\n",
      "636 --- {'prn': [\"@d'v~s'@d,v~s\"], 'hw': 'adverse'}\n",
      "637 --- {'prn': [\"@d'v~s.ti\"], 'hw': 'adversity'}\n",
      "638 --- {'prn': [\"'@d,v~t\"], 'hw': 'advert'}\n",
      "639 --- {'prn': [\"'@dv~,ta!z\"], 'hw': 'advertise'}\n",
      "640 --- {'prn_brit': 'y', 'prn': [\",@dv~'ta!zm.nt\"], 'hw': 'advertisement'}\n",
      "641 --- {'prn': [\"'@dv~,ta!z!N\"], 'hw': 'advertising'}\n",
      "642 --- {'prn': [\".d'va!s\"], 'hw': 'advice'}\n",
      "643 --- {'hw': 'advice column'}\n",
      "644 --- {'prn': [\".d'va!z.b.#\", \".d,va!z.'b!l.ti\"], 'hw': 'advisable'}\n",
      "645 --- {'prn': [\".d'va!z\", \".d'va!z~\"], 'hw': 'advise'}\n",
      "646 --- {'prn': [\".d'va!z.dli\"], 'hw': 'advisedly'}\n",
      "647 --- {'prn': [\".d'va!zm.nt\"], 'hw': 'advisement'}\n",
      "648 --- {'prn': [\".d'va!z.ri\"], 'hw': 'advisory'}\n",
      "649 --- {'hw': 'advisory'}\n",
      "650 --- {'prn': [\"'@dv.k.si\"], 'hw': 'advocacy'}\n",
      "651 --- {'prn': [\"'@dv.k.t\"], 'hw': 'advocate'}\n",
      "in audiofile\n",
      "652 --- {'prn': [\"'@dv.,ke!t\"], 'hw': 'advocate'}\n",
      "in audiofile\n",
      "653 --- {'prn': [\"'@dz\"], 'hw': 'adze'}\n",
      "654 --- {'prn': [\"'@d'hA:k\"], 'hw': 'ad hoc'}\n",
      "655 --- {'prn': [\",@d,!nf.'na!t.m\"], 'hw': 'ad infinitum'}\n",
      "656 --- {'prn': [\"@d'nA:zij.m\"], 'hw': 'ad nauseam'}\n",
      "657 --- {'prn': [\"'i:dZ.s\"], 'hw': 'aegis'}\n",
      "658 --- {'hw': 'aeon'}\n",
      "659 --- {'prn': [\"'e~,e!t\", \",e~'e!S.n\"], 'hw': 'aerate'}\n",
      "660 --- {'prn': [\"'erij.l\"], 'hw': 'aerial'}\n",
      "661 --- {'hw': 'aerial'}\n",
      "662 --- {'prn': [\"'eri\"], 'hw': 'aerie'}\n",
      "663 --- {'hw': 'aero-'}\n",
      "664 --- {'prn': [\",er.'b@t!ks\", \",er.'b@t!k\"], 'hw': 'aerobatics'}\n",
      "665 --- {'prn': [\",e~'oUb!k\"], 'hw': 'aerobic'}\n",
      "666 --- {'prn': [\",e~'oUb!ks\"], 'hw': 'aerobics'}\n",
      "667 --- {'prn': [\",eroUda!'n@m!ks\", \",eroUda!'n@m!k\", \",eroUda!'n@m!kli\"], 'hw': 'aerodynamics'}\n",
      "668 --- {'prn': [\",er.'nA:t!ks\", \",er.'nA:t!k.#\"], 'hw': 'aeronautics'}\n",
      "669 --- {'prn': [\"'er.,ple!n\"], 'hw': 'aeroplane'}\n",
      "670"
     ]
    }
   ],
   "source": [
    "#buildJSON20151109\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import shutil\n",
    "import codecs\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "#connect to MongoDB\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client.dpdb  # databas: dpdb\n",
    "\n",
    "geweiDict = db.geweiDict201511 # collection (table): geweiDict201511\n",
    "#geweiDict = db.geweiDictTest\n",
    "\n",
    "\n",
    "def a_has_id(tag):\n",
    "    return tag.has_attr('id')\n",
    "\n",
    "def a_has_href(tag):\n",
    "    return tag.has_attr('href')\n",
    "\n",
    "tfiles = ['core31.txt', 'core37.txt', 'wordRoot.txt', 'prefix.txt', 'suffix.txt',\n",
    "          'acaWriting.txt', 'airTravel.txt', 'bodyPart.txt', 'campus.txt', 'economics.txt', 'emotion.txt', \n",
    "          'employment.txt', 'environment.txt', 'family.txt', 'health.txt', 'job.txt', 'legal.txt', \n",
    "          'nonCount.txt', 'personality.txt', 'sports.txt', 'timeAdv.txt', 'timePeriod.txt', 'weather.txt']\n",
    "topics = []\n",
    "for tfile in tfiles:\n",
    "    topic = {}\n",
    "    with codecs.open('E:\\\\1Now\\\\dPDict\\\\taglist\\\\' + tfile, 'r', 'utf-8') as f:\n",
    "        twords = f.read().splitlines()\n",
    "        f.close()\n",
    "    topic['words'] = twords\n",
    "    topic['topic'] = tfile.split('.')[0]\n",
    "    topics.append(topic)\n",
    "\n",
    "#with codecs.open('E:\\\\1Now\\\\taglist\\\\core3140.txt', 'r', 'utf-8') as f:\n",
    "#    core31 = f.read().splitlines()\n",
    "#    f.close()\n",
    "\n",
    "#with codecs.open('E:\\\\1Now\\\\taglist\\\\core3787.txt', 'r', 'utf-8') as f:\n",
    "#    core37 = f.read().splitlines()\n",
    "#    f.close()    \n",
    "\n",
    "labels = ('US', 'chiefly US', 'Brit', 'chiefly Brit', 'slang', 'offensive', 'obscene', 'impolite', \n",
    "          'informal', 'formal', 'literary', 'old-fashioned', 'humorous', 'technical', \n",
    "          'disapproving', 'approving', 'medical', 'law', 'baseball', 'mathematics', 'sports', \n",
    "          'grammar', 'trademark', 'old-fashioned')\n",
    "\n",
    "#map IPA image symbols to my ASCII IPA symbols\n",
    "ipa_to_alpha = {\n",
    "    '22089': 'Z', #ZH -> Z\n",
    "    '22212': 'Z', #ZH -> Z\n",
    "    '22369': 'Z', #ZH -> Z\n",
    "    '22077': 'z',\n",
    "    '22200': 'y',\n",
    "    '22047': 'w',\n",
    "    '22005': 'v',\n",
    "    '22218': 'u-Y',\n",
    "    '22167': 'u-B',\n",
    "    '22170': 'u-b',\n",
    "    '22203': 'u-b',\n",
    "    '22137': 'u-A',\n",
    "    '22140': 'u-a',\n",
    "    '22254': 'u-2',\n",
    "    '22152': 'u-1',\n",
    "    '22242': 'u-1',\n",
    "    '22263': 'u-1',\n",
    "    '22294': 'u-1',\n",
    "    '22312': 'u-1',\n",
    "    '22339': 'u-_',\n",
    "    '22185': 'u-^',\n",
    "    '22309': 'u-#',\n",
    "    '22321': 'u-#',\n",
    "    '22029': 'U', # u -> U\n",
    "    '22074': 'u',\n",
    "    '22342': 'U', # u -> U\n",
    "    '22101': 'th', # TH -> th\n",
    "    '22206': 'th', # TH -> th\n",
    "    '22366': 'th', # TH -> th\n",
    "    '22038': 't',\n",
    "    '22044': 'S', # SH -> S\n",
    "    '22209': 'S', # SH -> S\n",
    "    '22363': 'S', # SH -> S\n",
    "    '22014': 's',\n",
    "    '22050': 'r',\n",
    "    '22092': 'p',\n",
    "    '22281': 'p',\n",
    "    '22026': 'o',\n",
    "    '22068': 'N', # NG -> N\n",
    "    '22360': 'N', # NG -> N\n",
    "    '21981': 'n',\n",
    "    '22080': 'n-', # n -> n-\n",
    "    '22357': 'n-', # n -> n-\n",
    "    '22035': 'm',\n",
    "    '22227': 'm',\n",
    "    '22023': 'l',\n",
    "    '22053': 'l-', # l -> l-\n",
    "    '22354': 'l-', # l -> l-\n",
    "    '22008': 'k',\n",
    "    '22071': 'dZ', # JH -> dZ\n",
    "    '22351': 'dZ', # JH -> dZ\n",
    "    '22062': 'j',\n",
    "    '21966': '!', # i -> !\n",
    "    '22032': 'i',\n",
    "    '22333': '!', # i -> !\n",
    "    '22065': 'h',\n",
    "    '22110': 'h',\n",
    "    '22086': 'g',\n",
    "    '22083': 'f',\n",
    "    '21996': '~', # ER -> ~\n",
    "    '22266': '~', # ER -> ~\n",
    "    '22330': '~', # ER -> ~\n",
    "    '21963': 'e',\n",
    "    '22059': 'E', # e -> E\n",
    "    '22269': 'E', # e -> E\n",
    "    '22345': 'E', # e -> E\n",
    "    '22131': 'TH', # DH -> TH\n",
    "    '22116': 'dd', # no change but what 'dd' means?\n",
    "    '21999': 'd',\n",
    "    '22104': 'tS', # CH -> tS\n",
    "    '22348': 'tS', # CH -> tS\n",
    "    '22119': 'b-a',\n",
    "    '22128': 'b-a',\n",
    "    '22011': 'b',    \n",
    "    '22056': '^', # AH -> ^\n",
    "    '22327': '^', # AH -> ^\n",
    "    '21975': '.', # AH -> .\n",
    "    '22272': '.', # AH -> .\n",
    "    '22324': '.', # AH -> .  \n",
    "    '21984': '@', # AE -> @\n",
    "    '21990': 'A', # a -> A\n",
    "    '22020': 'a',\n",
    "    '22257': 'A', # a -> A\n",
    "    '22336': 'A', # a -> A\n",
    "    '22041': 'u-~', # ~ -> u-~\n",
    "    '22002': ',', # ` -> , secondary stress\n",
    "    '21993': ':', # _ -> :\n",
    "    '22260': ':', # _ -> :\n",
    "    '21960': \"'\", # ^ -> ' primary stress\n",
    "    '22149': ';',\n",
    "    '21957': '/',\n",
    "    '21978': '', # , -> null\n",
    "    '21969': '#',\n",
    "    '21972': '#',\n",
    "    '21987': '#',\n",
    "    '22017': '#',\n",
    "    '22095': '#',\n",
    "    '22098': '#',\n",
    "    '22107': '#',\n",
    "    '22113': '#',\n",
    "    '22122': '#',\n",
    "    '22125': '#',\n",
    "    '22134': '#',\n",
    "    '22143': '#',\n",
    "    '22146': '#',\n",
    "    '22155': '#',\n",
    "    '22158': '#',\n",
    "    '22161': '#',\n",
    "    '22164': '#',\n",
    "    '22173': '#',\n",
    "    '22176': '#',\n",
    "    '22179': '#',\n",
    "    '22182': '#',\n",
    "    '22188': '#',\n",
    "    '22191': '#',\n",
    "    '22194': '#',\n",
    "    '22197': '#',\n",
    "    '22215': '#',\n",
    "    '22221': '#',\n",
    "    '22224': '#',\n",
    "    '22230': '#',\n",
    "    '22233': '#',\n",
    "    '22236': '#',\n",
    "    '22239': '#',\n",
    "    '22245': '#',\n",
    "    '22248': '#',\n",
    "    '22251': '#',\n",
    "    '22275': '#',\n",
    "    '22278': '#',\n",
    "    '22284': '#',\n",
    "    '22287': '#',\n",
    "    '22291': '#',\n",
    "    '22297': '#',\n",
    "    '22300': '#',\n",
    "    '22303': '#',\n",
    "    '22306': '#',\n",
    "    '22315': '#',\n",
    "    '22318': '#',\n",
    "    '22372': '#'\n",
    "}\n",
    "\n",
    "# homographs\n",
    "# 2015-11-20 add 'combine', 'recount'\n",
    "audiofile = [\"abstract\", \"abuse\", \"advocate\", \"aggregate\", \"alternate\", \"appropriate\", \"approximate\", \"articulate\", \n",
    "             \"attribute\", \"close\", \"combine\" ,\"compound\", \"concrete\", \"conduct\", \"conflict\", \"consummate\", \"contract\",\n",
    "             \"contrast\", \"decrease\", \"degenerate\", \"desert\", \"digest\", \"essay\", \"excuse\", \"export\", \"graduate\", \"imprint\", \n",
    "             \"incarnate\", \"incense\", \"increase\", \"insult\", \"lead\", \"live\", \"minute\", \"mobile\", \"object\", \"outright\", \n",
    "             \"overhaul\", \"overload\", \"present\", \"produce\", \"progress\", \"project\", \"protest\", \"recall\", \"record\", \"recount\"\n",
    "             \"research\", \"separate\", \"subject\", \"supplement\", \"survey\", \"tear\", \"transfer\", \"wind\"]\n",
    "\n",
    "#mypath = os.getcwd() + \"\\\\rawfile\"\n",
    "mypath = \"E:\\\\dictrawfile-39195\"\n",
    "print mypath\n",
    "onlyfiles = [ f for f in os.listdir(mypath) if isfile(join(mypath,f)) ]\n",
    "\n",
    "cnt = 0  #total words\n",
    "cnt_f = 0 #number of French words\n",
    "cnt_d = 0 #number of words beginning with a dash\n",
    "cnt_sq = 0 #number of words beginning with a single quote\n",
    "\n",
    "kk = 0\n",
    "for fname in onlyfiles:\n",
    "    jsonBody = {}\n",
    "    \n",
    "    fj = codecs.open('E:\\\\dictjson\\\\' + fname + '.json', 'w', 'utf-8')\n",
    "    #print fj\n",
    "    \n",
    "    with open('E:\\\\dictrawfile-39195\\\\' + fname, 'r') as fentry:\n",
    "    #with codecs.open('E:\\\\dictrawfile-39195\\\\' + fname, 'r', 'utf-8') as fentry: #don't work somehow\n",
    "        raw_doc = fentry.read()\n",
    "    #fentry = open('declare.axb8472', 'r')\n",
    "    #hw_doc = fentry.read()\n",
    "        \n",
    "    \n",
    "    #get IPA symbols\n",
    "    #first find the pair of slashes used to mark the beginning and end of a pronunciation\n",
    "    #image21955.gif, image21956.gif, image21957.gif -- images of a slash '/'\n",
    "    patt = '<img hspace=\"0\" align=\"middle\" losrc=\"Images\\/image21955\\.gif\" src=\"Images\\/image21956\\.gif\" hisrc=\"Images\\/image21957\\.gif\"\\/>'\n",
    "    pattern = patt + '(.*?)' + patt\n",
    "    #print pattern\n",
    "    ipa = re.compile(pattern, re.DOTALL)\n",
    "\n",
    "    flag_brit = 0 #suppose there is no British pronunciation\n",
    "    my_pronun = []\n",
    "    for sounds in ipa.findall(raw_doc):\n",
    "        i = 0\n",
    "        for sound in sounds.split('<i>Brit</i>'):\n",
    "            i += 1\n",
    "            ipa_soup = BeautifulSoup(sound)\n",
    "            if i == 1: cmu = ''\n",
    "            elif i == 2: #'Brit'\n",
    "                flag_brit = 1 #there is British pronunciation\n",
    "                break #skip British pronunciation\n",
    "            for symbol in ipa_soup.find_all('img'):\n",
    "                key = symbol['hisrc'][12:-4]\n",
    "                if key in ipa_to_alpha: cmu += ipa_to_alpha[key]\n",
    "                else: cmu += key\n",
    "            #print cmu\n",
    "            #print \"---\\n\"   \n",
    "            my_pronun.append(cmu)\n",
    "    #print my_pronun\n",
    "    if my_pronun: jsonBody['prn'] = my_pronun\n",
    "    if flag_brit == 1: jsonBody['prn_brit'] = 'y'\n",
    "        \n",
    "    \n",
    "    #after getting IPA, remove all image tags    \n",
    "    hw_doc = re.sub(r\"(<img[^>]*\\/>)\", \"\", raw_doc)\n",
    "    #remove Unicode 'middle dot' u+00B7\n",
    "    hw_doc = re.sub(u\"\\u00B7\", \"\", hw_doc)\n",
    "    #print hw_doc\n",
    "    #continue\n",
    "    fentry.close()\n",
    "\n",
    "    soup = BeautifulSoup(hw_doc)\n",
    "\n",
    "    \n",
    "    #get headword\n",
    "    headword = soup.find('idx:orth')\n",
    "    #if headword[0] == \"'\": headword = \"\\\\\" + headword\n",
    "    if headword: \n",
    "        hw = headword['value']\n",
    "        #jsonBody['hw'] = headword['value']\n",
    "        jsonBody['hw'] = hw\n",
    "        kk += 1\n",
    "        print kk, '---', jsonBody\n",
    "    else:\n",
    "        print fname, \": no headword\"\n",
    "        break\n",
    "        \n",
    "    \n",
    "    #check if it is in 3,000 basic English words (not accurate)\n",
    "    basic_word = soup.find('u')\n",
    "    if basic_word: jsonBody['bw'] = 1    \n",
    "    #print jsonBody\n",
    "    \n",
    "\n",
    "    #French words\n",
    "    if fname[0] == '.':\n",
    "        cnt_f += 1\n",
    "        jsonBody[\"fr\"] = \"y\" #is it a Frenche word? yes\n",
    "    elif fname[0] == '-':\n",
    "        cnt_d += 1\n",
    "        jsonBody[\"dash\"] = \"y\" # begin with a dash\n",
    "    elif fname[0] == \"'\":\n",
    "        cnt_sq += 1\n",
    "        jsonBody[\"sq\"] = \"y\" #begin with a single quote '\n",
    "    \n",
    "    \n",
    "    #get inflection\n",
    "    infl = []\n",
    "    for it in soup.find_all('idx:iform'):\n",
    "        infl.append(it['value'])\n",
    "        #print infl\n",
    "    if infl: jsonBody['infl'] = infl\n",
    "\n",
    "    #get id\n",
    "    aid = soup.find(a_has_id)\n",
    "    #print type(aid)\n",
    "    if aid: jsonBody['id'] = aid['id']\n",
    "\n",
    "    #get part of speech\n",
    "    #<i><font color=\"#999999\">noun</font></i>\n",
    "    pos = soup.find(color=\"#999999\")\n",
    "    if pos: jsonBody['pos'] = pos.get_text()\n",
    "\n",
    "        \n",
    "    # if headword in audiofile list, generate \"audiofile\" key and value    \n",
    "    if headword['value'] in audiofile:\n",
    "        print 'in audiofile'\n",
    "        jsonBody['audiofile'] = headword['value'] + \" \" + pos.get_text() # not to append suffix, may wav or mp3\n",
    "    # con is a key word of Windows, a filename as 'con.wav' is not allowed\n",
    "    elif headword['value'] == 'con':\n",
    "        print \"---------con-----------\"\n",
    "        jsonBody['audiofile'] = \"con1\"\n",
    "\n",
    "        \n",
    "    #get labels\n",
    "    label = []\n",
    "    label = soup.find_all(text=labels)\n",
    "    #some labels are not captured in tags, so use regex to get them\n",
    "    if soup.find(text=re.compile(\"figuratively\")): label.append(\"figuratively\")\n",
    "    if soup.find(text=re.compile(\"informal\")): label.append(\"informal\")\n",
    "    #no 'see color picture' in mobi file\n",
    "    #if soup.find_all(text=re.compile(\"see color picture\")): label.append(\"color picture\")\n",
    "    if label: jsonBody['label'] = label\n",
    "\n",
    "    #get common phrases\n",
    "    cplist = []\n",
    "    for item in soup.find_all('span'):\n",
    "        if item.parent.name == 'font': cplist.append(item.get_text())\n",
    "    if cplist: jsonBody['cp'] = cplist\n",
    "\n",
    "    #get all example sentences\n",
    "    examples = []\n",
    "    for it in soup.find_all(color=\"#002984\"):\n",
    "        examples.append(it.get_text())\n",
    "    if examples: jsonBody['alles'] = examples\n",
    "\n",
    "        \n",
    "    #get all idioms & phrasal verbs, including common phrases\n",
    "    idpvs = []\n",
    "    #get sub head words\n",
    "    subhw = []\n",
    "    for item in soup.find_all('span'):\n",
    "        #print item.parent.name, \"---\", item.get_text()\n",
    "        if item.parent.name != 'idx:entry':\n",
    "            if ' ' in item.get_text(): idpvs.append(item.get_text())\n",
    "            else: subhw.append(item.get_text())\n",
    "    if idpvs: jsonBody['idpvs'] = idpvs\n",
    "    if subhw: jsonBody['subhw'] = subhw\n",
    "                \n",
    "\n",
    "    #check if head word or sub head words are in some topic word lists\n",
    "    tag = []\n",
    "    for topic in topics:\n",
    "        if hw in topic['words']: tag.append(topic['topic'])\n",
    "        elif subhw:\n",
    "            for csubhw in subhw:\n",
    "                if csubhw in topic['words']: tag.append(topic['topic'])\n",
    "    if tag: jsonBody['tag'] = tag            \n",
    "            \n",
    "    #check if it is in core3140 words, core3787  \n",
    "    #if hw in core37: jsonBody['core37'] = 1\n",
    "    #if hw in core31: jsonBody['core31'] = 1\n",
    "    #elif subhw:        \n",
    "    #    for csubhw in subhw:\n",
    "    #        if csubhw in core31:\n",
    "    #            jsonBody['core31'] = 1\n",
    "    #            break\n",
    "    \n",
    "        \n",
    "                \n",
    "    #get cross references\n",
    "    cr = {}\n",
    "    for link in soup.find_all(a_has_href):\n",
    "        if link: cr[link.get('href').replace('#','')] = link.get_text().strip()\n",
    "    if cr: jsonBody['cr'] = cr\n",
    "\n",
    "        \n",
    "    #construct definitions & examples\n",
    "    sublist = []\n",
    "    i = 1 #cross reference counter\n",
    "    \n",
    "    # remove j that is not necessary\n",
    "    #j = 1 #idioms & phrasal verbs counter \n",
    "\n",
    "    for it in soup.find_all('blockquote'):\n",
    "        #print it.parent.parent.name, \">>\", it.parent.name, \"---\", it, \"\\n\"\n",
    "        if(it.parent.name=='idx:entry'):\n",
    "            examp = []\n",
    "            defi = it.get_text()\n",
    "            if defi==\" \": continue\n",
    "            for e in it.find_all(color=\"#002984\"):\n",
    "                examp.append(e.get_text())\n",
    "                defi = defi.replace(e.get_text(),\"\")\n",
    "            #print defi\n",
    "            #print examp\n",
    "\n",
    "            subentry = {}\n",
    "            # def is a key word of Python\n",
    "            subentry['defi'] = defi\n",
    "            subentry['es'] = examp\n",
    "            #print subentry\n",
    "            #print sublist                \n",
    "\n",
    "            if subentry: sublist.append(subentry)\n",
    "        \n",
    "        #idioms & phrasal verbs\n",
    "        if(it.parent.name=='div' and it.parent.parent.name!='blockquote'):\n",
    "            subentry = {}\n",
    "            \n",
    "            #just use 'idpv' as key\n",
    "            subentry['idpv'] = it.get_text()\n",
    "            #subentry['idpv'+str(j)] = it.get_text()\n",
    "            #j += 1\n",
    " \n",
    "            #print subentry\n",
    "            if subentry: sublist.append(subentry)\n",
    "\n",
    "            \n",
    "    if sublist: jsonBody['sublist'] = sublist\n",
    "    if jsonBody:\n",
    "        #print jsonBody\n",
    "        cnt += 1\n",
    "        \n",
    "        #dump json into a file\n",
    "        json.dump(jsonBody, fj, indent=4, sort_keys=True)\n",
    "        \n",
    "        # insert into MongoDB database\n",
    "        doc_id = geweiDict.insert(jsonBody)\n",
    "        #print doc_id \n",
    "        shutil.move(\"E:\\\\dictrawfile-39195\\\\\"+fname, \"E:\\\\dictprocessed\\\\\"+fname)\n",
    "    fj.close()\n",
    "\n",
    "print 'total words: ', cnt, ', French words: ', cnt_f, \", begin with a dash:\", cnt_d, \", begin with a ': \", cnt_sq\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "ta = \"a, b, c\"\n",
    "tb = 'dd'\n",
    "print ta.split(',')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acaWriting.txt', 'airTravel.txt', 'bodyPart.txt', 'campus.txt', 'economics.txt', 'emotion.txt', 'employment.txt', 'environment.txt', 'family.txt', 'health.txt', 'job.txt', 'legal.txt', 'list.txt', 'nonCount.txt', 'personality.txt', 'sport.txt', 'timeAdv.txt', 'timePeriod.txt', 'weather.txt']\n"
     ]
    }
   ],
   "source": [
    "with open('core3000\\\\topic.txt', 'r') as f:\n",
    "    lines = f.read().splitlines()\n",
    "print lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "914\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "\n",
    "tfiles = ['acaWriting.txt', 'airTravel.txt', 'bodyPart.txt', 'campus.txt', 'economics.txt', 'emotion.txt', \n",
    "          'employment.txt', 'environment.txt', 'family.txt', 'health.txt', 'job.txt', 'legal.txt', \n",
    "          'nonCount.txt', 'personality.txt', 'sport.txt', 'timeAdv.txt', 'timePeriod.txt', 'weather.txt']\n",
    "topics = []\n",
    "cnt = 0\n",
    "for tfile in tfiles:\n",
    "    topic = {}\n",
    "    with codecs.open('core3000\\\\' + tfile, 'r', 'utf-8') as f:\n",
    "        twords = f.read().splitlines()\n",
    "        cnt += len(twords)\n",
    "        f.close()\n",
    "    topic['words'] = twords\n",
    "    topic['topic'] = tfile.split('.')[0]\n",
    "    topics.append(topic)\n",
    "#print topics    \n",
    "print cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "fcore = codecs.open('core3000\\\\core3140.txt', 'w', 'utf-8')\n",
    "with codecs.open('core3000\\\\core3000raw20151123.txt', 'r', 'utf-8') as f:\n",
    "    lines = f.read().splitlines()\n",
    "\n",
    "cnt = 0    \n",
    "uCore = set()\n",
    "\n",
    "for line in lines:    \n",
    "    uCore.add(line.split('\\t')[0])\n",
    "uCoreSorted = sorted(uCore)    \n",
    "for word in uCoreSorted:\n",
    "    cnt += 1\n",
    "    fcore.write(word+'\\n')\n",
    "    #print cnt, ': ', word\n",
    "fcore.close()    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'decompose'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a6d700773372>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecompose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'decompose'"
     ]
    }
   ],
   "source": [
    "print(soup.img.decompose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpdict.find({\"label\":\"mathematics\"}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpdict.find({\"label\":\"slang\"}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpdict.find({\"label\":\"offensive\"}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "807"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpdict.find({\"label\":\"chiefly US\"}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2615"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpdict.find({\"label\":\"Brit\"}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2027"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.dpdict.find({\"label\":\"US\"}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-208-11f5d97b9c3b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-208-11f5d97b9c3b>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    db.dpdict.find({cp: {$exists: true}}).count()\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "db.dpdict.find({cp: {$exists: true}}).count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': ObjectId('537e93cd8707ee3128063ada'),\n",
       " u'alles': [u'I saw your doppelg\\xe4nger [=(more commonly) double] yesterday.',\n",
       "  u'In the story, the character is haunted by a doppelg\\xe4nger.'],\n",
       " u'fr': u'y',\n",
       " u'hw': u'doppelg\\xe4nger',\n",
       " u'idpvs': [u'dop\\xb7pel\\xb7gang\\xb7er'],\n",
       " u'infl': {u'1np1': u'doppelg\\xe4ngers', u'1ns1': u'doppelg\\xe4nger'},\n",
       " u'label': [u'literary'],\n",
       " u'pos': u'or',\n",
       " u'sublist': [{u'def': u'1 : someone who looks like someone else  ',\n",
       "   u'es': [u'I saw your doppelg\\xe4nger [=(more commonly) double] yesterday.']},\n",
       "  {u'def': u'2 literary : a ghost that looks like a living person ',\n",
       "   u'es': [u'In the story, the character is haunted by a doppelg\\xe4nger.']}]}"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpdict.find_one({'hw': u'doppelg\\xe4nger'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.cursor.Cursor at 0x7993630>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpdict.find({\"id\":\"filepos18005907\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<img hspace=\"0\" align=\"middle\" losrc=\"Images\\/image21955\\.gif\" src=\"Images\\/image21956\\.gif\" hisrc=\"Images\\/image21957\\.gif\"\\/>(.*?)<img hspace=\"0\" align=\"middle\" losrc=\"Images\\/image21955\\.gif\" src=\"Images\\/image21956\\.gif\" hisrc=\"Images\\/image21957\\.gif\"\\/>\n",
      "---\n",
      "\n",
      "Images/image21960.gif\n",
      "Images/image22005.gif\n",
      "Images/image21984.gif\n",
      "Images/image22014.gif\n",
      "Images/image22038.gif\n",
      "Images/image21978.gif\n",
      "---\n",
      "\n",
      "Images/image21960.gif\n",
      "Images/image22005.gif\n",
      "Images/image21990.gif\n",
      "Images/image21993.gif\n",
      "Images/image22014.gif\n",
      "Images/image22038.gif\n",
      "---\n",
      "\n",
      "Images/image21960.gif\n",
      "Images/image22005.gif\n",
      "Images/image21984.gif\n",
      "Images/image22014.gif\n",
      "Images/image22038.gif\n",
      "Images/image21981.gif\n",
      "Images/image21975.gif\n",
      "Images/image22014.gif\n",
      "Images/image21978.gif\n",
      "---\n",
      "\n",
      "Images/image21960.gif\n",
      "Images/image22005.gif\n",
      "Images/image21990.gif\n",
      "Images/image21993.gif\n",
      "Images/image22014.gif\n",
      "Images/image22038.gif\n",
      "Images/image21981.gif\n",
      "Images/image21975.gif\n",
      "Images/image22014.gif\n"
     ]
    }
   ],
   "source": [
    "comment = re.compile(r'/\\*(.*?)\\*/', re.DOTALL)\n",
    "patt = '<img hspace=\"0\" align=\"middle\" losrc=\"Images\\/image21955\\.gif\" src=\"Images\\/image21956\\.gif\" hisrc=\"Images\\/image21957\\.gif\"\\/>'\n",
    "pattern = patt + '(.*?)' + patt\n",
    "print pattern\n",
    "ipa = re.compile(pattern, re.DOTALL)\n",
    "text1 = '/* this is a comment */'\n",
    "text2 = '''/* this is a\n",
    "        multiline comment */\n",
    "        '''\n",
    "text3 = '''<idx:entry scriptable=\"yes\"><idx:orth value=\"vast\"><idx:infl>  <idx:iform name=\"1.adj.pos.1\" value=\"vast\"/></idx:infl><idx:infl>  <idx:iform name=\"2.n.s.1\" value=\"vast\"/>  <idx:iform name=\"2.n.p.1\" value=\"vasts\"/></idx:infl></idx:orth><a id=\"filepos83514877\" /><span><font size=\"3\"><b><u>vast</u></span> <img hspace=\"0\" align=\"middle\" losrc=\"Images/image21955.gif\" src=\"Images/image21956.gif\" hisrc=\"Images/image21957.gif\"/><img hspace=\"0\" align=\"middle\" losrc=\"Images/image21958.gif\" src=\"Images/image21959.gif\" hisrc=\"Images/image21960.gif\"/><img hspace=\"0\" align=\"middle\" losrc=\"Images/image22003.gif\" src=\"Images/image22004.gif\" hisrc=\"Images/image22005.gif\"/><img hspace=\"0\" align=\"middle\" losrc=\"Images/image21982.gif\" src=\"Images/image21983.gif\" hisrc=\"Images/image21984.gif\"/><img hspace=\"0\" align=\"middle\" losrc=\"Images/image22012.gif\" src=\"Images/image22013.gif\" hisrc=\"Images/image22014.gif\"/><img hspace=\"0\" align=\"middle\" losrc=\"Images/image22036.gif\" src=\"Images/image22037.gif\" hisrc=\"Images/image22038.gif\"/><img hspace=\"0\" align=\"middle\" losrc=\"Images/image21976.gif\" src=\"Images/image21977.gif\" hisrc=\"Images/image21978.gif\"/> <i>Brit</i> <img hspace=\"0\" align=\"middle\" losrc=\"Images/image21958.gif\" src=\"Images/image21959.gif\" hisrc=\"Images/image21960.gif\"/><img hspace=\"0\" align=\"middle\" losrc=\"Images/image22003.gif\" src=\"Images/image22004.gif\" hisrc=\"Images/image22005.gif\"/><img hspace=\"0\" align=\"middle\" losrc=\"Images/image21988.gif\" src=\"Images/image21989.gif\" hisrc=\"Images/image21990.gif\"/><img hspace=\"0\" align=\"middle\" losrc=\"Images/image21991.gif\" src=\"Images/image21992.gif\" hisrc=\"Images/image21993.gif\"/><img hspace=\"0\" align=\"middle\" losrc=\"Images/image22012.gif\" src=\"Images/image22013.gif\" hisrc=\"Images/image22014.gif\"/><img hspace=\"0\" align=\"middle\" losrc=\"Images/image22036.gif\" src=\"Images/image22037.gif\" hisrc=\"Images/image22038.gif\"/><img hspace=\"0\" align=\"middle\" losrc=\"Images/image21955.gif\" src=\"Images/image21956.gif\" hisrc=\"Images/image21957.gif\"/> <i><font color=\"#999999\">adj</font></i>, <b>vastr</b>, <b>-est</b> [<i>more <img hspace=\"0\" align=\"middle\" losrc=\"Images/image22039.gif\" src=\"Images/image22040.gif\" hisrc=\"Images/image22041.gif\"/>; most <img hspace=\"0\" align=\"middle\" losrc=\"Images/image22039.gif\" src=\"Images/image22040.gif\" hisrc=\"Images/image22041.gif\"/></i>]<blockquote align=\"left\"> <b>:</b> very great in size, amount, or extent <blockquote align=\"left\"><font color=\"#002984\">She has a <i>vast</i> amount of knowledge on this subject.</font></blockquote> <blockquote align=\"left\"><font color=\"#002984\"><i>vast</i> quantities of information</font></blockquote> <blockquote align=\"left\"><font color=\"#002984\">The policy is supported by the <i>vast</i> majority of citizens.</font></blockquote> <blockquote align=\"left\"><font color=\"#002984\">a <i>vast</i> expanse of land</font></blockquote></blockquote> <img hspace=\"0\" vspace=\"0\" align=\"middle\" src=\"Images/image21970.gif\"/><div align=\"left\"><blockquote><span><font size=\"3\"><b>vasty</span> <i><font color=\"#999999\">adv</font></i> <blockquote><font color=\"#002984\">His background is <i>vastly</i> different from mine.</font></blockquote> <blockquote><font color=\"#002984\">They <i>vastly</i> increased spending.</font></blockquote></blockquote> </div>\n",
    "\n",
    "<img hspace=\"0\" vspace=\"0\" align=\"middle\" src=\"Images/image21970.gif\"/><div align=\"left\"><blockquote><span><font size=\"3\"><b>vastess</span> \n",
    "\n",
    "<img hspace=\"0\" align=\"middle\" losrc=\"Images/image21955.gif\" src=\"Images/image21956.gif\" hisrc=\"Images/image21957.gif\"/>\n",
    "<img hspace=\"0\" align=\"middle\" losrc=\"Images/image21958.gif\" src=\"Images/image21959.gif\" hisrc=\"Images/image21960.gif\"/>\n",
    "<img hspace=\"0\" align=\"middle\" losrc=\"Images/image22003.gif\" src=\"Images/image22004.gif\" hisrc=\"Images/image22005.gif\"/>\n",
    "<img hspace=\"0\" align=\"middle\" losrc=\"Images/image21982.gif\" src=\"Images/image21983.gif\" hisrc=\"Images/image21984.gif\"/>\n",
    "<img hspace=\"0\" align=\"middle\" losrc=\"Images/image22012.gif\" src=\"Images/image22013.gif\" hisrc=\"Images/image22014.gif\"/>\n",
    "<img hspace=\"0\" align=\"middle\" losrc=\"Images/image22036.gif\" src=\"Images/image22037.gif\" hisrc=\"Images/image22038.gif\"/>\n",
    "<img hspace=\"0\" align=\"middle\" losrc=\"Images/image21979.gif\" src=\"Images/image21980.gif\" hisrc=\"Images/image21981.gif\"/>\n",
    "<img hspace=\"0\" align=\"middle\" losrc=\"Images/image21973.gif\" src=\"Images/image21974.gif\" hisrc=\"Images/image21975.gif\"/>\n",
    "<img hspace=\"0\" align=\"middle\" losrc=\"Images/image22012.gif\" src=\"Images/image22013.gif\" hisrc=\"Images/image22014.gif\"/>\n",
    "<img hspace=\"0\" align=\"middle\" losrc=\"Images/image21976.gif\" src=\"Images/image21977.gif\" hisrc=\"Images/image21978.gif\"/>\n",
    " <i>Brit</i> \n",
    " <img hspace=\"0\" align=\"middle\" losrc=\"Images/image21958.gif\" src=\"Images/image21959.gif\" hisrc=\"Images/image21960.gif\"/>\n",
    " <img hspace=\"0\" align=\"middle\" losrc=\"Images/image22003.gif\" src=\"Images/image22004.gif\" hisrc=\"Images/image22005.gif\"/>\n",
    " <img hspace=\"0\" align=\"middle\" losrc=\"Images/image21988.gif\" src=\"Images/image21989.gif\" hisrc=\"Images/image21990.gif\"/>\n",
    " <img hspace=\"0\" align=\"middle\" losrc=\"Images/image21991.gif\" src=\"Images/image21992.gif\" hisrc=\"Images/image21993.gif\"/>\n",
    " <img hspace=\"0\" align=\"middle\" losrc=\"Images/image22012.gif\" src=\"Images/image22013.gif\" hisrc=\"Images/image22014.gif\"/>\n",
    " <img hspace=\"0\" align=\"middle\" losrc=\"Images/image22036.gif\" src=\"Images/image22037.gif\" hisrc=\"Images/image22038.gif\"/>\n",
    " <img hspace=\"0\" align=\"middle\" losrc=\"Images/image21979.gif\" src=\"Images/image21980.gif\" hisrc=\"Images/image21981.gif\"/>\n",
    " <img hspace=\"0\" align=\"middle\" losrc=\"Images/image21973.gif\" src=\"Images/image21974.gif\" hisrc=\"Images/image21975.gif\"/>\n",
    " <img hspace=\"0\" align=\"middle\" losrc=\"Images/image22012.gif\" src=\"Images/image22013.gif\" hisrc=\"Images/image22014.gif\"/>\n",
    "<img hspace=\"0\" align=\"middle\" losrc=\"Images/image21955.gif\" src=\"Images/image21956.gif\" hisrc=\"Images/image21957.gif\"/> \n",
    "\n",
    "\n",
    "<i><font color=\"#999999\">noun</font></i> [<i>noncount</i>] <blockquote><font color=\"#002984\">the <i>vastness</i> of the desert/ocean</font></blockquote></blockquote></div></idx:entry><div><img hspace=\"0\" vspace=\"0\" align=\"middle\" src=\"Images/image21971.gif\"/></div><div><table width=\"100%\" bgcolor=\"#7593CD\"><tr><th widht=\"100%\" height=\"2px\"/></tr></table></div><div><img hspace=\"0\" vspace=\"0\" align=\"middle\" src=\"Images/image21972.gif\"/></div> \n",
    " \n",
    " '''\n",
    "#comment.findall(text1)\n",
    "#comment.findall(text2)\n",
    "for sounds in ipa.findall(text3):\n",
    "    for sound in sounds.split('<i>Brit</i>'):\n",
    "        print \"---\\n\"\n",
    "        soup = BeautifulSoup(sound)\n",
    "        for symbol in soup.find_all('img'):\n",
    "            print symbol['hisrc']\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vowels\n",
    "\n",
    "@   ask bat glad\n",
    "\n",
    "a:   : cot bomb caught paw\n",
    "\n",
    "e     bet fed\n",
    "\n",
    ".     about banana collide\n",
    "\n",
    "i  i very any thirty\n",
    "\n",
    "i:   i: eat bead bee\n",
    "\n",
    "!     id bid pit\n",
    "\n",
    "u    foot should put\n",
    "\n",
    "u:  u: boot two coo\n",
    "\n",
    "^    under putt bud\n",
    "\n",
    "~    merge bird further\n",
    "\n",
    "ei   e eight wade bay\n",
    "\n",
    "ai   a ice bite tie\n",
    "\n",
    "au   a out gown plow\n",
    "\n",
    "oi    o oyster coil boy\n",
    "\n",
    "ou   o oat own zone blow\n",
    "\n",
    "a~   car heart bizarre\n",
    "\n",
    "e~  e bare fair wear\n",
    "\n",
    "i~   i near deer mere pier\n",
    "\n",
    "o~   o boar port door shore\n",
    "\n",
    "u~   u boor tour insure\n",
    "\n",
    "\n",
    "Consonants\n",
    "\n",
    "b   b baby labor cab\n",
    "\n",
    "d   d day kid\n",
    "\n",
    "dZ    just badger fudge\n",
    "\n",
    "TH   then either bathe\n",
    "\n",
    "f   f foe tough buff\n",
    "\n",
    "g   g go dagger bag\n",
    "\n",
    "h   h hot ahead\n",
    "\n",
    "j   j yes vineyard\n",
    "\n",
    "k   k lacquer flock skin\n",
    "\n",
    "l   l law hollow\n",
    "\n",
    "l-   l pedal battle final\n",
    "\n",
    "m   m mat hemp hammer rim\n",
    "\n",
    "n   n new tent tenor run\n",
    "\n",
    "n-   n button satin kitten\n",
    "\n",
    "N    rung hang swinger\n",
    "\n",
    "p   p lapse top lip speed\n",
    "\n",
    "r   r rope arrive\n",
    "\n",
    "s   s sad mist kiss\n",
    "\n",
    "S    shoe mission slush\n",
    "\n",
    "t   t mat stick late\n",
    "\n",
    "(t toe attack)\n",
    "\n",
    "( later catty riddle)\n",
    "\n",
    "tS   t batch nature\n",
    "\n",
    "(t choose chin achieve)\n",
    "\n",
    "th    thin ether bath\n",
    "\n",
    "v   v vat never cave\n",
    "\n",
    "w   w wet software\n",
    "\n",
    "z   z zoo easy buzz\n",
    "\n",
    "Z    vision azure beige\n",
    "\n",
    "Other Symbols\n",
    "\n",
    "'   ' penmanship\n",
    ",   penmanship\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "#connect to MongoDB\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client.dpdb\n",
    "dpdict = db.dpdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'His outburst seemed incongruous to those who know him well.', u'The style of the porch is incongruous with [=does not match] the style of the house overall.', u'The modern sculpture seems incongruous [=out of place] among all the antiques.']\n",
      "[{u'def': u' : strange because of not agreeing with what is usual or expected   ', u'es': [u'His outburst seemed incongruous to those who know him well.', u'The style of the porch is incongruous with [=does not match] the style of the house overall.', u'The modern sculpture seems incongruous [=out of place] among all the antiques.']}, {u'idpv1': u'in\\xb7con\\xb7gru\\xb7i\\xb7ty noun, pl -ties [count, noncount]'}, {u'idpv2': u'in\\xb7con\\xb7gru\\xb7ous\\xb7ly adv'}]\n"
     ]
    }
   ],
   "source": [
    "words = dpdict.find({\"hw\":\"incongruous\"})\n",
    "for word in words:\n",
    "    print word.get(\"alles\")\n",
    "    print word.get(\"sublist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
