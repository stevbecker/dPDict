{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Project Dict"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Project Name**: Dict  \n",
      "**Initiation Date**: 2014-04-01  \n",
      "\n",
      "**Goals**:\n",
      "\n",
      "* Build a tool to create a customized dictionary which includes definitions, example sentences, sound files, and pronunciation for a text file or a word-list.\n",
      "* Build a solid foundation and routine to master American English\n",
      "* Build a solid tool foundation for mastering data science\n",
      "\n",
      "**Means**\n",
      "\n",
      "* Desgin database by MySQL Workbench\n",
      "* Load the whole dictionary into MySQL database\n",
      "* Graph the linked words (linked data)\n",
      "* Use D3.js\n",
      "* Keep track of word study progress by Excel forgetting curve\n",
      "* PowerPivot connects to MySQL\n",
      "\n",
      "**Datasets**:\n",
      "\n",
      "* Merriam-Webster's Advanced Learner's English Dictionary (Merriam-Webster 2008)\n",
      "* GRE tests\n",
      "* M-W API\n",
      "* M-W sound files of words\n",
      "* Wordnet\n",
      "* CMU Pronunciation dict\n",
      "* Most common words\n",
      "* Words I have known\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Know & Pre-process the Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This process is also called Exploratory Data Analysis (EDA).\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exploratory Data Analysis (EDA)**\n",
      "\n",
      "\n",
      "Pre-processing\n",
      "\n",
      "Split the file to about 20 files (use split command ~~a software 'Free-File-Splitter-v5.0.1189'~~), so I can open the split files in Notepad++ to check them.\n",
      "\n",
      "    $ split -l 1 MWDictASample.html dict\n",
      "\n",
      "In Notepad++, open a split file, find tag patterns by Regular Expressions.\n",
      "\n",
      "\n",
      "To find patterns, first remove all <img ... /> , but it is just a means to end. The <img ... /> includes phonetic information. So finally I have to use as much information as possible in the original file. Don't discard any useful messages.\n",
      "\n",
      "sed command:\n",
      "    s/<img[^>]*\\/>//g\n",
      "(use http://rubular.com/ to check the regex)\n",
      "(see p.418 of Regular Expressions Cookbook by Goyvaerts, Levithan (O'Reilly 2012))\n",
      "\n",
      "\n",
      "**First, know the data. Find patterns in the data.**  \n",
      "Sample the data because it is too big to check all of it.  \n",
      "Know Mobipocket custom tags\n",
      "\n",
      "\n",
      "Explore the beginning part of the data:  \n",
      "In the header section, there are\n",
      "\n",
      "    <mbp:pagebreak/>\n",
      "    <mbp:frameset> (there should be a </mbd:frameset> at the end of the data?)\n",
      "    \n",
      "Main entries separated by\n",
      "\n",
      "    \" <idx:entry\" (the first character is a white space) (the head)\n",
      "    'src=\"Images/image21972.gif\"/></div>' (the end)\n",
      "\n",
      "Explore the end part of the data. I create 3 files.\n",
      "\n",
      "* M-WDictHeadSection.txt\n",
      "* M-WDictEndSection.txt\n",
      "* M-WDictASample.html (Head section + two words + End section)\n",
      "\n",
      "\n",
      "**Divide & Conquer**\n",
      "Split every main entry into a file whose name is the name of the main entry.  \n",
      "use shell script or Python?  \n",
      "`sed | csplit`  \n",
      "\n",
      "(See p.101-102 of Introducing Regular Expressions by Fitzgerald (O'Reilly 2012), sed often is used with other Linux commands)\n",
      "\n",
      "    grep -Eo '<[_a-zA-Z][^>]*>' lorem.dita | sort | uniq | sed -f xslt.sed\n",
      "\n",
      "    $ csplit -k MWDictASample.html '/<idx:entry /' {*}\n",
      "    # -k (Leaves created file segments intact in the event of an error.)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Every entry is a XML file, use Python to process it?\n",
      "\n",
      "Then for each main entry, get its name from `<idx:orth value=\"accommodate\">` for its file.\n",
      "\n",
      "Bash Scripting & Read File line by line\n",
      "`3f.sh`\n",
      "\n",
      "```bash\n",
      "#st=\"Hallo World <idx:orth value=\\\"abc\\\">\"\n",
      "regg='<idx:orth value=\\\"([^>]*)\\\"'\n",
      "while read line\n",
      "do\n",
      "  st=$line\n",
      "  [[ $st =~ $regg ]] && echo ${BASH_REMATCH[1]}\n",
      "  cp $1 ${BASH_REMATCH[1]}\n",
      "done < $1\n",
      "\n",
      "$chmod u+x 3f.sh\n",
      "$ ./3f.sh abc04\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "Hand make a sample file for processing and checking if the result is what I want.\n",
      "\n",
      "Search\n",
      "\n",
      "    \"<idx:orth value=\" \n",
      "    main entry: <idx:orth value=\"writer\">\n",
      "    \"<font size=\"3\">\" \n",
      "\n",
      "phrase (verb): `<span><font size=\"3\"><b>`have (something) written all over it`</span>`  \n",
      "sub-entry(but has problem with the black spot separation): `<span><font size=\"3\"><b>wry\u7a55y</span>`\n",
      "\n",
      "\n",
      "headwords\n",
      "\n",
      "phrasal verbs\n",
      "\n",
      "idioms\n",
      "\n",
      "**common phrases**  \n",
      "Many **common phrases** are highlighted in examples and are sometimes followed by explanations.\n",
      "How to extract them?\n",
      "\n",
      "--suffix\n",
      "\n",
      "forms and tenses\n",
      "\n",
      "cliche\n",
      "\n",
      "2014-04-02\n",
      "Learn regex, sed, svn, git\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Reference"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "Mining the Social Web by Russell (O'Reilly 2013)\n",
      "\n",
      "http://shiffman.net/teaching/a2z/\n",
      "\n",
      "http://www.mobipocket.com/dev/article.asp?BaseFolder=prcgen&File=tagref_mobi.xml\n",
      "\n",
      "http://www.gnu.org/software/coreutils/manual/html_node/csplit-invocation.html#csplit-invocation  \n",
      "http://publib.boulder.ibm.com/infocenter/pseries/v5r3/index.jsp?topic=/com.ibm.aix.cmds/doc/aixcmds1/csplit.htm\n",
      "\n",
      "http://rubular.com/\n",
      "\n",
      "\n",
      "http://en.wikipedia.org/wiki/Pronunciation_respelling_for_English\n",
      "\n",
      "\t* AB \u2013 Arpabet, a commonly used computerized encoding of English pronunciation. It is used by the CMU Pronouncing Dictionary.\n",
      "\n",
      "http://en.wikipedia.org/wiki/Arpabet\n",
      "\n",
      "a machine-readable pronunciation dictionary for North American English\n",
      "\n",
      "* http://en.wikipedia.org/wiki/CMU_Pronouncing_Dictionary\n",
      "* http://www.speech.cs.cmu.edu/cgi-bin/cmudict\n",
      "* http://www.speech.cs.cmu.edu/tools/lmtool-new.html\n",
      "\n",
      "\n",
      "http://en.wikipedia.org/wiki/Grady_Ward  \n",
      "http://en.wikipedia.org/wiki/Moby_Project#Pronunciator\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "EDA by bash Programming"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Learn bash programming with bash Cookbook by Albing, Vossen, Newham (O'Reilly 2007)  \n",
      "6.8 Testing with Regular Expressions\n",
      "\n",
      "```bash\n",
      "#!/usr/bin/bash\n",
      "#filename: trackMatch\n",
      "\n",
      "for flist in *\n",
      "do\n",
      "  echo $flist\n",
      "done\n",
      "```\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "because csplit can't split multiple matches in one line, I add '\\n' to the data.  \n",
      "```bash\n",
      "$ sed 's/<idx:entry/\\n<idx:entry/g' M-W_AdvancedLearnersEnglishDictionary.html > mwLineBreak\n",
      "```  \n",
      "Then split\n",
      "\n",
      "```bash\n",
      "$ csplit -f axb -k mwLineBreak '/<idx:entry/' {*}\n",
      "$ ls axb* |wc -l\n",
      "39199\n",
      "```\n",
      "It took about 30 minutes to rename and copy all the 39199 files. The last processed word is 'dramatis personae'.\n",
      "\n",
      "Result files:\n",
      "\n",
      "* 39111 entries\n",
      "* `.axb00` is the head section, no word in it.\n",
      "* `zygote.axb39198` is the word 'zygote', which is the last word in the dictionary. Remove the end section of the file; just keep contents related to the word 'zygote'.\n",
      "* 84 files include sepecial characters. Need to be processed specially. They are:\n",
      "  - vicu\u00f1a, voil\u00e0\n",
      "\n",
      "So, I get 39111 + 84 = **39195** entries. But\n",
      "\n",
      "```bash\n",
      "$ grep -Eo '<idx:entry ' M-W_AdvancedLearnersEnglishDictionary.html | wc -l\n",
      "39198\n",
      "$ grep -Eo 'image21972' M-W_AdvancedLearnersEnglishDictionary.html | wc -l\n",
      "39198\n",
      "\n",
      "```\n",
      "*(See p.31 and p.38 of grep Pocket Reference by Bambenek, Klus (O'Reilly 2009) for the option of -o, -E)*\n",
      "\n",
      "Why is different? <font color='red'>What are the 3 entries?</font>\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Bash Script to Execute Command on All Files in Directory**\n",
      "```bash\n",
      "#!/usr/bin/bash\n",
      "#rename each entry file with entry name\n",
      "#\n",
      "for entry in axb*\n",
      "do\n",
      "#  echo $entry\n",
      "  ./3f.sh $entry\n",
      "done\n",
      "```\n",
      "\n",
      "**bash String-manipulation operators**  \n",
      "`inside ${ ... }`  \n",
      "*name/pattern/string* Replace first occurrence  \n",
      "*name//pattern/string* Replace all occurrences  \n",
      "(p.106 of bash Cookbook by Albing, Vossen, Newham (O'Reilly 2007))"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Drill Down in One Word"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "regg='<idx:orth value=\\\"([^>]*)\\\"'\n",
      "while read line\n",
      "do\n",
      "  st=$line\n",
      "  [[ $st =~ $regg ]]\n",
      "  orname=${BASH_REMATCH[1]}\n",
      "# echo $orname\n",
      "# [[ $st =~ $regg ]] && echo ${BASH_REMATCH[1]}\n",
      "  fname=${orname//[ ]/_}\n",
      "  echo $fname\n",
      "  cp $1 \"../tafew/\"$fname\".\"$1\n",
      "#  cp $1 \"../tafew/\"${BASH_REMATCH[1]}\".\"$1\n",
      "done < $1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}