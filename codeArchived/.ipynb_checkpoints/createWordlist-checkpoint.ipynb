{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# what are basic words of mwl?\n",
    "import codecs\n",
    "with codecs.open('E:\\\\1Now\\\\taglist\\\\3775BasicWordsfromDB.txt', 'r', 'utf-8') as f:\n",
    "    lines = f.read().splitlines()\n",
    "words = sorted(lines, key=lambda s: s.lower())\n",
    "f = codecs.open('E:\\\\1Now\\\\taglist\\\\bwrawSort.txt', 'w', 'utf-8')\n",
    "for word in words:\n",
    "    f.write(word + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# don't use this function (checkBymwBen) since 2015-12-06\n",
    "\n",
    "# check word lists \n",
    "# these word lists include (number in parentheses are the number of files)\n",
    "#   * words of 18 topics from mwl website (18)\n",
    "#   * 3140 core words from mwl website (1)\n",
    "#   * words of \"The Spelling of Different Sounds in English\" (1)\n",
    "#   * words of word roots, prefixes, suffixes (3)\n",
    "#   sub-total: 23\n",
    "#\n",
    "#   * words of mwl single images (1)\n",
    "#   * words of mwl group images (108)\n",
    "#   sub-total: 109\n",
    "#\n",
    "#   * homographs (1)\n",
    "#   * 3787 core words I collect (1)\n",
    "#   sub-total: 2\n",
    "# \n",
    "#   Total: 135\n",
    "\n",
    "import codecs\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "def checkBymwBen(path, wordlist):\n",
    "    '''get sorted unique head words of mwl for a word list which may include inflections and/or sub hws'''\n",
    "    \n",
    "    hwreturn = [] # hws returned by this function    \n",
    "    \n",
    "    # word list I want to check\n",
    "    with codecs.open(path + wordlist, 'r', 'utf-8') as f:\n",
    "        txtraw = f.read().splitlines()\n",
    "    print '\\n\\n------', wordlist, '------'\n",
    "    print '* has words : ', len(txtraw)\n",
    "    print '* has unique word number: ', len(set(txtraw))\n",
    "    dupinraw = set([x for x in txtraw if txtraw.count(x) > 1])\n",
    "    if dupinraw: print '* has duplicates: ', dupinraw\n",
    "\n",
    "\n",
    "    # with codecs.open(\"E:\\\\1Now\\\\taglist\\\\mwl77Entry.txt\", 'r', 'utf-8') as f:\n",
    "    with codecs.open(\"E:\\\\1Now\\\\taglist\\\\mwlBenchmark.txt\", 'r', 'utf-8') as f:    \n",
    "        lines = f.read().splitlines()\n",
    "\n",
    "    # create mwBen dictionary\n",
    "    mwBens = []\n",
    "    hws = [] # sorted unique hws\n",
    "    hwsC = [] # sorted unique capitalized hws\n",
    "    for line in lines:\n",
    "        entry = {}\n",
    "        hw = line.split(';')[1]\n",
    "        entry['hw'] = hw\n",
    "        entry['deriv'] = line.split(';')[0] # derivative, or hw that has no derivatives\n",
    "        mwBens.append(entry)\n",
    "        hws.append(hw)\n",
    "        if hw[0] in string.lowercase[0:26]:\n",
    "            hwsC.append(hw.capitalize())\n",
    "        \n",
    "    hws = sorted(set(hws))\n",
    "    hwsC = sorted(set(hwsC))        \n",
    "\n",
    "#     print 'mwBens: ', len(mwBens)\n",
    "#     print 'hws: ', len(hws)\n",
    "#     print 'hwsC: ', len(hwsC)\n",
    "\n",
    "\n",
    "    # begin to check the word list against mw benchmark dictionary\n",
    "    #  Word; Its-hw (Head Word)\n",
    "    #\n",
    "    # Three cases (the first two cases return hw)\n",
    "    # 1. word is exactly same as hw or is a capitalized hw\n",
    "    # 2. word is a derivative or is a capitalized derivative\n",
    "    # 3. word is not in mwBen\n",
    "\n",
    "\n",
    "    wordhw = [] # word is exactly same as hw\n",
    "    wordhwC = [] # word is same as capitalized hw\n",
    "    wordderiv = [] # derivatives or capitalized derivatives\n",
    "    wordnotBen = [] # word is not in mwBen\n",
    "\n",
    "    for word in txtraw:\n",
    "        hwflag = 0\n",
    "        derivflag = 0\n",
    "        \n",
    "        if word in hws:\n",
    "            wordhw.append(word)\n",
    "            hwreturn.append(word)\n",
    "            hwflag = 1\n",
    "        elif word.capitalize() in hws: # like leo\n",
    "            wordhw.append(word)\n",
    "            hwreturn.append(word.capitalize())\n",
    "            hwflag = 1            \n",
    "        elif word in hwsC: # like Walk\n",
    "            wordhwC.append(word)\n",
    "            hwreturn.append(word.lower())\n",
    "            hwflag = 1\n",
    "\n",
    "        if hwflag == 0:\n",
    "            dercnt = 0\n",
    "            for mwben in mwBens:                \n",
    "                if word == mwben['deriv'] or word == mwben['deriv'].capitalize() or word.capitalize() == mwben['deriv']:\n",
    "                    wordderiv.append(word)\n",
    "                    hwreturn.append(mwben['hw'])\n",
    "                    derivflag = 1\n",
    "                    print 'derivative: ', word, '--- hw: ', mwben['hw']\n",
    "                    dercnt += 1\n",
    "            if dercnt > 1: print word, '--- derivate has multiple hws --- ', dercnt\n",
    "\n",
    "        if hwflag == 0 and derivflag == 0:\n",
    "            if word.find(' ') == -1: wordnotBen.append(word)\n",
    "            else:\n",
    "                print '>>> >>> >>> >>> >> not a single word: ', word\n",
    "                for x in word.split(' '):\n",
    "                    if x in hws: hwreturn.append(x)\n",
    "                    elif x.capitalize() in hws: hwreturn.append(x.capitalize())\n",
    "                    elif x in hwsC: hwreturn.append(x.lower())\n",
    "                    else:\n",
    "                        wdflagx = 0 \n",
    "                        for mwben in mwBens:                \n",
    "                            if x == mwben['deriv'] or x == mwben['deriv'].capitalize() \\\n",
    "                            or x.capitalize() == mwben['deriv']:\n",
    "                                hwreturn.append(mwben['hw'])\n",
    "                                wdflagx = 1\n",
    "                        if wdflagx == 0: print '**************^^^^^^^!!@@@@@*************** really is not in mwBen: ', x\n",
    "                                \n",
    "                            \n",
    "            \n",
    "    \n",
    "    if wordhw: print '* same as hw: ', len(wordhw)  #,' -- ', wordhw\n",
    "    if wordhwC: print '* same as capitalized hw: ', len(wordhwC)  #,' -- ', wordhwC\n",
    "    if wordderiv: print '* words are derivatives: ', len(wordderiv) #,' -- ', wordderiv\n",
    "        \n",
    "    if len(txtraw) == len(wordhw) + len(wordhwC) + len(wordderiv) + len(wordnotBen): \n",
    "        if wordnotBen:\n",
    "            print '**************##########***************** not in mwBen: ', len(wordnotBen), ' -- ', wordnotBen\n",
    "#         print '--- len(txtraw) == len(wordhw) + len(wordhwC) + len(wordderiv) + len(wordnotBen) ---\\n'\n",
    "    else: print \"--- words' numbers don't mattch, check ---\\n\"\n",
    "    \n",
    "    dupl = [x for x in hwreturn if hwreturn.count(x)>1]\n",
    "    if dupl:\n",
    "        print 'how many duplicates in raw hwreturn --- ', len(dupl), ' - ', len(set(dupl)), ' = ', len(dupl)-len(set(dupl))\n",
    "        print dupl\n",
    "\n",
    "    print '\\nhow many hws supposed to be returned--- ', len(txtraw) - len(wordnotBen) - (len(dupl)-len(set(dupl)))\n",
    "    hwreturn = sorted(set(hwreturn))\n",
    "    print 'acutal return: ', len(hwreturn)\n",
    "    return hwreturn\n",
    "    \n",
    "print checkBymwBen('E:\\\\1Now\\\\taglist\\\\', 'testmwBen.txt')\n",
    "\n",
    "# result = checkBymwBen('E:\\\\1Now\\\\taglist\\\\', '3744BasicWords.txt')\n",
    "# f = codecs.open(\"E:\\\\1Now\\\\taglist\\\\2939BasicWords.txt\", 'w', 'utf-8')\n",
    "# for x in result:\n",
    "#     f.write(x + '\\n')\n",
    "# f.close()\n",
    "\n",
    "\n",
    "# import os\n",
    "# from os import listdir\n",
    "# from os.path import isfile, join\n",
    "\n",
    "# wlpath = \"E:\\\\1Now\\\\taglist\\\\mwlimgGrpwlRaw\\\\\"\n",
    "# for wlname in os.listdir(wlpath):\n",
    "#     if isfile(join(wlpath, wlname)):\n",
    "#         result = checkBymwBen(wlpath, wlname)\n",
    "#     else: continue\n",
    "    \n",
    "#     f = codecs.open(\"E:\\\\1Now\\\\taglist\\\\mwlimgGrpwl\\\\\" + wlname, 'w', 'utf-8')\n",
    "#     for x in result:\n",
    "#         f.write(x + '\\n')\n",
    "#     f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---words not excluded---\n",
      "22  words not excluded\n",
      "\n",
      "---in mw77 words: 10\n",
      "animation\n",
      "blasé\n",
      "bloodstream\n",
      "café\n",
      "caricature\n",
      "consciousness\n",
      "goofy\n",
      "laid-back\n",
      "opinionated\n",
      "tame\n",
      "deck:sPlay hw:animation or hw:blasé or hw:bloodstream or hw:café or hw:caricature or hw:consciousness or hw:goofy or hw:laid-back or hw:opinionated or hw:tame or\n",
      "\n",
      "---not in mw77: 12\n",
      "-\n",
      "09\n",
      "2\n",
      "29\n",
      "3\n",
      "47-3\n",
      "53-4\n",
      "DOCTER\n",
      "PD1\n",
      "PD2\n",
      "dendrites\n",
      "that's\n"
     ]
    }
   ],
   "source": [
    "# apply beautifulExclu.txt to a text\n",
    "\n",
    "import codecs\n",
    "import re\n",
    "\n",
    "# text I want to analyze\n",
    "wlflag = 0 # if wlflag==1, input file is already a word list, no need to create one\n",
    "with codecs.open(\"E:\\\\1Now\\\\mae\\\\article\\\\pd12.txt\", 'r', 'utf-8') as f:\n",
    "    txtlines = f.read().splitlines()  \n",
    "#     f.close()\n",
    "\n",
    "with codecs.open(\"E:\\\\1Now\\\\mae\\\\beautifulExclu.txt\", 'r', 'utf-8') as f:\n",
    "    bexclus = f.read().splitlines()\n",
    "#     f.close()\n",
    "bexclus2 = [x.capitalize() for x in bexclus]\n",
    "\n",
    "with codecs.open(\"E:\\\\1Now\\\\taglist\\\\mwlBenchmark.txt\", 'r', 'utf-8') as f:\n",
    "    mwlines = f.read().splitlines()\n",
    "#     f.close()\n",
    "    \n",
    "mw77s = []\n",
    "for line in mwlines:\n",
    "    entry = {}\n",
    "    entry['hw'] = line.split(';')[1]\n",
    "    entry['subhw'] = line.split(';')[0]\n",
    "#     if entry['hw'] == \"they're\": print entry\n",
    "    mw77s.append(entry)\n",
    "    \n",
    "    # add a duplicate but first word of subhw is uppercase\n",
    "    entry = {}\n",
    "    entry['hw'] = line.split(';')[1]\n",
    "    entry['subhw'] = line.split(';')[0].capitalize() \n",
    "#     if entry['hw'] == \"they're\": print entry\n",
    "    mw77s.append(entry)    \n",
    "\n",
    "\n",
    "txtraw = []\n",
    "if wlflag == 1: \n",
    "    txtraw = txtlines  # already a word list, no need to create one\n",
    "elif wlflag == 0:\n",
    "    for line in txtlines:\n",
    "        prog = re.compile(r'[^\\w\\'\\-]+', re.U) # ^\\w\\'\\- means not words ' -\n",
    "        line = prog.sub(' ', line) # replace all not words ' - with a space\n",
    "        txtraw += line.split(' ')\n",
    "    \n",
    "#     # 1. first replace '< > / . ;' with space\n",
    "#     for line in txtlines:\n",
    "#         line = re.sub(r'[\\<\\>\\/\\&\\.\\;]+', ' ', line)\n",
    "#         # then split words by space\n",
    "#         txtraw += line.split(' ')\n",
    "\n",
    "#     # 2. replace charaters not being A-Z, a-z, ', - with null\n",
    "#     txtraw = [re.sub(r'[^A-Za-z\\'\\-]+', '', x) for x in txtraw]\n",
    "\n",
    "txtraw = sorted(set(txtraw))\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "txtnew = []\n",
    "print '---words not excluded---' \n",
    "for word in txtraw:\n",
    "    if word and word not in bexclus and word not in bexclus2:\n",
    "        #print word\n",
    "#         fout.write(word + '\\n')\n",
    "        txtnew.append(word)\n",
    "        cnt += 1\n",
    "print cnt, ' words not excluded' \n",
    "\n",
    "txtinmw77 = []\n",
    "txtnotinmw77 = []\n",
    "for word in txtnew:\n",
    "    wordflag = 0\n",
    "    for item in mw77s:\n",
    "        if word == item['subhw']:            \n",
    "            # print word, '--hw is--', item['hw']\n",
    "            txtinmw77.append(item['hw'])\n",
    "            wordflag = 1            \n",
    "            break\n",
    "    if wordflag == 0: txtnotinmw77.append(word)\n",
    "txtinmw77 = sorted(set(txtinmw77))\n",
    "\n",
    "print '\\n---in mw77 words:', len(txtinmw77)\n",
    "fout = codecs.open(\"E:\\\\1Now\\\\mae\\\\article\\\\outwordlist.txt\", 'w', 'utf-8')\n",
    "fout.write('---in mw77 words: ' + str(len(txtinmw77)) + '\\n')\n",
    "searchString = 'deck:sPlay'\n",
    "for x in txtinmw77:\n",
    "    print x\n",
    "    searchString += ' hw:' + x + ' or'\n",
    "    fout.write(x + '\\n')\n",
    "\n",
    "print searchString\n",
    "\n",
    "print '\\n---not in mw77:', len(txtnotinmw77)\n",
    "fout.write('\\n\\n---not in mw77: ' + str(len(txtnotinmw77)) + '\\n')\n",
    "for x in txtnotinmw77:\n",
    "    print x\n",
    "    fout.write(x + '\\n')\n",
    "\n",
    "fout.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "with codecs.open(\"E:\\\\1Now\\\\taglist\\\\compare\\\\main.txt\", 'r', 'utf-8') as f:\n",
    "    mains = f.read().splitlines()\n",
    "\n",
    "with codecs.open(\"E:\\\\1Now\\\\taglist\\\\compare\\\\coreTotal.txt\", 'r', 'utf-8') as f:\n",
    "    core4s = f.read().splitlines()\n",
    "    \n",
    "core4s = sorted(set(core4s)) \n",
    "fawl = codecs.open(\"E:\\\\1Now\\\\taglist\\\\compare\\\\coreNew.txt\", 'w', 'utf-8')\n",
    "\n",
    "cnt1 = 0\n",
    "cnt2 = 0\n",
    "for core4 in core4s:\n",
    "    if core4 in mains:\n",
    "        fawl.write(core4 + '\\n')\n",
    "        cnt1 += 1\n",
    "    else:\n",
    "        cnt2 += 1\n",
    "        print core4, ' ... not in mwaled'\n",
    "    #word = line.split('\\t')[0]\n",
    "print cnt1, '...', cnt2\n",
    "    \n",
    "    \n",
    "fawl.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get all entries of core37 (note: core37 hws are all in 39195)\n",
    "# first method: from mwaled77561entry\n",
    "\n",
    "import codecs\n",
    "\n",
    "with codecs.open(\"E:\\\\1Now\\\\taglist\\\\mwaled77561entry.txt\", 'r', 'utf-8') as f:\n",
    "    mw77s = f.read().splitlines()\n",
    "    \n",
    "mw77 = []\n",
    "for line in mw77s:\n",
    "    entry = {}\n",
    "    entry['hw'] = line.split(';')[1]\n",
    "    entry['subhw'] = line.split(';')[0]\n",
    "    mw77.append(entry)\n",
    "\n",
    "with codecs.open(\"E:\\\\1Now\\\\taglist\\\\core37.txt\", 'r', 'utf-8') as f:\n",
    "    core37s = f.read().splitlines()\n",
    "\n",
    "f37 = codecs.open(\"E:\\\\1Now\\\\taglist\\\\core37entry2.txt\", 'w', 'utf-8')\n",
    "\n",
    "cnt1 = 0\n",
    "for core37 in core37s:\n",
    "    for item in mw77:\n",
    "        if core37 == item['hw']:\n",
    "            f37.write(item['subhw'] + '\\n')\n",
    "            cnt1 += 1\n",
    "\n",
    "print cnt1    \n",
    "    \n",
    "f37.close()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# codecs if for read and write files with unicode, encoding 'utf-8'\n",
    "import codecs\n",
    "import re\n",
    "\n",
    "#connect to MongoDB\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client.dpdb  # databas: dpdb\n",
    "geweiDict = db.geweiDict201511 # collection (table): geweiDict201511\n",
    "\n",
    "\n",
    "fdict = codecs.open('anki\\\\fr.txt', 'w', 'utf-8')\n",
    "    \n",
    "results = geweiDict.find({\"fr\":\"y\"}, {\"_id\":0, \"hw\":1})\n",
    "\n",
    "# Produce Anki note fields and tags:\n",
    "for result in results:    \n",
    "    hw = result.get(\"hw\")\n",
    "    print hw\n",
    "    fdict.write(hw + \"\\n\")\n",
    "    \n",
    "fdict.close()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "with codecs.open('E:\\\\1Now\\\\taglist\\\\84fr.txt', 'r', 'utf-8') as f:\n",
    "    fr = f.read().splitlines()\n",
    "with codecs.open('E:\\\\1Now\\\\taglist\\\\84fr2en.txt', 'r', 'utf-8') as f:\n",
    "    fr2en = f.read().splitlines()\n",
    "fd = codecs.open('E:\\\\1Now\\\\taglist\\\\84en_fr.txt', 'w', 'utf-8')\n",
    "for i in range(0,84):\n",
    "    fd.write('2;' + fr2en[i] + ';' + fr[i] + '\\n')\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output core31.txt by processing core3000raw20151123.txt\n",
    "\n",
    "with codecs.open('E:\\\\1Now\\\\taglist\\\\core3000raw20151123.txt', 'r', 'utf-8') as f:\n",
    "    lines = f.read().splitlines()\n",
    "words = [x.split('\\t')[0] for x in lines]\n",
    "wordsu = sorted(set(words))\n",
    "fout = codecs.open('E:\\\\1Now\\\\taglist\\\\core3140n.txt', 'w', 'utf-8')\n",
    "for word in wordsu:\n",
    "    fout.write(word + '\\n')\n",
    "fout.close()\n",
    "\n",
    "print len(words), len(wordsu)\n",
    "dupl = set([x for x in words if words.count(x)>1])\n",
    "print len(dupl)\n",
    "# print sorted(dupl)\n",
    "\n",
    "# # compare core3140n.txt and core31.txt\n",
    "# with codecs.open('E:\\\\1Now\\\\taglist\\\\core31.txt', 'r', 'utf-8') as f:\n",
    "#     core31s = f.read().splitlines()\n",
    "#     f.close()\n",
    "# print set(core31s) ^ set(wordsu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with codecs.open('E:\\\\1Now\\\\taglist\\\\570awlraw.txt', 'r', 'utf-8') as f:\n",
    "    lines = f.read().splitlines()\n",
    "fd = codecs.open('E:\\\\1Now\\\\taglist\\\\570awl.txt', 'w', 'utf-8')\n",
    "for x in lines:\n",
    "    fd.write(x.split('\\t')[0] + '\\n')\n",
    "fd.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
