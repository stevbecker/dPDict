{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walk\n",
      "Awol\n",
      "-ness\n",
      "February\n",
      "<type 'str'>\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print 'walk'.capitalize() # Walk is good\n",
    "print 'AWOL'.capitalize() # not good because Awol isn't a word\n",
    "print '-ness'.capitalize()\n",
    "print 'February'.capitalize()\n",
    "al = string.lowercase[0:26]\n",
    "print type(al)\n",
    "# for x in al: print x\n",
    "print 'Tuesday'[0] in al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total head words:  39195\n",
      "hw unique number:  34398\n",
      "39195\n",
      "number of hws with homographs:  39195\n",
      "number of unique hws:  34398\n",
      "number of words capitalized:  37517\n",
      "67125\n"
     ]
    }
   ],
   "source": [
    "# output mwl39195hw.txt  (having duplicates)\n",
    "# and explore 39195 hw entries\n",
    "# 2015-12-01\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# codecs if for read and write files with unicode, encoding 'utf-8'\n",
    "import codecs\n",
    "import string\n",
    "\n",
    "#connect to MongoDB\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client.dpdb  # databas: dpdb\n",
    "geweiDict = db.geweiDict201511 # collection (table): geweiDict201511\n",
    "#geweiDict = db.geweiDictTest\n",
    "\n",
    "fhw = codecs.open('E:\\\\1Now\\\\taglist\\\\mwl39195hwraw.txt', 'w', 'utf-8')\n",
    "    \n",
    "results = geweiDict.find({}, {\"_id\":0, \"hw\":1}) #.limit(1000)\n",
    "\n",
    "\n",
    "totalhw = 0 # total number of head words\n",
    "for result in results:    \n",
    "    word = result.get(\"hw\")    \n",
    "    if word:\n",
    "        #print word\n",
    "        fhw.write(word + '\\n')\n",
    "        totalhw += 1\n",
    "    else:\n",
    "        print \"no head word\"\n",
    "        continue\n",
    "\n",
    "fhw.close()\n",
    "print \"total head words: \", totalhw\n",
    "\n",
    "\n",
    "# sort out by head words and output\n",
    "# with homographs, 39195 head words have duplicates; unique number is 34398\n",
    "\n",
    "# create mwl39195hw.txt\n",
    "with codecs.open('E:\\\\1Now\\\\taglist\\\\mwl39195hwraw.txt', 'r', 'utf-8') as f:\n",
    "    lines = f.read().splitlines()\n",
    "    f.close()\n",
    "lines = sorted(lines)\n",
    "print 'hw unique number: ', len(set(lines))\n",
    "\n",
    "fd = codecs.open('E:\\\\1Now\\\\taglist\\\\mwl39195hw.txt', 'w', 'utf-8')\n",
    "cnt = 0\n",
    "for line in lines:\n",
    "    fd.write(line + '\\n')\n",
    "    cnt += 1\n",
    "fd.close()\n",
    "print cnt\n",
    "\n",
    "\n",
    "\n",
    "# explore 39195 hws\n",
    "with codecs.open('E:\\\\1Now\\\\taglist\\\\mwl39195hw.txt', 'r', 'utf-8') as f:\n",
    "    words = f.read().splitlines()\n",
    "    f.close()\n",
    "print 'number of hws with homographs: ', len(words)\n",
    "print 'number of unique hws: ', len(set(words))\n",
    "\n",
    "# wordsC = [x.capitalize() for x in words]\n",
    "wordsC = []\n",
    "for word in words:\n",
    "    # only capitalize words beginning with a lowercase letter. no need for 'Feburary'\n",
    "    # Don't capitalize words like 'AWOL' -- Awol is not a word!\n",
    "    if word[0] in string.lowercase[0:26]:\n",
    "        wordsC.append(word.capitalize())\n",
    "        cnt += 1\n",
    "    \n",
    "print 'number of words capitalized: ', len(wordsC)\n",
    "\n",
    "# put words and wordsC together and get unique\n",
    "# wordsTotal = sorted(set(words + wordsC))\n",
    "# fd = codecs.open('E:\\\\1Now\\\\taglist\\\\mwl39195hwCap.txt', 'w', 'utf-8')\n",
    "# for x in wordsTotal:\n",
    "#     fd.write(x + '\\n')\n",
    "# fd.close()\n",
    "# print len(wordsTotal)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total head words:  39195\n",
      "hw unique number:  34398\n",
      "39195\n",
      "hw summary unique number:  38862\n",
      "39195\n"
     ]
    }
   ],
   "source": [
    "# output mwl39195sum.txt  (having duplicates)\n",
    "# hw entries and their summary (subhw, prn, idpvs, tags)\n",
    "# 2015-11-27 2015-12-01\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# codecs if for read and write files with unicode, encoding 'utf-8'\n",
    "import codecs\n",
    "\n",
    "#connect to MongoDB\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client.dpdb  # databas: dpdb\n",
    "geweiDict = db.geweiDict201511 # collection (table): geweiDict201511\n",
    "#geweiDict = db.geweiDictTest\n",
    "\n",
    "fdict = codecs.open('E:\\\\1Now\\\\taglist\\\\mwl39195sumraw.txt', 'w', 'utf-8')\n",
    "    \n",
    "results = geweiDict.find({}, {\"_id\":0, \"hw\":1, \"subhw\":1, \"prn\":1, \"idpvs\":1, \"tag\":1}) #.limit(1000)\n",
    "\n",
    "\n",
    "totalhw = 0 # total number of head words\n",
    "for result in results:    \n",
    "    word = result.get(\"hw\")    \n",
    "    if word:\n",
    "        #print word\n",
    "        fdict.write(word)\n",
    "        totalhw += 1\n",
    "    else:\n",
    "        print \"no head word\"\n",
    "        continue\n",
    "\n",
    "    # get items of result\n",
    "    prns = result.get(\"prn\")\n",
    "    subhws = result.get(\"subhw\")\n",
    "    idpvs = result.get(\"idpvs\")  \n",
    "    tags = result.get('tag')\n",
    "    \n",
    "    if subhws:\n",
    "        cnt = 1\n",
    "        for subhw in subhws:\n",
    "            if cnt == 1: fdict.write(' (' + subhw)                \n",
    "            else: fdict.write(' ' + subhw)\n",
    "            cnt += 1        \n",
    "        fdict.write(')')\n",
    "    \n",
    "    if prns:\n",
    "        cnt = 1\n",
    "        for prn in prns:                 \n",
    "            fdict.write(' /' + prn + '/')\n",
    "            cnt += 1\n",
    "\n",
    "    if idpvs:\n",
    "        cnt = 1\n",
    "        for idpv in idpvs:\n",
    "            if cnt == 1: fdict.write('  [' + idpv)\n",
    "            else: fdict.write(', ' + idpv)\n",
    "            cnt += 1\n",
    "        fdict.write(']')\n",
    "            \n",
    "    if tags:\n",
    "        cnt = 1\n",
    "        for tag in tags:\n",
    "            if cnt == 1: fdict.write('  {' + tag)\n",
    "            else: fdict.write(' ' + tag)\n",
    "            cnt += 1\n",
    "        fdict.write('}')\n",
    "\n",
    "    fdict.write('\\n')    \n",
    "\n",
    "fhw.close()\n",
    "fdict.close()\n",
    "print \"total head words: \", totalhw\n",
    "\n",
    "\n",
    "# sort out and create mwl39195sum.txt\n",
    "with codecs.open('E:\\\\1Now\\\\taglist\\\\mwl39195sumraw.txt', 'r', 'utf-8') as f:\n",
    "    lines = f.read().splitlines()\n",
    "    f.close()\n",
    "lines = sorted(lines)\n",
    "print 'hw summary unique number: ', len(set(lines))\n",
    "\n",
    "fd = codecs.open('E:\\\\1Now\\\\taglist\\\\mwl39195sum.txt', 'w', 'utf-8')\n",
    "cnt = 0\n",
    "for line in lines:\n",
    "    fd.write(line + '\\n')\n",
    "    cnt += 1\n",
    "fd.close()\n",
    "print cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total head words:  39195\n",
      "total inflections:  64355\n",
      "total subhws:  9544\n",
      "total subhws whose 1st letters are different from hws:  334\n",
      "only hw:  11182\n",
      "53972\n"
     ]
    }
   ],
   "source": [
    "# output mwlBenchmark.txt (mwBen) (no duplicates)\n",
    "\n",
    "# format: derivatives of hw (inflections, or subhws);hw\n",
    "# sort by 'derivatives;hw' and make every line unique\n",
    "# 2015-11-28, 2015-11-30, 2015-12-01\n",
    "\n",
    "# blazes;blaze\n",
    "# blazing;blaze\n",
    "# blazingly;blazing\n",
    "\n",
    "# I can know blaze, blazing are hws, the two lines below are not allowd because hws have derivates:\n",
    "# blaze;blaze\n",
    "# blazing;blazing\n",
    "# the two lines above are redundant.\n",
    "\n",
    "# manually delete: asas\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# codecs if for read and write files with unicode, encoding 'utf-8'\n",
    "import codecs\n",
    "\n",
    "#connect to MongoDB\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client.dpdb  # databas: dpdb\n",
    "geweiDict = db.geweiDict201511 # collection (table): geweiDict201511\n",
    "#geweiDict = db.geweiDictTest\n",
    "\n",
    "fdict = codecs.open('E:\\\\1Now\\\\taglist\\\\mwlBenchmarkraw.txt', 'w', 'utf-8')\n",
    "    \n",
    "results = geweiDict.find({}, {\"_id\":0, \"hw\":1, \"infl\":1, \"subhw\":1}) #.limit(1000)\n",
    "# sort method will use much more memory\n",
    "#results = geweiDict.find({}, {\"_id\":0, \"hw\":1, \"prn\":1, \"alles\":1, \"idpvs\":1, \"sublist\":1}).sort(\"hw\", 1).limit(1000)\n",
    "\n",
    "\n",
    "hwcnt = 0 # number of head words (hws)\n",
    "# hwcapcnt = 0 # number of hws capitalized\n",
    "inflcnt = 0 # number of inflections\n",
    "subhwcnt = 0 # number of subhws\n",
    "subhw1cnt = 0 # number of subhws whose first letter is not same as hw\n",
    "onlyhwcnt = 0\n",
    "\n",
    "for result in results:\n",
    "    inflflag = 0\n",
    "    subhwflag = 0\n",
    "    \n",
    "    word = result.get(\"hw\")    \n",
    "    if word:\n",
    "        #print word\n",
    "#         fdict.write(word + ';' + word + '\\n')\n",
    "        hwcnt += 1      \n",
    "\n",
    "    else:\n",
    "        print \"no head word\"\n",
    "        continue\n",
    "\n",
    "    # get items of result\n",
    "    infls = result.get(\"infl\")\n",
    "    subhws = result.get(\"subhw\")     \n",
    "    \n",
    "    if infls:\n",
    "        for infl in infls:\n",
    "            if infl == word:\n",
    "#                 print 'infl == word', infl\n",
    "                continue\n",
    "            fdict.write(infl + ';' + word + '\\n')\n",
    "            inflcnt += 1   \n",
    "            inflflag = 1\n",
    "            \n",
    "    if subhws:\n",
    "        for subhw in subhws:\n",
    "            # check if subhw is a real sub hw of word by comparing first letter 77561 -> 77256\n",
    "            # no need again because the check has been done in db buidling\n",
    "            #if subhw[0] != word[0]: continue       \n",
    "            if subhw == word:\n",
    "#                 print 'subhw == word', infl\n",
    "                continue           \n",
    "            if subhw[0] != word[0]:\n",
    "#                 print 'subhw is not like word: ', subhw, '...', word\n",
    "                subhw1cnt += 1\n",
    "            fdict.write(subhw + ';' + word + '\\n')\n",
    "            subhwcnt += 1      \n",
    "            subhwflag = 1\n",
    "    if inflflag == 0 and subhwflag == 0:\n",
    "        fdict.write(word + ';' + word + '\\n')\n",
    "        onlyhwcnt += 1\n",
    "    \n",
    "fdict.close()\n",
    "print \"total head words: \", hwcnt\n",
    "# print 'total hws capitalized: ', hwcapcnt\n",
    "print \"total inflections: \", inflcnt\n",
    "print 'total subhws: ', subhwcnt\n",
    "print 'total subhws whose 1st letters are different from hws: ', subhw1cnt\n",
    "print 'only hw: ', onlyhwcnt\n",
    "\n",
    "\n",
    "# sort out by head words\n",
    "with codecs.open('E:\\\\1Now\\\\taglist\\\\mwlBenchmarkraw.txt', 'r', 'utf-8') as f:\n",
    "    lines = f.read().splitlines()\n",
    "lines = sorted(set(lines))\n",
    "\n",
    "fd = codecs.open('E:\\\\1Now\\\\taglist\\\\mwlBenchmark.txt', 'w', 'utf-8')\n",
    "cnt = 0\n",
    "for line in lines:\n",
    "    fd.write(line + '\\n')\n",
    "    cnt += 1\n",
    "fd.close()\n",
    "print cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 4, 5}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get duplicates\n",
    "l = [1,2,3,4,4,5,5,6,1]\n",
    "set([x for x in l if l.count(x) > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3905 3140\n",
      "661\n",
      "set([])\n"
     ]
    }
   ],
   "source": [
    "# output core31.txt by processing core3000raw20151123.txt\n",
    "\n",
    "with codecs.open('E:\\\\1Now\\\\taglist\\\\core3000raw20151123.txt', 'r', 'utf-8') as f:\n",
    "    lines = f.read().splitlines()\n",
    "    f.close()\n",
    "words = [x.split('\\t')[0] for x in lines]\n",
    "wordsu = sorted(set(words))\n",
    "fout = codecs.open('E:\\\\1Now\\\\taglist\\\\core3140n.txt', 'w', 'utf-8')\n",
    "for word in wordsu:\n",
    "    fout.write(word + '\\n')\n",
    "fout.close()\n",
    "\n",
    "print len(words), len(wordsu)\n",
    "dupl = set([x for x in words if words.count(x)>1])\n",
    "print len(dupl)\n",
    "# print sorted(dupl)\n",
    "\n",
    "# # compare core3140n.txt and core31.txt\n",
    "# with codecs.open('E:\\\\1Now\\\\taglist\\\\core31.txt', 'r', 'utf-8') as f:\n",
    "#     core31s = f.read().splitlines()\n",
    "#     f.close()\n",
    "# print set(core31s) ^ set(wordsu)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello ... hello2\n",
      "hi ... hi2\n"
     ]
    }
   ],
   "source": [
    "def gethw():\n",
    "    a = [{'k1': 'hello', 'k2':'hello2'}, {'k1': 'hi', 'k2':'hi2'}]\n",
    "    return a\n",
    "b = gethw()\n",
    "for x in b:\n",
    "    print x['k1'], '...', x['k2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ E:\\1Now\\taglist\\testmwBen.txt ------\n",
      "* has words :  19\n",
      "* has unique word number:  18\n",
      "* has duplicates:  set([u'taking'])\n",
      "\n",
      "\n",
      "derivative:  Taking --- hw:  take\n",
      "derivative:  taking --- hw:  take\n",
      "derivative:  taking --- hw:  take\n",
      "derivative:  20/20 --- hw:  twenty-twenty\n",
      "derivative:  Flurries --- hw:  flurry\n",
      "\n",
      "\n",
      "* same as hw:  10\n",
      "* same as capitalized hw:  3\n",
      "* has derivatives:  5\n",
      "* not in mwBen:  1  --  [u'tAke']\n",
      "--- len(txtraw) == len(wordhw) + len(wordhwC) + len(wordderiv) + len(wordnotBen) ---\n",
      "\n",
      "how many hw duplicates---  12  -  5  =  7\n",
      "[u'take', u'take', u'takings', u'takings', u'take', u'blazing', u'blazing', u'take', u'twenty-twenty', u'twenty-twenty', u'impressionism', u'impressionism']\n",
      "how many hws being returned---  11\n",
      "11\n",
      "[u'against', u'blaze', u'blazing', u'flurry', u'impressionism', u'revolt', u'take', u'taken', u'takings', u'took', u'twenty-twenty']\n"
     ]
    }
   ],
   "source": [
    "# check word lists only for building mwl mongodb database\n",
    "# these word lists include (number in parentheses are the number of files)\n",
    "#   * words of 18 topics from mwl website (18)\n",
    "#   * 3140 core words from mwl website (1)\n",
    "#   * words of \"The Spelling of Different Sounds in English\" (1)\n",
    "#   * words of word roots, prefixes, suffixes (3)\n",
    "#   sub-total: 23\n",
    "#\n",
    "#   * words of mwl single images (1)\n",
    "#   * words of mwl group images (106)\n",
    "#   sub-total: 107\n",
    "#\n",
    "#   * homographs (1)\n",
    "#   * 3787 core words I collect (1)\n",
    "#   sub-total: 2\n",
    "# \n",
    "#   Total: 131\n",
    "\n",
    "\n",
    "\n",
    "import codecs\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "def checkBymwBen(wordlist):    \n",
    "    hwreturn = [] # hws returned by this function    \n",
    "    \n",
    "    # word list I want to check\n",
    "    with codecs.open(wordlist, 'r', 'utf-8') as f:\n",
    "        txtraw = f.read().splitlines()\n",
    "        f.close()\n",
    "    print '------', wordlist, '------'\n",
    "    print '* has words : ', len(txtraw)\n",
    "    print '* has unique word number: ', len(set(txtraw))\n",
    "    print '* has duplicates: ', set([x for x in txtraw if txtraw.count(x) > 1])\n",
    "    print '\\n'\n",
    "\n",
    "    # with codecs.open(\"E:\\\\1Now\\\\taglist\\\\mwl77Entry.txt\", 'r', 'utf-8') as f:\n",
    "    with codecs.open(\"E:\\\\1Now\\\\taglist\\\\mwlBenchmark.txt\", 'r', 'utf-8') as f:    \n",
    "        lines = f.read().splitlines()\n",
    "        f.close()\n",
    "\n",
    "    # create mwBen dictionary\n",
    "    mwBens = []\n",
    "    hws = [] # sorted unique hws\n",
    "    hwsC = [] # sorted unique capitalized hws\n",
    "    for line in lines:\n",
    "        entry = {}\n",
    "        hw = line.split(';')[1]\n",
    "        entry['hw'] = hw\n",
    "        entry['deriv'] = line.split(';')[0] # derivative, or hw that has no derivatives\n",
    "        mwBens.append(entry)\n",
    "        hws.append(hw)\n",
    "        if hw[0] in string.lowercase[0:26]:\n",
    "            hwsC.append(hw.capitalize())\n",
    "        \n",
    "    hws = sorted(set(hws))\n",
    "    hwsC = sorted(set(hwsC))        \n",
    "\n",
    "#     print 'mwBens: ', len(mwBens)\n",
    "#     print 'hws: ', len(hws)\n",
    "#     print 'hwsC: ', len(hwsC)\n",
    "\n",
    "\n",
    "    # begin to check the word list against mw benchmark dictionary\n",
    "    #  Word; Its-hw (Head Word)\n",
    "    #\n",
    "    # Three cases (the first two cases return hw)\n",
    "    # 1. word is exactly same as hw or is a capitalized hw\n",
    "    # 2. word is a derivative or is a capitalized derivative\n",
    "    # 3. word is not in mwBen\n",
    "\n",
    "\n",
    "    wordhw = [] # word is exactly same as hw\n",
    "    wordhwC = [] # word is same as capitalized hw\n",
    "    wordderiv = [] # derivatives or capitalized derivatives\n",
    "    wordnotBen = [] # word is not in mwBen\n",
    "\n",
    "    for word in txtraw:\n",
    "        hwflag = 0\n",
    "        derivflag = 0\n",
    "        \n",
    "        if word in hws:\n",
    "            wordhw.append(word)\n",
    "            hwreturn.append(word)\n",
    "            hwflag = 1\n",
    "        elif word in hwsC:\n",
    "            wordhwC.append(word)\n",
    "            hwreturn.append(word.lower())\n",
    "            hwflag = 1\n",
    "\n",
    "        if hwflag == 0:\n",
    "            dercnt = 0\n",
    "            for mwben in mwBens:                \n",
    "                if word == mwben['deriv'] or word == mwben['deriv'].capitalize():\n",
    "                    wordderiv.append(word)\n",
    "                    hwreturn.append(mwben['hw'])\n",
    "                    derivflag = 1\n",
    "                    print 'derivative: ', word, '--- hw: ', mwben['hw']\n",
    "                    dercnt += 1\n",
    "            if dercnt > 1: print word, '--- derivate has multiple hws --- ', dercnt\n",
    "\n",
    "        if hwflag == 0 and derivflag == 0:\n",
    "            wordnotBen.append(word)\n",
    "    \n",
    "    print '\\n'\n",
    "    print '* same as hw: ', len(wordhw)  #,' -- ', wordhw\n",
    "    print '* same as capitalized hw: ', len(wordhwC)  #,' -- ', wordhwC\n",
    "    print '* has derivatives: ', len(wordderiv) #,' -- ', wordderiv\n",
    "    print '* not in mwBen: ', len(wordnotBen), ' -- ', wordnotBen\n",
    "    if len(txtraw) == len(wordhw) + len(wordhwC) + len(wordderiv) + len(wordnotBen): \n",
    "        print '--- len(txtraw) == len(wordhw) + len(wordhwC) + len(wordderiv) + len(wordnotBen) ---\\n'\n",
    "    else: print \"--- words' numbers don't mattch, check ---\\n\"\n",
    "    \n",
    "    dupl = [x for x in hwreturn if hwreturn.count(x)>1]\n",
    "    print 'how many hw duplicates--- ', len(dupl), ' - ', len(set(dupl)), ' = ', len(dupl)-len(set(dupl))\n",
    "    print dupl\n",
    "\n",
    "    print 'how many hws being returned--- ', len(txtraw) - len(wordnotBen) - (len(dupl)-len(set(dupl)))\n",
    "    return sorted(set(hwreturn))\n",
    "    \n",
    "    \n",
    "# result = checkBymwBen(\"E:\\\\1Now\\\\taglist\\\\core3140n.txt\")\n",
    "result = checkBymwBen('E:\\\\1Now\\\\taglist\\\\testmwBen.txt')\n",
    "\n",
    "print len(result)\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
