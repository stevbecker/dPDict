{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- mwBen statistics ---\n",
      "total head words:  39195\n",
      "total inflections:  64355\n",
      "total subhws:  9544\n",
      "total subhws whose 1st letters are different from hws:  334\n",
      "hw without any derivatives:  11182\n",
      "number of lines in mwBen:  53972\n"
     ]
    }
   ],
   "source": [
    "# output mwlBenchmark.txt (mwBen) (no duplicate lines)\n",
    "\n",
    "# format: derivatives of hw (inflections, or subhws);hw\n",
    "# sort by 'derivatives;hw' and make every line unique\n",
    "# 2015-11-28, 2015-11-30, 2015-12-01\n",
    "\n",
    "# blazes;blaze\n",
    "# blazing;blaze\n",
    "# blazingly;blazing\n",
    "\n",
    "# I can know blaze, blazing are hws, the two lines below are not allowd because hws have derivates:\n",
    "# blaze;blaze\n",
    "# blazing;blazing\n",
    "# the two lines above are redundant.\n",
    "\n",
    "# manually delete: asas\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# codecs if for read and write files with unicode, encoding 'utf-8'\n",
    "import codecs\n",
    "\n",
    "#connect to MongoDB\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client.dpdb  # databas: dpdb\n",
    "geweiDict = db.geweiDict201511 # collection (table): geweiDict201511\n",
    "#geweiDict = db.geweiDictTest\n",
    "\n",
    "fdict = codecs.open('E:\\\\1Now\\\\taglist\\\\mwlBenchmarkraw.txt', 'w', 'utf-8')\n",
    "    \n",
    "results = geweiDict.find({}, {\"_id\":0, \"hw\":1, \"infl\":1, \"subhw\":1}) #.limit(1000)\n",
    "# sort method will use much more memory\n",
    "#results = geweiDict.find({}, {\"_id\":0, \"hw\":1, \"prn\":1, \"alles\":1, \"idpvs\":1, \"sublist\":1}).sort(\"hw\", 1).limit(1000)\n",
    "\n",
    "\n",
    "hwcnt = 0 # number of head words (hws)\n",
    "# hwcapcnt = 0 # number of hws capitalized\n",
    "inflcnt = 0 # number of inflections\n",
    "subhwcnt = 0 # number of subhws\n",
    "subhw1cnt = 0 # number of subhws whose first letter is not same as hw\n",
    "onlyhwcnt = 0\n",
    "\n",
    "# subhw1hw = []\n",
    "\n",
    "for result in results:\n",
    "    inflflag = 0\n",
    "    subhwflag = 0\n",
    "    \n",
    "    word = result.get(\"hw\")    \n",
    "    if word:\n",
    "        #print word\n",
    "#         fdict.write(word + ';' + word + '\\n')\n",
    "        hwcnt += 1      \n",
    "    else:\n",
    "        print \"no head word\"\n",
    "        continue\n",
    "\n",
    "    # get items of result\n",
    "    infls = result.get(\"infl\")\n",
    "    subhws = result.get(\"subhw\")     \n",
    "    \n",
    "    if infls:\n",
    "        for infl in infls:\n",
    "            if infl == word:\n",
    "#                 print 'infl == word', infl\n",
    "                continue\n",
    "            fdict.write(infl + ';' + word + '\\n')\n",
    "            inflcnt += 1   \n",
    "            inflflag = 1\n",
    "            \n",
    "    if subhws:\n",
    "        for subhw in subhws:\n",
    "            #if subhw[0] != word[0]: continue       \n",
    "            if subhw == word:\n",
    "#                 print 'subhw == word', infl\n",
    "                continue           \n",
    "            if subhw[0] != word[0]:\n",
    "#                 print 'subhw is not like word: ', subhw, '...', word\n",
    "                subhw1cnt += 1\n",
    "#                 subhw1hw.append(subhw+';'+word)\n",
    "            fdict.write(subhw + ';' + word + '\\n')\n",
    "            subhwcnt += 1      \n",
    "            subhwflag = 1\n",
    "            \n",
    "    # hw;hw (only when hw has no inflections and no subhws)\n",
    "    if inflflag == 0 and subhwflag == 0:\n",
    "        fdict.write(word + ';' + word + '\\n')\n",
    "        onlyhwcnt += 1\n",
    "    \n",
    "fdict.close()\n",
    "\n",
    "print '--- mwBen statistics ---'\n",
    "print \"total head words: \", hwcnt\n",
    "# print 'total hws capitalized: ', hwcapcnt\n",
    "print \"total inflections: \", inflcnt\n",
    "print 'total subhws: ', subhwcnt\n",
    "print 'total subhws whose 1st letters are different from hws: ', subhw1cnt\n",
    "print 'hw without any derivatives: ', onlyhwcnt\n",
    "\n",
    "\n",
    "# sort out by head words\n",
    "with codecs.open('E:\\\\1Now\\\\taglist\\\\mwlBenchmarkraw.txt', 'r', 'utf-8') as f:\n",
    "    lines = f.read().splitlines()\n",
    "lines = sorted(set(lines))\n",
    "\n",
    "fd = codecs.open('E:\\\\1Now\\\\taglist\\\\mwlBenchmark.txt', 'w', 'utf-8')\n",
    "cnt = 0\n",
    "for line in lines:\n",
    "    fd.write(line + '\\n')\n",
    "    cnt += 1\n",
    "fd.close()\n",
    "print 'number of lines in mwBen: ', cnt\n",
    "\n",
    "# subhw1hw = sorted(set(subhw1hw))\n",
    "# fd = codecs.open('E:\\\\1Now\\\\taglist\\\\subhw1hw.txt', 'w', 'utf-8')\n",
    "# for x in subhw1hw:\n",
    "#     fd.write(x + '\\n')\n",
    "# fd.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- explore mwBen ---\n",
      "number of derivative column:  53972\n",
      "number of hw column:  53972\n",
      "unique number of hw column:  34398\n",
      "number of derivatives (inflections and subhws) whose 1st letter different from hws:  337\n",
      "number of capitalized hws:  1487\n"
     ]
    }
   ],
   "source": [
    "# explore mwBen\n",
    "\n",
    "import codecs\n",
    "import string\n",
    "\n",
    "with codecs.open('E:\\\\1Now\\\\taglist\\\\mwlBenchmark.txt', 'r', 'utf-8') as f:\n",
    "    lines = f.read().splitlines()\n",
    "\n",
    "deriv = [] # derivative\n",
    "benhw = [] # hw\n",
    "deriv1hw = [] # derivative (inflection, subhw) first letter different from its hw\n",
    "hwcap = [] # hw whose first letter is capitalized\n",
    "for line in lines:\n",
    "    x1 = line.split(';')[0]\n",
    "    x2 = line.split(';')[1]\n",
    "    deriv.append(x1)\n",
    "    benhw.append(x2)\n",
    "    if x1[0] != x2[0]: deriv1hw.append(line)\n",
    "    if x2[0] in string.uppercase[0:26]: hwcap.append(x2)\n",
    "derivS = sorted(deriv)\n",
    "benhwSU = sorted(set(benhw)) # Sorted, Unique\n",
    "hwcap = sorted(set(hwcap))\n",
    "\n",
    "print '--- explore mwBen ---'\n",
    "print 'number of derivative column: ', len(deriv)\n",
    "print 'number of hw column: ', len(benhw)\n",
    "print 'unique number of hw column: ', len(benhwSU)\n",
    "print 'number of derivatives (inflections and subhws) whose 1st letter different from hws: ', len(deriv1hw)\n",
    "print 'number of capitalized hws: ', len(hwcap)\n",
    "\n",
    "fout = codecs.open('E:\\\\1Now\\\\taglist\\\\mwlStat.txt', 'w', 'utf-8')\n",
    "fout.write('--- statistics ---\\n')\n",
    "fout.write('number of lines in mwBen: ' + str(len(deriv)) + '\\n')\n",
    "fout.write('unique number of hw: ' + str(len(benhwSU)) + '\\n')\n",
    "fout.write('number of derivatives (inflections and subhws) whose 1st letter different from hws: ' + str(len(deriv1hw)) + '\\n')\n",
    "fout.write('number of capitalized hws: ' + str(len(hwcap)) + '\\n')\n",
    "\n",
    "fout.write('Contents\\n--------\\n')\n",
    "fout.write(\"Q: Are there duplicate derivatives who aren't hws in mwBen?\\n\")\n",
    "fout.write(\"Q: List derivatives (inflections and subhws) whose first letter is different from the first letter of their hws\\n\")\n",
    "fout.write(\"Capitalized hws\\n\\n\")\n",
    "\n",
    "# Q: Are there duplicate derivatives who aren't hws in mwBen?\n",
    "dupderiv = [x for x in derivS if x not in benhwSU and derivS.count(x)>1]\n",
    "fout.write(\"--- Duplicate derivatives not being hws: ---\\n\")\n",
    "for x in dupderiv:\n",
    "    fout.write(x + '\\n')\n",
    "\n",
    "# Q: List subhws whose first letter is different from the first letter of their hws\n",
    "fout.write(\"\\n--- derivatives (inflections and subhws) whose 1st letter different from hws: ---\\n\")\n",
    "fout.write(\"derivatives (inflections and subhws);hw\\n\\n\")\n",
    "for x in subhw1hw:\n",
    "    fout.write(x + '\\n')\n",
    "\n",
    "fout.write(\"\\n--- Capitalized hws: ---\\n\")\n",
    "for x in hwcap:\n",
    "    fout.write(x + '\\n')\n",
    "           \n",
    "fout.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "------ testmwBen.txt ------\n",
      "* has words :  20\n",
      "* has unique word number:  19\n",
      "* has duplicates:  set([u'taking'])\n",
      "derivative:  Taking --- hw:  take\n",
      "derivative:  taking --- hw:  take\n",
      "derivative:  tAke --- hw:  shot\n",
      "derivative:  taking --- hw:  take\n",
      "derivative:  20/20 --- hw:  twenty-twenty\n",
      "derivative:  Flurries --- hw:  flurry\n",
      "derivative:  axes --- hw:  ax\n",
      "derivative:  axes --- hw:  axis\n",
      "axes --- derivate has multiple hws ---  2\n",
      "* same as hw:  10\n",
      "* same as capitalized hw:  3\n",
      "* words are derivatives:  8\n",
      "--- words' numbers don't mattch, check ---\n",
      "\n",
      "how many duplicates in raw hwreturn ---  12  -  5  =  7\n",
      "[u'take', u'take', u'takings', u'takings', u'take', u'blazing', u'blazing', u'take', u'twenty-twenty', u'twenty-twenty', u'impressionism', u'impressionism']\n",
      "\n",
      "how many hws supposed to be returned---  13\n",
      "acutal return:  14\n",
      "[u'against', u'ax', u'axis', u'blaze', u'blazing', u'flurry', u'impressionism', u'revolt', u'shot', u'take', u'taken', u'takings', u'took', u'twenty-twenty']\n"
     ]
    }
   ],
   "source": [
    "# check word lists \n",
    "# these word lists include (number in parentheses are the number of files)\n",
    "#   * words of 18 topics from mwl website (18)\n",
    "#   * 3140 core words from mwl website (1)\n",
    "#   * words of \"The Spelling of Different Sounds in English\" (1)\n",
    "#   * words of word roots, prefixes, suffixes (3)\n",
    "#   sub-total: 23\n",
    "#\n",
    "#   * words of mwl single images (1)\n",
    "#   * words of mwl group images (108)\n",
    "#   sub-total: 109\n",
    "#\n",
    "#   * homographs (1)\n",
    "#   * 3787 core words I collect (1)\n",
    "#   sub-total: 2\n",
    "# \n",
    "#   Total: 135\n",
    "\n",
    "import codecs\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "def checkBymwBen(path, wordlist):\n",
    "    '''get sorted unique head words of mwl for a word list which may include inflections and/or sub hws'''\n",
    "    \n",
    "    hwreturn = [] # hws returned by this function    \n",
    "    \n",
    "    # word list I want to check\n",
    "    with codecs.open(path + wordlist, 'r', 'utf-8') as f:\n",
    "        txtraw = f.read().splitlines()\n",
    "    print '\\n\\n------', wordlist, '------'\n",
    "    print '* has words : ', len(txtraw)\n",
    "    print '* has unique word number: ', len(set(txtraw))\n",
    "    dupinraw = set([x for x in txtraw if txtraw.count(x) > 1])\n",
    "    if dupinraw: print '* has duplicates: ', dupinraw\n",
    "\n",
    "\n",
    "    # with codecs.open(\"E:\\\\1Now\\\\taglist\\\\mwl77Entry.txt\", 'r', 'utf-8') as f:\n",
    "    with codecs.open(\"E:\\\\1Now\\\\taglist\\\\mwlBenchmark.txt\", 'r', 'utf-8') as f:    \n",
    "        lines = f.read().splitlines()\n",
    "\n",
    "    # create mwBen dictionary\n",
    "    mwBens = []\n",
    "    hws = [] # sorted unique hws\n",
    "    hwsC = [] # sorted unique capitalized hws\n",
    "    for line in lines:\n",
    "        entry = {}\n",
    "        hw = line.split(';')[1]\n",
    "        entry['hw'] = hw\n",
    "        entry['deriv'] = line.split(';')[0] # derivative, or hw that has no derivatives\n",
    "        mwBens.append(entry)\n",
    "        hws.append(hw)\n",
    "        if hw[0] in string.lowercase[0:26]:\n",
    "            hwsC.append(hw.capitalize())\n",
    "        \n",
    "    hws = sorted(set(hws))\n",
    "    hwsC = sorted(set(hwsC))        \n",
    "\n",
    "#     print 'mwBens: ', len(mwBens)\n",
    "#     print 'hws: ', len(hws)\n",
    "#     print 'hwsC: ', len(hwsC)\n",
    "\n",
    "\n",
    "    # begin to check the word list against mw benchmark dictionary\n",
    "    #  Word; Its-hw (Head Word)\n",
    "    #\n",
    "    # Three cases (the first two cases return hw)\n",
    "    # 1. word is exactly same as hw or is a capitalized hw\n",
    "    # 2. word is a derivative or is a capitalized derivative\n",
    "    # 3. word is not in mwBen\n",
    "\n",
    "\n",
    "    wordhw = [] # word is exactly same as hw\n",
    "    wordhwC = [] # word is same as capitalized hw\n",
    "    wordderiv = [] # derivatives or capitalized derivatives\n",
    "    wordnotBen = [] # word is not in mwBen\n",
    "\n",
    "    for word in txtraw:\n",
    "        hwflag = 0\n",
    "        derivflag = 0\n",
    "        \n",
    "        if word in hws:\n",
    "            wordhw.append(word)\n",
    "            hwreturn.append(word)\n",
    "            hwflag = 1\n",
    "        elif word.capitalize() in hws: # like leo\n",
    "            wordhw.append(word)\n",
    "            hwreturn.append(word.capitalize())\n",
    "            hwflag = 1            \n",
    "        elif word in hwsC: # like Walk\n",
    "            wordhwC.append(word)\n",
    "            hwreturn.append(word.lower())\n",
    "            hwflag = 1\n",
    "\n",
    "        if hwflag == 0:\n",
    "            dercnt = 0\n",
    "            for mwben in mwBens:                \n",
    "                if word == mwben['deriv'] or word == mwben['deriv'].capitalize() or word.capitalize() in mwben['deriv']:\n",
    "                    wordderiv.append(word)\n",
    "                    hwreturn.append(mwben['hw'])\n",
    "                    derivflag = 1\n",
    "                    print 'derivative: ', word, '--- hw: ', mwben['hw']\n",
    "                    dercnt += 1\n",
    "            if dercnt > 1: print word, '--- derivate has multiple hws --- ', dercnt\n",
    "\n",
    "        if hwflag == 0 and derivflag == 0:\n",
    "            if word.find(' ') == -1: wordnotBen.append(word)\n",
    "            else:\n",
    "                print '>>> >>> >>> >>> >> not a single word: ', word\n",
    "                for x in word.split(' '):\n",
    "                    if x in hws: hwreturn.append(x)\n",
    "                    elif x.capitalize() in hws: hwreturn.append(x.capitalize())\n",
    "                    elif x in hwsC: hwreturn.append(x.lower())\n",
    "                    else:\n",
    "                        wdflagx = 0 \n",
    "                        for mwben in mwBens:                \n",
    "                            if x == mwben['deriv'] or x == mwben['deriv'].capitalize() \\\n",
    "                            or x.capitalize() in mwben['deriv']:\n",
    "                                hwreturn.append(mwben['hw'])\n",
    "                                wdflagx = 1\n",
    "                        if wdflagx == 0: print '**************^^^^^^^!!@@@@@*************** really is not in mwBen: ', x\n",
    "                                \n",
    "                            \n",
    "            \n",
    "    \n",
    "    if wordhw: print '* same as hw: ', len(wordhw)  #,' -- ', wordhw\n",
    "    if wordhwC: print '* same as capitalized hw: ', len(wordhwC)  #,' -- ', wordhwC\n",
    "    if wordderiv: print '* words are derivatives: ', len(wordderiv) #,' -- ', wordderiv\n",
    "        \n",
    "    if len(txtraw) == len(wordhw) + len(wordhwC) + len(wordderiv) + len(wordnotBen): \n",
    "        if wordnotBen:\n",
    "            print '**************##########***************** not in mwBen: ', len(wordnotBen), ' -- ', wordnotBen\n",
    "#         print '--- len(txtraw) == len(wordhw) + len(wordhwC) + len(wordderiv) + len(wordnotBen) ---\\n'\n",
    "    else: print \"--- words' numbers don't mattch, check ---\\n\"\n",
    "    \n",
    "    dupl = [x for x in hwreturn if hwreturn.count(x)>1]\n",
    "    if dupl:\n",
    "        print 'how many duplicates in raw hwreturn --- ', len(dupl), ' - ', len(set(dupl)), ' = ', len(dupl)-len(set(dupl))\n",
    "        print dupl\n",
    "\n",
    "    print '\\nhow many hws supposed to be returned--- ', len(txtraw) - len(wordnotBen) - (len(dupl)-len(set(dupl)))\n",
    "    hwreturn = sorted(set(hwreturn))\n",
    "    print 'acutal return: ', len(hwreturn)\n",
    "    return hwreturn\n",
    "    \n",
    "print checkBymwBen('E:\\\\1Now\\\\taglist\\\\', 'testmwBen.txt')\n",
    "\n",
    "# result = checkBymwBen('E:\\\\1Now\\\\taglist\\\\', '3744BasicWords.txt')\n",
    "# f = codecs.open(\"E:\\\\1Now\\\\taglist\\\\2939BasicWords.txt\", 'w', 'utf-8')\n",
    "# for x in result:\n",
    "#     f.write(x + '\\n')\n",
    "# f.close()\n",
    "\n",
    "\n",
    "# import os\n",
    "# from os import listdir\n",
    "# from os.path import isfile, join\n",
    "\n",
    "# wlpath = \"E:\\\\1Now\\\\taglist\\\\mwlimgGrpwlRaw\\\\\"\n",
    "# for wlname in os.listdir(wlpath):\n",
    "#     if isfile(join(wlpath, wlname)):\n",
    "#         result = checkBymwBen(wlpath, wlname)\n",
    "#     else: continue\n",
    "    \n",
    "#     f = codecs.open(\"E:\\\\1Now\\\\taglist\\\\mwlimgGrpwl\\\\\" + wlname, 'w', 'utf-8')\n",
    "#     for x in result:\n",
    "#         f.write(x + '\\n')\n",
    "#     f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "------ E:\\1Now\\taglist\\testmwBen.txt ------\n",
      "* has words :  25\n",
      "* has unique word number:  24\n",
      "* has duplicates:  set([u'taking'])\n",
      "derivative:  Taking --- hw:  take\n",
      "derivative:  taking --- hw:  take\n",
      "derivative:  taking --- hw:  take\n",
      "derivative:  20/20 --- hw:  twenty-twenty\n",
      "derivative:  Flurries --- hw:  flurry\n",
      "derivative:  axes --- hw:  ax\n",
      "derivative:  axes --- hw:  axis\n",
      "axes --- derivate has multiple hws ---  2\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  runCIM\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  -\n",
      ">>> >>> >>> >>> >> not a single word:   \n",
      "**************^^^^^^^!!@@@@@*************** really is not in mwBen:  \n",
      "**************^^^^^^^!!@@@@@*************** really is not in mwBen:  \n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  2\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  3\n",
      "* same as hw:  10\n",
      "* capitalized hw:  4\n",
      "* words are derivatives:  7\n",
      "--- words' numbers don't mattch, check ---\n",
      "\n",
      "how many duplicates in raw hwreturn ---  13  -  5  =  8\n",
      "[u'takings', u'takings', u'take', u'blazing', u'blazing', u'take', u'twenty-twenty', u'impressionism', u'impressionism', u'take', u'take', u'take', u'twenty-twenty']\n",
      "\n",
      "how many hws supposed to be returned---  11\n",
      "acutal return:  13\n",
      "{'finederiv': [u'20/20', u'axes', u'flurries', u'taking'], 'noinben': [u'', u'-', u'2', u'3', u'runCIM'], 'rawhwderiv': [u'20/20', u'Blazing', u'Flurries', u'Impressionism', u'Taking', u'Takings', u'against', u'axes', u'blaze', u'blazing', u'impressionism', u'revolt', u'tAke', u'take', u'taken', u'taking', u'takings', u'took', u'twenty-twenty'], 'fineallhw': [u'against', u'ax', u'axis', u'blaze', u'blazing', u'flurry', u'impressionism', u'revolt', u'take', u'taken', u'takings', u'took', u'twenty-twenty']}\n"
     ]
    }
   ],
   "source": [
    "# check a word list:\n",
    "# * transfer to mwl hws\n",
    "# \n",
    "\n",
    "\n",
    "import codecs\n",
    "import re\n",
    "import string\n",
    "\n",
    "def tuneBymwBen(wlist=[], wlfile=''):\n",
    "    ''''''\n",
    "    rnt = []\n",
    "    hwreturn = [] # hws returned by this function    \n",
    "    \n",
    "    if wlfile:\n",
    "        print '\\n\\n------', wlfile, '------'\n",
    "        with codecs.open(wlfile, 'r', 'utf-8') as f:\n",
    "            txtraw = f.read().splitlines()\n",
    "    elif wlist:\n",
    "        txtraw = wlist        \n",
    "    \n",
    "    print '* has words : ', len(txtraw)\n",
    "    print '* has unique word number: ', len(set(txtraw))\n",
    "    dupinraw = set([x for x in txtraw if txtraw.count(x) > 1])\n",
    "    if dupinraw: print '* has duplicates: ', dupinraw\n",
    "\n",
    "\n",
    "    with codecs.open(\"E:\\\\1Now\\\\taglist\\\\mwlBenchmark.txt\", 'r', 'utf-8') as f:    \n",
    "        lines = f.read().splitlines()\n",
    "\n",
    "    # create mwBen dictionary\n",
    "    mwBens = []\n",
    "    hws = [] # sorted unique hws\n",
    "    hwsC = [] # sorted unique capitalized hws\n",
    "    for line in lines:\n",
    "        if len(line) < 1:\n",
    "            print 'len(line)<1', line \n",
    "            return -1\n",
    "        entry = {}\n",
    "        hw = line.split(';')[1]\n",
    "        entry['hw'] = hw\n",
    "        entry['deriv'] = line.split(';')[0] # derivative, or hw that has no derivatives\n",
    "        mwBens.append(entry)\n",
    "        hws.append(hw)\n",
    "        if hw[0] in string.lowercase[0:26]:\n",
    "            hwsC.append(hw.capitalize())\n",
    "        \n",
    "    hws = sorted(set(hws))\n",
    "    hwsC = sorted(set(hwsC))        \n",
    "\n",
    "\n",
    "    # begin to check the word list against mw benchmark dictionary\n",
    "    #  Word; Its-hw (Head Word)\n",
    "    #\n",
    "    # Three cases\n",
    "    # 1. word is exactly same as hw or is a capitalized hw (like 'Walk') or word.capitalize() is in hw (like 'leo')\n",
    "    # 2. word is a derivative or is a capitalized derivative (like 'Walks') or word.capitalize() is in derivate (like 'leos')\n",
    "    # 3. word is not in mwBen\n",
    "\n",
    "\n",
    "    wordhw = [] # word is exactly same as hw\n",
    "    wordhwL = [] # word.lower() is a hw, like 'Walk'\n",
    "    wordhwC = [] # word.capitalize() is a hw, like 'leo'\n",
    "    \n",
    "    wordDeriv = [] # raw derivatives or capitalized derivatives or derivative.lower()\n",
    "    fineDeriv = [] # fine derivateivs are in mwBen\n",
    "    hwofDeriv = [] # hws of derivatives\n",
    "    wordnotBen = [] # word is not in mwBen\n",
    "\n",
    "    for word in txtraw:\n",
    "        hwflag = 0 # suppose that word is not a hw\n",
    "        derivflag = 0 # suppose that word is not a derivative\n",
    "        \n",
    "        # first check if word is a hw\n",
    "        if word in hws:\n",
    "            wordhw.append(word)\n",
    "            hwreturn.append(word)\n",
    "            hwflag = 1\n",
    "        elif word.capitalize() in hws: # like leo\n",
    "            wordhwC.append(word)\n",
    "            hwreturn.append(word.capitalize())\n",
    "            hwflag = 1            \n",
    "        elif word.capitalize() in hwsC: # like Walk, tAke\n",
    "            wordhwL.append(word)\n",
    "            hwreturn.append(word.lower())\n",
    "            hwflag = 1\n",
    "\n",
    "        # if word isn't a hw, then check if it's a derivative\n",
    "        if hwflag == 0:\n",
    "            dercnt = 0\n",
    "            for mwben in mwBens:                \n",
    "                if word == mwben['deriv'] or word == mwben['deriv'].capitalize() or word.capitalize() == mwben['deriv']:\n",
    "                    wordDeriv.append(word)\n",
    "                    fineDeriv.append(mwben['deriv'])\n",
    "                    hwofDeriv.append(mwben['hw'])\n",
    "                    derivflag = 1\n",
    "                    print 'derivative: ', word, '--- hw: ', mwben['hw']\n",
    "                    dercnt += 1\n",
    "            if dercnt > 1: print word, '--- derivate has multiple hws --- ', dercnt\n",
    "\n",
    "        if hwflag == 0 and derivflag == 0:\n",
    "            if word.find(' ') == -1:\n",
    "                wordnotBen.append(word)\n",
    "                print '**************^^^^^^^!!@@@@@*************** is not in mwBen: ', word\n",
    "            else:\n",
    "                print '>>> >>> >>> >>> >> not a single word: ', word\n",
    "                for x in word.split(' '):\n",
    "                    if x in hws: hwreturn.append(x)\n",
    "                    elif x.capitalize() in hws: hwreturn.append(x.capitalize())\n",
    "                    elif x in hwsC: hwreturn.append(x.lower())\n",
    "                    else:\n",
    "                        wdflagx = 0 \n",
    "                        for mwben in mwBens:                \n",
    "                            if x == mwben['deriv'] or x == mwben['deriv'].capitalize() \\\n",
    "                            or x.capitalize() == mwben['deriv']:\n",
    "                                wordDeriv.append(word)\n",
    "                                fineDeriv.append(mwben['deriv'])\n",
    "                                hwofDeriv.append(mwben['hw'])\n",
    "                                wdflagx = 1\n",
    "                        if wdflagx == 0:\n",
    "                            wordnotBen.append(x)\n",
    "                            print '**************^^^^^^^!!@@@@@*************** really is not in mwBen: ', x\n",
    "                                \n",
    "                            \n",
    "            \n",
    "    \n",
    "    if wordhw: print '* same as hw: ', len(wordhw)  #,' -- ', wordhw\n",
    "    if wordhwL: print '* capitalized hw: ', len(wordhwL)  #,' -- ', wordhwL\n",
    "    if wordhwC: print '* hw typo, should be capitalized: ', len(wordhwC)  #,' -- ', wordhwC\n",
    "    \n",
    "    if wordDeriv: print '* words are derivatives: ', len(wordDeriv) #,' -- ', wordderiv\n",
    "        \n",
    "    if len(txtraw) == len(wordhw) + len(wordhwL) + len(wordhwC) + len(wordDeriv) + len(wordnotBen): \n",
    "        if wordnotBen:\n",
    "            print '**************##########***************** not in mwBen: ', len(wordnotBen), ' -- ', wordnotBen\n",
    "    else: print \"--- words' numbers don't mattch, check ---\\n\"\n",
    "\n",
    "        \n",
    "    rntdic = {}\n",
    "    rntdic['fineallhw'] = sorted(set(hwreturn + hwofDeriv))   \n",
    "    rntdic['finederiv'] = sorted(set(fineDeriv))\n",
    "    rntdic['rawhwderiv'] = sorted(set(wordhw + wordhwL + wordhwC + wordDeriv))\n",
    "    rntdic['noinben'] = sorted(set(wordnotBen))\n",
    "#     rnt.append(rntdic)\n",
    "    \n",
    "    \n",
    "    hwreturn += hwofDeriv    \n",
    "    dupl = [x for x in hwreturn if hwreturn.count(x)>1]\n",
    "    if dupl:\n",
    "        print 'how many duplicates in raw hwreturn --- ', len(dupl), ' - ', len(set(dupl)), ' = ', len(dupl)-len(set(dupl))\n",
    "        print dupl\n",
    "\n",
    "    print '\\nhow many hws supposed to be returned--- ', len(txtraw) - len(wordnotBen) - (len(dupl)-len(set(dupl)))\n",
    "    hwreturn = sorted(set(hwreturn))\n",
    "    print 'acutal return: ', len(hwreturn)\n",
    "    \n",
    "#     return rnt\n",
    "    return rntdic\n",
    "    \n",
    "print tuneBymwBen([], 'E:\\\\1Now\\\\taglist\\\\testmwBen.txt')\n",
    "\n",
    "# result = checkBymwBen('E:\\\\1Now\\\\taglist\\\\', '3744BasicWords.txt')\n",
    "# f = codecs.open(\"E:\\\\1Now\\\\taglist\\\\2939BasicWords.txt\", 'w', 'utf-8')\n",
    "# for x in result:\n",
    "#     f.write(x + '\\n')\n",
    "# f.close()\n",
    "\n",
    "\n",
    "# import os\n",
    "# from os import listdir\n",
    "# from os.path import isfile, join\n",
    "\n",
    "# wlpath = \"E:\\\\1Now\\\\taglist\\\\mwlimgGrpwlRaw\\\\\"\n",
    "# for wlname in os.listdir(wlpath):\n",
    "#     if isfile(join(wlpath, wlname)):\n",
    "#         result = checkBymwBen(wlpath, wlname)\n",
    "#     else: continue\n",
    "    \n",
    "#     f = codecs.open(\"E:\\\\1Now\\\\taglist\\\\mwlimgGrpwl\\\\\" + wlname, 'w', 'utf-8')\n",
    "#     for x in result:\n",
    "#         f.write(x + '\\n')\n",
    "#     f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* has words :  132\n",
      "* has unique word number:  132\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  \n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  -\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  09\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  2\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  29\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  3\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  47-3\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  53-4\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  DOCTER\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  PD1\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  PD2\n",
      "derivative:  caricatured --- hw:  caricature\n",
      "derivative:  characters --- hw:  character\n",
      "derivative:  compared --- hw:  compare\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  dendrites\n",
      "derivative:  dolls --- hw:  doll\n",
      "derivative:  emotions --- hw:  emotion\n",
      "derivative:  heard --- hw:  hear\n",
      "derivative:  movies --- hw:  movie\n",
      "derivative:  personalities --- hw:  personality\n",
      "derivative:  playing --- hw:  play\n",
      "derivative:  realized --- hw:  realize\n",
      "derivative:  realizing --- hw:  realize\n",
      "derivative:  stories --- hw:  story\n",
      "derivative:  subjects --- hw:  subject\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  that's\n",
      "derivative:  things --- hw:  thing\n",
      "derivative:  trains --- hw:  train\n",
      "derivative:  vessels --- hw:  vessel\n",
      "* same as hw:  97\n",
      "* capitalized hw:  6\n",
      "* words are derivatives:  16\n",
      "**************##########***************** not in mwBen:  13  --  [u'', u'-', u'09', u'2', u'29', u'3', u'47-3', u'53-4', u'DOCTER', u'PD1', u'PD2', u'dendrites', u\"that's\"]\n",
      "how many duplicates in raw hwreturn ---  10  -  5  =  5\n",
      "[u'and', u'she', u'well', u'and', u'movie', u'she', u'well', u'movie', u'realize', u'realize']\n",
      "\n",
      "how many hws supposed to be returned---  114\n",
      "acutal return:  114\n",
      "\n",
      "--------- before excluded -------\n",
      "\n",
      "[u'I', u\"I've\", u'OK', u'a', u'about', u'all', u'allow', u'and', u'animation', u'as', u'being', u'best', u'blas\\xe9', u'blood', u'bloodstream', u'body', u'brain', u'but', u'caf\\xe9', u'caricature', u'case', u'character', u'compare', u'consciousness', u'daughter', u'days', u'definitely', u'did', u'different', u'does', u'doll', u'dream', u'emotion', u'energy', u'exactly', u'excited', u'felt', u'floor', u'for', u'from', u'goofy', u'got', u'have', u'hear', u'high', u'human', u'if', u'in', u'including', u'instead', u'into', u'it', u'just', u'kid', u'kind', u'know', u'laid-back', u'led', u'like', u'little', u'lot', u'lucky', u'man', u'me', u'mind', u'more', u'movie', u'much', u'of', u'on', u'opinionated', u'opposed', u'our', u'over', u'personality', u'play', u'pretty', u'production', u'quiet', u'realize', u'reason', u'represent', u'seen', u'she', u'so', u'some', u'sort', u'stomach', u'story', u'strong', u'subject', u'tame', u'that', u'the', u'these', u'thing', u'thinking', u'this', u'through', u'to', u'train', u'traveling', u'us', u'vessel', u'was', u'we', u'well', u'went', u'were', u'what', u'with', u'would', u'yeah', u'you']\n",
      "\n",
      "--------- after excluded -------\n",
      "\n",
      "[u'animation', u'blas\\xe9', u'bloodstream', u'caf\\xe9', u'caricature', u'consciousness', u'goofy', u'laid-back', u'opinionated', u'tame']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def txt2wl(path, txtfile):\n",
    "    '''extract a word list from a text, return a sorted unqiue raw word list'''\n",
    "    with codecs.open(path + txtfile, 'r', 'utf-8') as f:\n",
    "        parags = f.read().splitlines() # each paragraph as one line\n",
    "    \n",
    "    wlraw = [] # raw word list from the text\n",
    "    for parag in parags:\n",
    "        regxp = re.compile(r'[^\\w\\'\\-]+', re.U) # regular expression pattern: ^\\w\\'\\- means not words ' -\n",
    "        parag = regxp.sub(' ', parag) # replace all not words ' - with a space\n",
    "        wlraw += parag.split(' ')\n",
    "    \n",
    "    rnt = sorted(set(wlraw))\n",
    "    return rnt\n",
    "\n",
    "# print txt2wl('E:\\\\1Now\\\\mae\\\\article\\\\', 'pd12.txt')\n",
    "\n",
    "\n",
    "def beaExclu(wlist=[], wlfile=''):\n",
    "    '''This function only excludes hws and their derivatives exactly in mwl.\n",
    "    So it's better to use tuneBymwBen() first to get a fine word list'''\n",
    "    \n",
    "    if wlfile:\n",
    "        with codecs.open(path + finewl, 'r', 'utf-8') as f:\n",
    "            words = f.read().splitlines()\n",
    "    elif wlist:\n",
    "        words = wlist\n",
    "        \n",
    "    with codecs.open(\"E:\\\\1Now\\\\mae\\\\beautifulExclu.txt\", 'r', 'utf-8') as f:\n",
    "        bexclus = f.read().splitlines()\n",
    "    \n",
    "    word4learn = []\n",
    "    for word in words:\n",
    "        if word not in bexclus: word4learn.append(word)\n",
    "    \n",
    "    return sorted(set(word4learn))\n",
    "    \n",
    "# print beaExclu(txt2wl('E:\\\\1Now\\\\mae\\\\article\\\\', 'pd12.txt'))\n",
    "allrnt = tuneBymwBen(txt2wl('E:\\\\1Now\\\\mae\\\\article\\\\', 'pd12.txt'))\n",
    "cnt = 0\n",
    "print '\\n--------- before excluded -------\\n'\n",
    "print allrnt['fineallhw']\n",
    "print '\\n--------- after excluded -------\\n'\n",
    "print beaExclu(allrnt['fineallhw'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Organize 'beautifulExcluHw.txt' and generate 'beautifulExclu.txt'\n",
    "# (note: words in beautifulExcluHw.txt are absolutely hws in 39195 of mwl)\n",
    "# directly from mwaled mongodb dpdict. words not being a hw in mwaled won't be added to the two lists\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# codecs if for read and write files with unicode, encoding 'utf-8'\n",
    "import codecs\n",
    "\n",
    "#connect to MongoDB\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client.dpdb  # databas: dpdb\n",
    "geweiDict = db.geweiDict201511 # collection (table): geweiDict201511\n",
    "#geweiDict = db.geweiDictTest\n",
    "\n",
    "\n",
    "with codecs.open(\"E:\\\\1Now\\\\mae\\\\beautifulExcluHw.txt\", 'r', 'utf-8') as f:\n",
    "    behws = f.read().splitlines()\n",
    "    f.close()    \n",
    "# sort and make unique words in beautifulExcluHw.txt\n",
    "behws = sorted(set(behws))\n",
    "print 'number of excluded hw: ', len(behws)\n",
    "fd = codecs.open(\"E:\\\\1Now\\\\mae\\\\beautifulExcluHw.txt\", 'w', 'utf-8')\n",
    "for behw in behws:\n",
    "    fd.write(behw + '\\n')\n",
    "fd.close()\n",
    "    \n",
    "fdict = codecs.open('E:\\\\1Now\\\\mae\\\\beautifulExcluraw.txt', 'w', 'utf-8')\n",
    "    \n",
    "results = geweiDict.find({}, {\"_id\":0, \"hw\":1, \"infl\":1, \"subhw\":1}) #.limit(1000)\n",
    "\n",
    "# total number of head words\n",
    "totalhw = 0\n",
    "totalcnt = 0\n",
    "\n",
    "for result in results:    \n",
    "    word = result.get(\"hw\")    \n",
    "\n",
    "    if word and word in behws:\n",
    "        #print word\n",
    "#         fdict.write(word + ';' + word + '\\n')\n",
    "        fdict.write(word + '\\n')\n",
    "        totalhw += 1\n",
    "    else:\n",
    "#         print \"no head word\"\n",
    "        continue\n",
    "\n",
    "    # get items of result\n",
    "    infls = result.get(\"infl\")\n",
    "    subhws = result.get(\"subhw\")     \n",
    "    \n",
    "    if infls:\n",
    "        for infl in infls:\n",
    "#             fdict.write(infl + ';' + word + '\\n')\n",
    "            fdict.write(infl + '\\n')\n",
    "            totalcnt += 1   \n",
    "            \n",
    "    if subhws:\n",
    "        for subhw in subhws:\n",
    "            if subhw[0] != word[0]: continue # check if subhw is a real sub hw of word by comparing first letter\n",
    "#             fdict.write(subhw + ';' + word  + '\\n')\n",
    "            fdict.write(subhw + '\\n')\n",
    "            totalcnt += 1        \n",
    "    \n",
    "fdict.close()\n",
    "print \"total head words: \", totalhw\n",
    "print \"total words: \", totalcnt + totalhw\n",
    "\n",
    "\n",
    "# sort out by head words and make them unique\n",
    "with codecs.open('E:\\\\1Now\\\\mae\\\\beautifulExcluraw.txt', 'r', 'utf-8') as f:\n",
    "    lines = f.read().splitlines()\n",
    "lines = sorted(set(lines))\n",
    "#lines = sorted(lines)\n",
    "\n",
    "fd = codecs.open('E:\\\\1Now\\\\mae\\\\beautifulExclu.txt', 'w', 'utf-8')\n",
    "cnt = 0\n",
    "for line in lines:\n",
    "    fd.write(line + '\\n')\n",
    "    cnt += 1\n",
    "fd.close()\n",
    "print 'unique words:', cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "def compareWordlist(path, wl1, wl2):\n",
    "    '''get common and different parts of two word lists'''\n",
    "    with codecs.open(path + wl1, 'r', 'utf-8') as f:\n",
    "        words1 = f.read().splitlines()\n",
    "    with codecs.open(path + wl2, 'r', 'utf-8') as f:\n",
    "        words2 = f.read().splitlines()\n",
    "    comm = [x for x in words1 if x in words2]\n",
    "    only1 = [x for x in words1 if x not in words2]\n",
    "    only2 = [x for x in words2 if x not in words1]\n",
    "    \n",
    "    f = codecs.open('E:\\\\1Now\\\\taglist\\\\compare\\\\' + wl1 + '_' + wl2 + '.txt', 'w', 'utf-8')\n",
    "    \n",
    "    f.write('words only in ' + wl1 + ': ' + str(len(only1)) + '\\n')\n",
    "    for x in only1:\n",
    "        f.write(x + '\\n')    \n",
    "    \n",
    "    f.write('\\n\\nwords only in ' + wl2 + ': ' + str(len(only2)) + '\\n')\n",
    "    for x in only2:\n",
    "        f.write(x + '\\n')       \n",
    "    \n",
    "    f.write('\\n\\ncommon words of ' + wl1 + ' and ' + wl2 + ': ' + str(len(comm)) + '\\n')\n",
    "    for x in comm:\n",
    "        f.write(x + '\\n')\n",
    "        \n",
    "    f.close()\n",
    "\n",
    "compareWordlist(\"E:\\\\1Now\\\\mae\\\\\", \"31img.txt\", \"33img.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what are basic words of mwl?\n",
    "import codecs\n",
    "with codecs.open('E:\\\\1Now\\\\taglist\\\\3775BasicWordsfromDB.txt', 'r', 'utf-8') as f:\n",
    "    lines = f.read().splitlines()\n",
    "words = sorted(lines, key=lambda s: s.lower())\n",
    "f = codecs.open('E:\\\\1Now\\\\taglist\\\\bwrawSort.txt', 'w', 'utf-8')\n",
    "for word in words:\n",
    "    f.write(word + '\\n')\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walk\n",
      "Awol\n",
      "-ness\n",
      "February\n",
      "<type 'str'>\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print 'walk'.capitalize() # Walk is good\n",
    "print 'AWOL'.capitalize() # not good because Awol isn't a word\n",
    "print '-ness'.capitalize()\n",
    "print 'February'.capitalize()\n",
    "al = string.lowercase[0:26]\n",
    "print type(al)\n",
    "# for x in al: print x\n",
    "print 'Tuesday'[0] in al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABCDEFGHIJKLMNOPQRSTUVWXYZ\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print string.uppercase[0:26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 4, 5}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get duplicates\n",
    "l = [1,2,3,4,4,5,5,6,1]\n",
    "set([x for x in l if l.count(x) > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3905 3140\n",
      "661\n",
      "set([])\n"
     ]
    }
   ],
   "source": [
    "# output core31.txt by processing core3000raw20151123.txt\n",
    "\n",
    "with codecs.open('E:\\\\1Now\\\\taglist\\\\core3000raw20151123.txt', 'r', 'utf-8') as f:\n",
    "    lines = f.read().splitlines()\n",
    "words = [x.split('\\t')[0] for x in lines]\n",
    "wordsu = sorted(set(words))\n",
    "fout = codecs.open('E:\\\\1Now\\\\taglist\\\\core3140n.txt', 'w', 'utf-8')\n",
    "for word in wordsu:\n",
    "    fout.write(word + '\\n')\n",
    "fout.close()\n",
    "\n",
    "print len(words), len(wordsu)\n",
    "dupl = set([x for x in words if words.count(x)>1])\n",
    "print len(dupl)\n",
    "# print sorted(dupl)\n",
    "\n",
    "# # compare core3140n.txt and core31.txt\n",
    "# with codecs.open('E:\\\\1Now\\\\taglist\\\\core31.txt', 'r', 'utf-8') as f:\n",
    "#     core31s = f.read().splitlines()\n",
    "#     f.close()\n",
    "# print set(core31s) ^ set(wordsu)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello ... hello2\n",
      "hi ... hi2\n"
     ]
    }
   ],
   "source": [
    "def gethw():\n",
    "    a = [{'k1': 'hello', 'k2':'hello2'}, {'k1': 'hi', 'k2':'hi2'}]\n",
    "    return a\n",
    "b = gethw()\n",
    "for x in b:\n",
    "    print x['k1'], '...', x['k2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"thEy're café\".title()\n",
    "print \"thEy're café\".capitalize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = \"joy and café surprise.&nbsp;<br />And as I was ... surprise.And that\"\n",
    "print re.sub(r'[\\<\\>\\/\\&\\.\\;]+', ' ', a)\n",
    "print u'é'\n",
    "\n",
    "b = u\"café laid-back, <code>that's</tag>\" # u -- unicode \n",
    "c = \"café laid-back, <code>that's</tag>\"\n",
    "\n",
    "xx = re.compile(r'[^\\w\\'\\-]+', re.U)\n",
    "print xx.sub('...', b) # work\n",
    "print xx.sub('...', c) # doesn't work\n",
    "\n",
    "print re.sub(r'[^A-Za-z\\'\\-]+', '...', b)\n",
    "print re.sub(r'[^\\w+]', '---', b, re.U) # why this one doesn't work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-f6fe266591e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hi'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hello'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\codecs.pyc\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 694\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwritelines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\codecs.pyc\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, object)\u001b[0m\n\u001b[0;32m    356\u001b[0m         \"\"\"\n\u001b[0;32m    357\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsumed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwritelines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file"
     ]
    }
   ],
   "source": [
    "\n",
    "# is it necessary to close file in with statement?\n",
    "with codecs.open('E:\\\\temp\\\\with.txt', 'w', 'utf-8') as f:\n",
    "    f.write('hi')\n",
    "    f.close() # no need, it'll be closed automatically\n",
    "f.write('hello') # f has been closed automatically\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
