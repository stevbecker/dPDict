{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ------ Load These Five Functions First ---\n",
    "\n",
    "# 1. tuneBymwBen(wlist=[], path='', wfile='')\n",
    "# 2. tuneReport(wlist=[], path='', wfile='')\n",
    "# 3. txt2wl(path='', wfile='')\n",
    "# 4. hw4learn(playtype=1, wdict={}, wlist=[], path='', wfile='', excluf='E:\\\\1Now\\\\taglist\\\\2939exclu.txt')\n",
    "# 5. compareWordlist(l1=[], l2=[], path='', f1='', f2='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* has words :  869\n",
      "* has unique word number:  869\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  \n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  -\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  0\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  00\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  01\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  02-17\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  03\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  03-0\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  05\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  09\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  1\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  10\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  11\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  11-13\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  12-18\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  13\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  14\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  16\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  17\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  18\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  19\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  19-8\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  2\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  20\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  24\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  27\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  29\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  3\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  30-10\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  32\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  32-12\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  33\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  35\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  35-17\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  36\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  37\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  38-5\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  4\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  41\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  41-11\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  43\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  44-1\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  45-19\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  47\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  47-3\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  48-20\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  51\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  53-4\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  56-4\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  58-2\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  6\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  8\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  9\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  Andrew\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  Carmen\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  Catmull\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  DOCTER\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  Dacher\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  Denmark\n",
      "---derivative:  Dr --- hw:  Dr.\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  Ekman\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  Francisco\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  Jonas\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  Keltner\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  Lasseter\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  Minnesota\n",
      "inflection:  Others --- hw:  other\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  PD1\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  PD10\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  PD11\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  PD12\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  PD13\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  PD14\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  PD15\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  PD16\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  PD17\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  PD18\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  PD2\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  PD3\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  PD4\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  PD5\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  PD6\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  PD7\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  PD8\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  PD9\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  Paul\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  Pixar\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  Ranft\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  Rivera\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  Ronnie\n",
      "---derivative:  Sadness --- hw:  sad\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  San\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  Stanton\n",
      "inflection:  Studios --- hw:  studio\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  That's\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  Unkrich\n",
      "inflection:  adaptations --- hw:  adaptation\n",
      "inflection:  adding --- hw:  add\n",
      "---derivative:  adulthood --- hw:  adult\n",
      "inflection:  all-nighters --- hw:  all-nighter\n",
      "inflection:  allows --- hw:  allow\n",
      "inflection:  asked --- hw:  ask\n",
      "inflection:  aspects --- hw:  aspect\n",
      "inflection:  assuaged --- hw:  assuage\n",
      "inflection:  attracted --- hw:  attract\n",
      "---derivative:  blissfully --- hw:  blissful\n",
      "inflection:  called --- hw:  call\n",
      "inflection:  caricatured --- hw:  caricature\n",
      "inflection:  cases --- hw:  case\n",
      "inflection:  chairs --- hw:  chair\n",
      "inflection:  chances --- hw:  chance\n",
      "inflection:  changes --- hw:  change\n",
      "inflection:  characters --- hw:  character\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  co-director\n",
      "inflection:  comes --- hw:  come\n",
      "inflection:  compared --- hw:  compare\n",
      "---derivative:  completely --- hw:  complete\n",
      "inflection:  connecting --- hw:  connect\n",
      "inflection:  connections --- hw:  connection\n",
      "inflection:  consulted --- hw:  consult\n",
      "inflection:  deals --- hw:  deal\n",
      "inflection:  decoding --- hw:  decode\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  deeper\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  deepest\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  del\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  dendrites\n",
      "inflection:  directed --- hw:  direct\n",
      "inflection:  discussions --- hw:  discussion\n",
      "inflection:  dolls --- hw:  doll\n",
      "inflection:  doodling --- hw:  doodle\n",
      "inflection:  drawings --- hw:  drawing\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  easier\n",
      "inflection:  effects --- hw:  effect\n",
      "inflection:  elements --- hw:  element\n",
      "inflection:  embarrassed --- hw:  embarrass\n",
      "inflection:  embracing --- hw:  embrace\n",
      "---derivative:  emotionally --- hw:  emotional\n",
      "inflection:  emotions --- hw:  emotion\n",
      "inflection:  existing --- hw:  exist\n",
      "inflection:  expecting --- hw:  expect\n",
      "inflection:  experts --- hw:  expert\n",
      "inflection:  eyes --- hw:  eye\n",
      "inflection:  faces --- hw:  face\n",
      "---derivative:  fairness --- hw:  fair\n",
      "inflection:  falling --- hw:  fall\n",
      "inflection:  fears --- hw:  fear\n",
      "inflection:  feels --- hw:  feel\n",
      "inflection:  filmmakers --- hw:  filmmaker\n",
      "inflection:  films --- hw:  film\n",
      "inflection:  findings --- hw:  finding\n",
      "inflection:  flukes --- hw:  fluke\n",
      "inflection:  folks --- hw:  folk\n",
      "inflection:  friends --- hw:  friend\n",
      "inflection:  getting --- hw:  get\n",
      "inflection:  globes --- hw:  globe\n",
      "inflection:  growing --- hw:  grow\n",
      "inflection:  guys --- hw:  guy\n",
      "inflection:  hands --- hw:  hand\n",
      "inflection:  happened --- hw:  happen\n",
      "inflection:  hats --- hw:  hat\n",
      "inflection:  having --- hw:  have\n",
      "inflection:  headaches --- hw:  headache\n",
      "inflection:  heard --- hw:  hear\n",
      "inflection:  helped --- hw:  help\n",
      "---derivative:  identifiable --- hw:  identify\n",
      "inflection:  identified --- hw:  identify\n",
      "---derivative:  initially --- hw:  initial\n",
      "---derivative:  interconnection --- hw:  interconnect\n",
      "inflection:  introduced --- hw:  introduce\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  iterate\n",
      "inflection:  joys --- hw:  joy\n",
      "inflection:  keeps --- hw:  keep\n",
      "inflection:  kids --- hw:  kid\n",
      "inflection:  laughs --- hw:  laugh\n",
      "inflection:  lessons --- hw:  lesson\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  longer\n",
      "inflection:  looking --- hw:  look\n",
      "inflection:  looks --- hw:  look\n",
      "inflection:  memories --- hw:  memory\n",
      "---derivative:  metaphorically --- hw:  metaphor\n",
      "inflection:  mistakes --- hw:  mistake\n",
      "inflection:  models --- hw:  model\n",
      "---derivative:  motivator --- hw:  motivate\n",
      "inflection:  moved --- hw:  move\n",
      "inflection:  movies --- hw:  movie\n",
      "inflection:  named --- hw:  name\n",
      "inflection:  needed --- hw:  need\n",
      "inflection:  particles --- hw:  particle\n",
      "inflection:  personalities --- hw:  personality\n",
      "inflection:  pitching --- hw:  pitch\n",
      "inflection:  places --- hw:  place\n",
      "inflection:  playing --- hw:  play\n",
      "inflection:  points --- hw:  point\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  re-establishing\n",
      "inflection:  realized --- hw:  realize\n",
      "inflection:  realizing --- hw:  realize\n",
      "inflection:  reasons --- hw:  reason\n",
      "inflection:  relationships --- hw:  relationship\n",
      "inflection:  representing --- hw:  represent\n",
      "inflection:  responded --- hw:  respond\n",
      "inflection:  responsibilities --- hw:  responsibility\n",
      "---derivative:  sadness --- hw:  sad\n",
      "inflection:  scenes --- hw:  scene\n",
      "---derivative:  scientifically --- hw:  scientific\n",
      "inflection:  scientists --- hw:  scientist\n",
      "inflection:  screened --- hw:  screen\n",
      "inflection:  seemed --- hw:  seem\n",
      "inflection:  seems --- hw:  seem\n",
      "inflection:  sets --- hw:  set\n",
      "inflection:  songs --- hw:  song\n",
      "inflection:  splitting --- hw:  split\n",
      "inflection:  spying --- hw:  spy\n",
      "inflection:  started --- hw:  start\n",
      "---derivative:  statistically --- hw:  statistic\n",
      "inflection:  stayed --- hw:  stay\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  stick-figure\n",
      "inflection:  stories --- hw:  story\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  storyboarding\n",
      "inflection:  subjects --- hw:  subject\n",
      "inflection:  taking --- hw:  take\n",
      "inflection:  talked --- hw:  talk\n",
      "inflection:  talking --- hw:  talk\n",
      "inflection:  tells --- hw:  tell\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  that's\n",
      "inflection:  themes --- hw:  theme\n",
      "inflection:  things --- hw:  thing\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  three-month\n",
      "inflection:  tinged --- hw:  tinge\n",
      "inflection:  trains --- hw:  train\n",
      "---derivative:  turned --- hw:  head\n",
      "inflection:  vessels --- hw:  vessel\n",
      "inflection:  visualized --- hw:  visualize\n",
      "inflection:  visuals --- hw:  visual\n",
      "inflection:  waiting --- hw:  wait\n",
      "inflection:  wanted --- hw:  want\n",
      "inflection:  watching --- hw:  watch\n",
      "inflection:  wearing --- hw:  wear\n",
      "inflection:  weekends --- hw:  weekend\n",
      "inflection:  weeks --- hw:  week\n",
      "---derivative:  weirdly --- hw:  weird\n",
      "inflection:  worked --- hw:  work\n",
      "inflection:  years --- hw:  year\n",
      "**************^^^^^^^!!@@@@@*************** is not in mwBen:  younger\n",
      "* same as hw:  573\n",
      "* capitalized hw:  53\n",
      "* words are derivatives:  17\n",
      "* words are inflections:  120\n",
      "\n",
      "**************##########***************** All not in mwBen:  106 \n",
      "[u'', u'-', u'0', u'00', u'01', u'02-17', u'03', u'03-0', u'05', u'09', u'1', u'10', u'11', u'11-13', u'12-18', u'13', u'14', u'16', u'17', u'18', u'19', u'19-8', u'2', u'20', u'24', u'27', u'29', u'3', u'30-10', u'32', u'32-12', u'33', u'35', u'35-17', u'36', u'37', u'38-5', u'4', u'41', u'41-11', u'43', u'44-1', u'45-19', u'47', u'47-3', u'48-20', u'51', u'53-4', u'56-4', u'58-2', u'6', u'8', u'9', u'Andrew', u'Carmen', u'Catmull', u'DOCTER', u'Dacher', u'Denmark', u'Ekman', u'Francisco', u'Jonas', u'Keltner', u'Lasseter', u'Minnesota', u'PD1', u'PD10', u'PD11', u'PD12', u'PD13', u'PD14', u'PD15', u'PD16', u'PD17', u'PD18', u'PD2', u'PD3', u'PD4', u'PD5', u'PD6', u'PD7', u'PD8', u'PD9', u'Paul', u'Pixar', u'Ranft', u'Rivera', u'Ronnie', u'San', u'Stanton', u\"That's\", u'Unkrich', u'co-director', u'deeper', u'deepest', u'del', u'dendrites', u'easier', u'iterate', u'longer', u're-establishing', u'stick-figure', u'storyboarding', u\"that's\", u'three-month', u'younger']\n",
      "\n",
      "---words to learn---:  119\n",
      "deck:soundPlay ( hw:\"'cause\" or hw:\"Dr\" or hw:\"I'd\" or hw:\"I'm\" or hw:\"I've\" or hw:\"Sunday\" or hw:\"absolutely\" or hw:\"adaptation\" or hw:\"all-nighter\" or hw:\"alongside\" or hw:\"animation\" or hw:\"aspect\" or hw:\"assuage\" or hw:\"blissfully\" or hw:\"bloodstream\" or hw:\"caricature\" or hw:\"cloudy\" or hw:\"consciousness\" or hw:\"deck\" or hw:\"decode\" or hw:\"definitely\" or hw:\"definitive\" or hw:\"dialogue\" or hw:\"doodle\" or hw:\"ed\" or hw:\"editorial\" or hw:\"eight\" or hw:\"embrace\" or hw:\"eyewitness\" or hw:\"fairly\" or hw:\"fifth\" or hw:\"filmmaker\" or hw:\"five\" or hw:\"fluent\" or hw:\"fluke\" or hw:\"folk\" or hw:\"globe\" or hw:\"goofy\" or hw:\"he's\" or hw:\"headache\" or hw:\"headquarters\" or hw:\"intensive\" or hw:\"interact\" or hw:\"interconnection\" or hw:\"intuition\" or hw:\"it's\" or hw:\"joe\" or hw:\"john\" or hw:\"laid-back\" or hw:\"largely\" or hw:\"laughter\" or hw:\"lee\" or hw:\"let's\" or hw:\"long-term\" or hw:\"luckily\" or hw:\"manageable\" or hw:\"melancholy\" or hw:\"metaphorically\" or hw:\"mom\" or hw:\"motivator\" or hw:\"online\" or hw:\"opinionated\" or hw:\"outwardly\" or hw:\"producer\" or hw:\"purity\" or hw:\"quickly\" or hw:\"receipt\" or hw:\"redundancy\" or hw:\"regulate\" or hw:\"relatively\" or hw:\"revelation\" or hw:\"ripped\" or hw:\"roil\" or hw:\"s\" or hw:\"sacred\" or hw:\"scary\" or hw:\"script\" or hw:\"seven\" or hw:\"she's\" or hw:\"six\" or hw:\"slowly\" or hw:\"spark\" or hw:\"spiel\" or hw:\"spy\" or hw:\"statistically\" or hw:\"studio\" or hw:\"suddenly\" or hw:\"sunny\" or hw:\"surroundings\" or hw:\"susceptible\" or hw:\"tame\" or hw:\"testimony\" or hw:\"there's\" or hw:\"they're\" or hw:\"they've\" or hw:\"third\" or hw:\"those\" or hw:\"three\" or hw:\"tinge\" or hw:\"totally\" or hw:\"tricky\" or hw:\"two\" or hw:\"ultimate\" or hw:\"uncertainty\" or hw:\"unchanging\" or hw:\"unreliable\" or hw:\"upcoming\" or hw:\"usually\" or hw:\"visual\" or hw:\"visualize\" or hw:\"we've\" or hw:\"weird\" or hw:\"weirdly\" or hw:\"whammy\" or hw:\"whereby\" or hw:\"who's\" or hw:\"wrestling\" or hw:\"yeah\" or hw:\"you're\")\n"
     ]
    }
   ],
   "source": [
    "# --- You have an article, and want to extract a word list to learn in Anki (sentence or sound play) ---\n",
    "\n",
    "wlraw = txt2wl('E:\\\\1Now\\\\mae\\\\article\\\\', 'pd1_18.txt')\n",
    "rnt = tuneReport(wlist=wlraw)\n",
    "soundPlay = hw4learn(1, wdict=rnt)\n",
    "# sPlay = hw4learn(2, wdict=rnt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "------ E:\\1Now\\taglist\\46sounds2.txt ------\n",
      "* has words :  212\n",
      "* has unique word number:  212\n",
      "---derivative:  oceanic --- hw:  ocean\n",
      "* same as hw:  211\n",
      "* words are derivatives:  1\n",
      "\n",
      "---words to learn---:  212\n",
      "deck:soundPlay ( hw:\"McCoy\" or hw:\"Satan\" or hw:\"above\" or hw:\"abut\" or hw:\"acquisition\" or hw:\"adjective\" or hw:\"air\" or hw:\"aqua\" or hw:\"arduous\" or hw:\"arrive\" or hw:\"autumn\" or hw:\"azure\" or hw:\"baby\" or hw:\"banner\" or hw:\"bare\" or hw:\"battle\" or hw:\"bear\" or hw:\"beauty\" or hw:\"beer\" or hw:\"bet\" or hw:\"betel\" or hw:\"bird\" or hw:\"blue\" or hw:\"boar\" or hw:\"bone\" or hw:\"boor\" or hw:\"bosun\" or hw:\"boulder\" or hw:\"boy\" or hw:\"bread\" or hw:\"budget\" or hw:\"buzz\" or hw:\"captain\" or hw:\"cello\" or hw:\"chasm\" or hw:\"chauffeur\" or hw:\"cheetah\" or hw:\"choir\" or hw:\"circus\" or hw:\"coat\" or hw:\"coin\" or hw:\"collegiate\" or hw:\"comb\" or hw:\"conscious\" or hw:\"cornucopia\" or hw:\"cot\" or hw:\"cotton\" or hw:\"could\" or hw:\"cracked\" or hw:\"crazed\" or hw:\"crew\" or hw:\"cushion\" or hw:\"cute\" or hw:\"day\" or hw:\"days\" or hw:\"did\" or hw:\"do\" or hw:\"doe\" or hw:\"dollar\" or hw:\"door\" or hw:\"dummy\" or hw:\"dye\" or hw:\"earth\" or hw:\"easy\" or hw:\"eat\" or hw:\"egg\" or hw:\"emir\" or hw:\"err\" or hw:\"exaggerate\" or hw:\"example\" or hw:\"fact\" or hw:\"fade\" or hw:\"famous\" or hw:\"fan\" or hw:\"farther\" or hw:\"fascinate\" or hw:\"fascism\" or hw:\"father\" or hw:\"fern\" or hw:\"feud\" or hw:\"few\" or hw:\"fine\" or hw:\"flu\" or hw:\"fur\" or hw:\"gem\" or hw:\"genuflect\" or hw:\"ghost\" or hw:\"glazier\" or hw:\"go\" or hw:\"graduation\" or hw:\"grief\" or hw:\"guide\" or hw:\"hat\" or hw:\"hear\" or hw:\"hillock\" or hw:\"humdrum\" or hw:\"hurry\" or hw:\"idol\" or hw:\"ink\" or hw:\"journal\" or hw:\"joy\" or hw:\"key\" or hw:\"knot\" or hw:\"know\" or hw:\"laugh\" or hw:\"liar\" or hw:\"lie\" or hw:\"loud\" or hw:\"low\" or hw:\"luncheon\" or hw:\"lure\" or hw:\"machine\" or hw:\"main\" or hw:\"marinate\" or hw:\"mass\" or hw:\"mat\" or hw:\"match\" or hw:\"mattress\" or hw:\"me\" or hw:\"measure\" or hw:\"mission\" or hw:\"mnemonic\" or hw:\"myth\" or hw:\"nation\" or hw:\"nature\" or hw:\"nauseous\" or hw:\"no\" or hw:\"now\" or hw:\"ocean\" or hw:\"oceanic\" or hw:\"odd\" or hw:\"offer\" or hw:\"ogre\" or hw:\"oh\" or hw:\"one\" or hw:\"opinion\" or hw:\"patois\" or hw:\"pedal\" or hw:\"persuade\" or hw:\"physician\" or hw:\"pick\" or hw:\"pier\" or hw:\"port\" or hw:\"pour\" or hw:\"pretty\" or hw:\"prey\" or hw:\"pull\" or hw:\"question\" or hw:\"race\" or hw:\"receive\" or hw:\"red\" or hw:\"region\" or hw:\"rheumatism\" or hw:\"rhyme\" or hw:\"rich\" or hw:\"rough\" or hw:\"rubber\" or hw:\"satin\" or hw:\"sausage\" or hw:\"savvy\" or hw:\"saw\" or hw:\"say\" or hw:\"schism\" or hw:\"schist\" or hw:\"school\" or hw:\"see\" or hw:\"serious\" or hw:\"shah\" or hw:\"shy\" or hw:\"sign\" or hw:\"silent\" or hw:\"sing\" or hw:\"ski\" or hw:\"sly\" or hw:\"soccer\" or hw:\"soldier\" or hw:\"sorry\" or hw:\"special\" or hw:\"squirrel\" or hw:\"steak\" or hw:\"stop\" or hw:\"strenuous\" or hw:\"sudden\" or hw:\"sugar\" or hw:\"supper\" or hw:\"take\" or hw:\"tax\" or hw:\"telephone\" or hw:\"their\" or hw:\"there\" or hw:\"thin\" or hw:\"this\" or hw:\"tip\" or hw:\"tissue\" or hw:\"tour\" or hw:\"unit\" or hw:\"vein\" or hw:\"very\" or hw:\"vinyl\" or hw:\"vision\" or hw:\"war\" or hw:\"way\" or hw:\"weird\" or hw:\"whale\" or hw:\"woman\" or hw:\"wood\" or hw:\"world\" or hw:\"write\" or hw:\"xylophone\" or hw:\"yard\" or hw:\"youth\" or hw:\"zone\")\n"
     ]
    }
   ],
   "source": [
    "# --- You have a word list, and want to learn them in Anki (sentence or sound play) ---\n",
    "\n",
    "rnt = tuneReport(path='E:\\\\1Now\\\\taglist\\\\', wfile='46sounds2.txt')\n",
    "soundPlay = hw4learn(1, wdict=rnt, excluf='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- load 5 functions ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import codecs\n",
    "import re\n",
    "import string\n",
    "\n",
    "def tuneBymwBen(wlist=[], path='', wfile=''):        \n",
    "    \n",
    "    if wfile:\n",
    "        print '\\n\\n------', path+wfile, '------'\n",
    "        with codecs.open(path+wfile, 'r', 'utf-8') as f:\n",
    "            txtraw = f.read().splitlines()\n",
    "        txtraw = [x.strip() for x in txtraw]\n",
    "    elif wlist:\n",
    "        txtraw = [x.strip() for x in wlist]\n",
    "    else:\n",
    "        print 'function argumenents error'\n",
    "        return -1\n",
    "    \n",
    "    print '* has words : ', len(txtraw)\n",
    "    print '* has unique word number: ', len(set(txtraw))\n",
    "    dupinraw = set([x for x in txtraw if txtraw.count(x) > 1])\n",
    "    if dupinraw: print '* has duplicates: ', dupinraw\n",
    "   \n",
    "        \n",
    "    with codecs.open(\"E:\\\\1Now\\\\taglist\\\\mwlBenchmark.txt\", 'r', 'utf-8') as f:    \n",
    "        lines = f.read().splitlines()\n",
    "\n",
    "    # generate mwBen dictionary    \n",
    "    hws = [] # sorted unique hws\n",
    "    hwsC = [] # sorted unique capitalized hws\n",
    "#     mwBens = []\n",
    "    mwBenDerivs = []\n",
    "    mwBenInfls = []\n",
    "    \n",
    "    \n",
    "    for line in lines:\n",
    "#         if len(line) < 1:\n",
    "#             print 'len(line)<1', line \n",
    "#             return -1\n",
    "        hw = line.split(';')[2]\n",
    "        wtype = line.split(';')[0]\n",
    "                \n",
    "        entry = {}\n",
    "        if wtype == '2':            \n",
    "            entry['hw'] = hw\n",
    "            entry['deriv'] = line.split(';')[1] # derivative\n",
    "            mwBenDerivs.append(entry)\n",
    "        elif wtype == '3':            \n",
    "            entry['hw'] = hw\n",
    "            entry['infl'] = line.split(';')[1] # inflection\n",
    "            mwBenInfls.append(entry)\n",
    "                \n",
    "        hws.append(hw)\n",
    "        if hw[0] in string.lowercase[0:26]:\n",
    "            hwsC.append(hw.capitalize())\n",
    "        \n",
    "    hws = sorted(set(hws))\n",
    "    hwsC = sorted(set(hwsC))        \n",
    "\n",
    "\n",
    "    # begin to check the word list against mw benchmark dictionary\n",
    "    #  Word; Its-hw (Head Word)\n",
    "    #\n",
    "    # Three cases\n",
    "    # 1. word is exactly same as hw or is a capitalized hw (like 'Walk') or word.capitalize() is in hw (like 'leo')\n",
    "    # 2. word is a derivative or is a capitalized derivative (like 'Walks') or word.capitalize() is in derivate (like 'leos')\n",
    "    # 3. word is not in mwBen\n",
    "\n",
    "    \n",
    "    hwreturn = [] # hws returned by this function\n",
    "    \n",
    "    wordhw = [] # word is exactly same as hw\n",
    "    wordhwL = [] # word.lower() is a hw, like 'Walk'\n",
    "    wordhwC = [] # word.capitalize() is a hw, like 'leo'\n",
    "    \n",
    "    wordDeriv = [] # raw derivatives or capitalized derivatives or derivative.lower()\n",
    "    fineDeriv = [] # fine derivateivs are in mwBen\n",
    "    hwofDeriv = [] # hws of derivatives\n",
    "    \n",
    "    wordInfl = [] # raw inflections or capitalized inflections or inflection.lower()\n",
    "    fineInfl = [] # fine inflections are in mwBen\n",
    "    hwofInfl = [] # hws of inflections\n",
    "    \n",
    "    wordnotBen = [] # word is not in mwBen\n",
    "\n",
    "    for word in txtraw:\n",
    "        hwflag = 0 # suppose that word is not a hw\n",
    "        derivflag = 0 # suppose that word is not a derivative\n",
    "        inflflag = 0 # suppose that word is not a inflection\n",
    "        \n",
    "        # first check if word is a hw\n",
    "        if word in hws:\n",
    "            wordhw.append(word)\n",
    "            hwreturn.append(word)\n",
    "            hwflag = 1\n",
    "        elif word.capitalize() in hws: # like leo\n",
    "            wordhwC.append(word)\n",
    "            hwreturn.append(word.capitalize())\n",
    "            hwflag = 1            \n",
    "        elif word.capitalize() in hwsC: # like Walk, tAke\n",
    "            wordhwL.append(word)\n",
    "            hwreturn.append(word.lower())\n",
    "            hwflag = 1\n",
    "\n",
    "        # if word isn't a hw, then check if it's a derivative\n",
    "        if hwflag == 0:\n",
    "            dercnt = 0\n",
    "            for mwben in mwBenDerivs:                \n",
    "                if word == mwben['deriv'] or word == mwben['deriv'].capitalize() or word.capitalize() == mwben['deriv']:\n",
    "                    wordDeriv.append(word)\n",
    "                    fineDeriv.append(mwben['deriv'])\n",
    "                    hwofDeriv.append(mwben['hw'])\n",
    "                    derivflag = 1\n",
    "                    print '---derivative: ', word, '--- hw: ', mwben['hw']\n",
    "                    dercnt += 1\n",
    "            if dercnt > 1: print word, '--- derivate has multiple hws --- ', dercnt\n",
    "\n",
    "        if hwflag == 0 and derivflag == 0:\n",
    "            inflcnt = 0\n",
    "            for mwben in mwBenInfls:                \n",
    "                if word == mwben['infl'] or word == mwben['infl'].capitalize() or word.capitalize() == mwben['infl']:\n",
    "                    wordInfl.append(word)\n",
    "                    fineInfl.append(mwben['infl'])\n",
    "                    hwofInfl.append(mwben['hw'])\n",
    "                    inflflag = 1\n",
    "                    print 'inflection: ', word, '--- hw: ', mwben['hw']\n",
    "                    inflcnt += 1\n",
    "            if inflcnt > 1: print word, '--- inflection has multiple hws --- ', inflcnt                \n",
    "                \n",
    "                \n",
    "        if hwflag == 0 and derivflag == 0 and inflflag == 0:\n",
    "            if word.find(' ') == -1:\n",
    "                wordnotBen.append(word)\n",
    "                print '**************^^^^^^^!!@@@@@*************** is not in mwBen: ', word\n",
    "            else:\n",
    "                print '>>> >>> >>> >>> >> not a single word: ', word\n",
    "                for x in word.split(' '):\n",
    "                    if x in hws: hwreturn.append(x)\n",
    "                    elif x.capitalize() in hws: hwreturn.append(x.capitalize())\n",
    "                    elif x in hwsC: hwreturn.append(x.lower())\n",
    "                    else:\n",
    "                        wdflagx = 0 \n",
    "                        for mwben in mwBenDerivs:                \n",
    "                            if x == mwben['deriv'] or x == mwben['deriv'].capitalize() \\\n",
    "                            or x.capitalize() == mwben['deriv']:\n",
    "                                wordDeriv.append(word)\n",
    "                                fineDeriv.append(mwben['deriv'])\n",
    "                                hwofDeriv.append(mwben['hw'])\n",
    "                                wdflagx = 1\n",
    "                        if wdflagx == 0:\n",
    "                            for mwben in mwBenInfls:                \n",
    "                                if x == mwben['infl'] or x == mwben['infl'].capitalize() \\\n",
    "                                or x.capitalize() == mwben['infl']:\n",
    "                                    wordInfl.append(word)\n",
    "                                    fineInfl.append(mwben['infl'])\n",
    "                                    hwofInfl.append(mwben['hw'])\n",
    "                                    wdflagx = 1\n",
    "                        if wdflagx == 0:\n",
    "                            wordnotBen.append(x)\n",
    "                            print '**************^^^^^^^!!@@@@@*************** really is not in mwBen: ', x\n",
    "                                \n",
    "                            \n",
    "            \n",
    "    \n",
    "    if wordhw: print '* same as hw: ', len(wordhw)  #,' -- ', wordhw\n",
    "    if wordhwL: print '* capitalized hw: ', len(wordhwL)  #,' -- ', wordhwL\n",
    "    if wordhwC: print '* hw typo, should be capitalized: ', len(wordhwC)  #,' -- ', wordhwC\n",
    "    \n",
    "    if wordDeriv: print '* words are derivatives: ', len(wordDeriv) #,' -- ', wordDeriv\n",
    "    if wordInfl: print '* words are inflections: ', len(wordInfl) #,' -- ', wordInfl\n",
    "\n",
    "    if wordnotBen:\n",
    "        print '\\n**************##########***************** All not in mwBen: ', len(wordnotBen), '\\n', wordnotBen\n",
    "        \n",
    "#     if len(txtraw) == len(wordhw) + len(wordhwL) + len(wordhwC) + len(wordDeriv) + len(wordnotBen):         \n",
    "#     else: print \"--- words' numbers don't mattch, check ---\\n\"\n",
    "\n",
    "        \n",
    "    rntdic = {}    \n",
    "    rntdic['tunehw'] = sorted(set(hwreturn))\n",
    "    rntdic['hwofDeriv'] = sorted(set(hwofDeriv))\n",
    "    rntdic['tuneDeriv'] = sorted(set(fineDeriv))\n",
    "    rntdic['hwofInfl'] = sorted(set(hwofInfl))\n",
    "    rntdic['tuneInfl'] = sorted(set(fineInfl))\n",
    "    rntdic['rawhwderiv'] = sorted(set(wordhw + wordhwL + wordhwC + wordDeriv + wordInfl))\n",
    "    rntdic['notinben'] = sorted(set(wordnotBen))\n",
    "    \n",
    "    return rntdic\n",
    "    \n",
    "# tuneBymwBen(path='E:\\\\1Now\\\\taglist\\\\', wfile='testmwBen.txt') \n",
    "\n",
    "\n",
    "def tuneReport(wlist=[], path='', wfile=''):\n",
    "    if wlist: fname = 'tuneReport-list.txt'\n",
    "    elif wfile: fname = 'tuneReport-' + wfile\n",
    "    else:\n",
    "        print 'arguments error'\n",
    "        return -1\n",
    "    \n",
    "    rnt = tuneBymwBen(wlist, path, wfile)\n",
    "    \n",
    "    tunehw = rnt['tunehw']\n",
    "    hwofDeriv = rnt['hwofDeriv']\n",
    "    tuneDeriv = rnt['tuneDeriv'] \n",
    "    hwofInfl = rnt['hwofInfl']\n",
    "    tuneInfl = rnt['tuneInfl']\n",
    "    notinben = rnt['notinben']    \n",
    "    #rawhwderiv = rnt['rawhwderiv']\n",
    "    \n",
    "    fd = codecs.open('E:\\\\1Now\\\\mae\\\\report\\\\' + fname, 'w', 'utf-8')\n",
    "    if notinben:\n",
    "        fd.write('---not in mwBen---:' + str(len(notinben)) + '\\n')\n",
    "        for x in notinben: fd.write(x + '\\n')\n",
    "    if tunehw:\n",
    "        fd.write('\\n\\n--- tuned hws of raw hws which are in mwBen---: ' + str(len(tunehw)) + '\\n')\n",
    "        for x in tunehw: fd.write(x + '\\n')\n",
    "    if hwofDeriv:\n",
    "        fd.write('\\n\\n--- tuned hws of raw derivatives which are in mwBen---: ' + str(len(hwofDeriv)) + '\\n')\n",
    "        for x in hwofDeriv: fd.write(x + '\\n')\n",
    "    if tuneDeriv:\n",
    "        fd.write('\\n\\n--- all tuned derivatives which are in mwBen---: ' + str(len(tuneDeriv)) + '\\n')\n",
    "        for x in tuneDeriv: fd.write(x + '\\n') \n",
    "    if hwofInfl:\n",
    "        fd.write('\\n\\n--- tuned hws of raw inflections which are in mwBen---: ' + str(len(hwofInfl)) + '\\n')\n",
    "        for x in hwofInfl: fd.write(x + '\\n')\n",
    "    if tuneInfl:\n",
    "        fd.write('\\n\\n--- all tuned inflections which are in mwBen---: ' + str(len(tuneInfl)) + '\\n')\n",
    "        for x in tuneInfl: fd.write(x + '\\n')             \n",
    "\n",
    "    fd.close()\n",
    "    return rnt\n",
    "       \n",
    "# tuneReport(path='E:\\\\1Now\\\\taglist\\\\', wfile='testmwBen.txt')\n",
    "\n",
    "\n",
    "\n",
    "def txt2wl(path='', wfile=''):\n",
    "    '''extract a word list from a text, return a sorted unqiue raw word list'''\n",
    "    if wfile:\n",
    "        with codecs.open(path + wfile, 'r', 'utf-8') as f:\n",
    "            parags = f.read().splitlines() # each paragraph as one line\n",
    "    else:\n",
    "        print 'argument error'\n",
    "        return -1\n",
    "    \n",
    "    wlraw = [] # raw word list from the text\n",
    "    for parag in parags:\n",
    "        regxp = re.compile(r'[^\\w\\'\\-]+', re.U) # regular expression pattern: ^\\w\\'\\- means not words ' -\n",
    "        parag = regxp.sub(' ', parag) # replace all not words ' - with a space\n",
    "        wlraw += parag.split(' ')\n",
    "    \n",
    "    return sorted(set(wlraw))\n",
    "\n",
    "\n",
    "\n",
    "def hw4learn(playtype=1, wdict={}, wlist=[], path='', wfile='', excluf='E:\\\\1Now\\\\taglist\\\\2939exclu.txt'):\n",
    "    '''This function only excludes hws and their derivatives exactly in mwl.\n",
    "    So it's better to use tuneBymwBen() first to get a fine word list\n",
    "    playtype=1 (sound play)\n",
    "    playtype=2 (sentence play)\n",
    "    '''\n",
    "  \n",
    "    if wdict:\n",
    "        if playtype == 1:  words = wdict['tunehw'] + wdict['hwofInfl'] + wdict['tuneDeriv']\n",
    "        elif playtype ==2: words = wdict['tunehw'] + wdict['hwofDeriv'] + wdict['hwofInfl']        \n",
    "    elif wlist:\n",
    "        words = [x.strip() for x in wlist]\n",
    "    elif wfile:\n",
    "        with codecs.open(path + wfile, 'r', 'utf-8') as f:\n",
    "            words = f.read().splitlines()\n",
    "        words = [x.strip() for x in words]\n",
    "    else:\n",
    "        print 'argument error'\n",
    "        return -1\n",
    "    \n",
    "    \n",
    "    word4learn = []       \n",
    "    if excluf:\n",
    "        with codecs.open(excluf, 'r', 'utf-8') as f:\n",
    "            bexclus = f.read().splitlines()    \n",
    "        for word in words:\n",
    "            if word not in bexclus: word4learn.append(word)\n",
    "    else:\n",
    "        word4learn = words\n",
    "            \n",
    "    word4learn = sorted(set(word4learn))\n",
    "    \n",
    "    # generate Anki search string for filtered deck    \n",
    "    if playtype == 1:   ankiSearchStr = 'deck:soundPlay ('\n",
    "    elif playtype == 2: ankiSearchStr = 'deck:sPlay ('\n",
    "        \n",
    "    for x in word4learn:\n",
    "        if x != word4learn[-1]: ankiSearchStr += ' hw:\"' + x + '\" or'\n",
    "        else: ankiSearchStr += ' hw:\"' + x + '\")'\n",
    "    print '\\n---words to learn---: ', len(word4learn)\n",
    "    print ankiSearchStr\n",
    "        \n",
    "#     return word4learn\n",
    "\n",
    "\n",
    "def compareWordlist(l1=[], l2=[], path='', f1='', f2=''):\n",
    "    '''get common and different parts of two lists or word lists of two files'''\n",
    "    \n",
    "    if l1:\n",
    "        words1 = l1\n",
    "#         words1 = [x.strip() for x in l1]\n",
    "        f1name = 'list-1'\n",
    "    if l2:\n",
    "        words2 = l2\n",
    "#         words2 = [x.strip() for x in l2]\n",
    "        f2name = 'list-2'\n",
    "    if f1:\n",
    "        with codecs.open(path+f1, 'r', 'utf-8') as f:\n",
    "            words1 = f.read().splitlines()\n",
    "#         words1 = [x.strip() for x in words1]\n",
    "        f1name = f1\n",
    "    if f2:\n",
    "        with codecs.open(path+f2, 'r', 'utf-8') as f:\n",
    "            words2 = f.read().splitlines()\n",
    "#         words2 = [x.strip() for x in words2]\n",
    "        f2name = f2\n",
    "            \n",
    "    comm = [x for x in words1 if x in words2]\n",
    "    only1 = [x for x in words1 if x not in words2]\n",
    "    only2 = [x for x in words2 if x not in words1]\n",
    "    \n",
    "    comm = sorted(set(comm))\n",
    "    \n",
    "    f = codecs.open('E:\\\\1Now\\\\taglist\\\\report\\\\compare_' + f1name + '_' + f2name + '.txt', 'w', 'utf-8')\n",
    "    \n",
    "    print '---common words of ' + f1name + ' and ' + f2name + '---: ' + str(len(comm))\n",
    "    f.write('---common words of ' + f1name + ' and ' + f2name + '---: ' + str(len(comm)) + '\\n')\n",
    "    for x in comm:\n",
    "        f.write(x + '\\n')\n",
    "    \n",
    "    print '---words only in ' + f1name + '---: ' + str(len(only1))\n",
    "    f.write('\\n\\n---words only in ' + f1name + '---: ' + str(len(only1)) + '\\n')\n",
    "    for x in only1:\n",
    "        f.write(x + '\\n')    \n",
    "    \n",
    "    print '---words only in ' + f2name + '---: ' + str(len(only2))\n",
    "    f.write('\\n\\n---words only in ' + f2name + '---: ' + str(len(only2)) + '\\n')\n",
    "    for x in only2:\n",
    "        f.write(x + '\\n')\n",
    "        \n",
    "    f.close()\n",
    "\n",
    "    \n",
    "print '--- load 5 functions ---'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique words :  134\n",
      "134\n",
      "number of notes in Anki:  134\n"
     ]
    }
   ],
   "source": [
    "# check number of words and notes in a filtered deck\n",
    "# first export the filted deck in Anki\n",
    "\n",
    "import codecs\n",
    "with codecs.open('E:\\\\1Now\\\\mae\\\\article\\\\filter_46sounds1.txt', 'r', 'utf-8') as f:\n",
    "    lines = f.read().splitlines()\n",
    "words = [x.split('\\t')[0] for x in lines]\n",
    "words = sorted(words)\n",
    "print 'number of unique words : ', len(set(words))\n",
    "\n",
    "b = {}\n",
    "for x in words:     \n",
    "    b[x] = words.count(x)\n",
    "#     print x, b[x]\n",
    "print len(b)\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "for x in b:\n",
    "    #print x, b[x]\n",
    "    cnt += b[x]\n",
    "print 'number of notes in Anki: ', cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of excluded hw:  2939\n",
      "total head words:  5011\n",
      "total words:  31600\n",
      "unique words: 9833\n"
     ]
    }
   ],
   "source": [
    "# Organize 'beautifulExcluHw.txt' and generate 'beautifulExclu.txt'\n",
    "# (note: words in beautifulExcluHw.txt are absolutely hws in 39195 of mwl)\n",
    "# directly from mwaled mongodb dpdict. words not being a hw in mwaled won't be added to the two lists\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# codecs if for read and write files with unicode, encoding 'utf-8'\n",
    "import codecs\n",
    "\n",
    "#connect to MongoDB\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client.dpdb  # databas: dpdb\n",
    "geweiDict = db.geweiDict201511 # collection (table): geweiDict201511\n",
    "#geweiDict = db.geweiDictTest\n",
    "\n",
    "\n",
    "with codecs.open(\"E:\\\\1Now\\\\taglist\\\\2939bw.txt\", 'r', 'utf-8') as f:\n",
    "    behws = f.read().splitlines()\n",
    "    f.close()    \n",
    "# sort and make unique words in beautifulExcluHw.txt\n",
    "behws = sorted(set(behws))\n",
    "print 'number of excluded hw: ', len(behws)\n",
    "\n",
    "# fd = codecs.open(\"E:\\\\1Now\\\\mae\\\\beautifulExcluHw.txt\", 'w', 'utf-8')\n",
    "# for behw in behws:\n",
    "#     fd.write(behw + '\\n')\n",
    "# fd.close()\n",
    "    \n",
    "fdict = codecs.open('E:\\\\1Now\\\\mae\\\\beautifulExcluraw.txt', 'w', 'utf-8')\n",
    "    \n",
    "results = geweiDict.find({}, {\"_id\":0, \"hw\":1, \"infl\":1, \"subhw\":1}) #.limit(1000)\n",
    "\n",
    "# total number of head words\n",
    "totalhw = 0\n",
    "totalcnt = 0\n",
    "\n",
    "for result in results:    \n",
    "    word = result.get(\"hw\")    \n",
    "\n",
    "    if word and word in behws:\n",
    "        #print word\n",
    "#         fdict.write(word + ';' + word + '\\n')\n",
    "        fdict.write(word + '\\n')\n",
    "        totalhw += 1\n",
    "    else:\n",
    "#         print \"no head word\"\n",
    "        continue\n",
    "\n",
    "    # get items of result\n",
    "    infls = result.get(\"infl\")\n",
    "    subhws = result.get(\"subhw\")     \n",
    "    \n",
    "    if infls:\n",
    "        for infl in infls:\n",
    "#             fdict.write(infl + ';' + word + '\\n')\n",
    "            fdict.write(infl + '\\n')\n",
    "            totalcnt += 1   \n",
    "            \n",
    "    if subhws:\n",
    "        for subhw in subhws:\n",
    "            if subhw[0] != word[0]: continue # check if subhw is a real sub hw of word by comparing first letter\n",
    "#             fdict.write(subhw + ';' + word  + '\\n')\n",
    "            fdict.write(subhw + '\\n')\n",
    "            totalcnt += 1        \n",
    "    \n",
    "fdict.close()\n",
    "print \"total head words: \", totalhw\n",
    "print \"total words: \", totalcnt + totalhw\n",
    "\n",
    "\n",
    "# sort out by head words and make them unique\n",
    "with codecs.open('E:\\\\1Now\\\\mae\\\\beautifulExcluraw.txt', 'r', 'utf-8') as f:\n",
    "    lines = f.read().splitlines()\n",
    "lines = sorted(set(lines))\n",
    "print 'unique words:', len(lines)\n",
    "#lines = sorted(lines)\n",
    "\n",
    "fd = codecs.open('E:\\\\1Now\\\\mae\\\\beautifulExclu.txt', 'w', 'utf-8')\n",
    "for line in lines:\n",
    "    fd.write(line + '\\n')\n",
    "fd.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- mwBen statistics ---\n",
      "total head words:  39195\n",
      "total inflections:  64355\n",
      "total subhws:  8493\n",
      "total subhws whose 1st letters are different from hws:  158\n",
      "hw without any derivatives:  11221\n",
      "\n",
      "\n",
      "number of lines in mwBen before adding 84en_fr.txt:  84069\n",
      "number of unique lines in mwBen before adding 84en_fr.txt:  53853\n",
      "number of lines in 84en_fr.txt:  84\n",
      "number of unique lines in 84en_fr.txt:  83\n",
      "---common words of list-1 and list-2---: 15\n",
      "---words only in list-1---: 68\n",
      "---words only in list-2---: 53838\n",
      "number of lines in mwBen after adding 84en_fr.txt:  53921\n"
     ]
    }
   ],
   "source": [
    "# output mwlBenchmark.txt (mwBen) (no duplicate lines)\n",
    "# 2015-11-28, 2015-11-30, 2015-12-01, 2015-12-08\n",
    "\n",
    "# sort and make every line unique\n",
    "# format: n;hw, derivative, or inflection;hw\n",
    "# 1 - head word; 2 - derivative; 3 - inflection\n",
    "\n",
    "# 1;truly;truly\n",
    "# 2;blazingly;blazing\n",
    "# 3;blazes;blaze\n",
    "# 3;blazing;blaze\n",
    "\n",
    "# By the lines above, I can know blaze and blazing are hws, the two lines below are not allowd \n",
    "# because hws have derivates or inflections:\n",
    "# blaze;blaze\n",
    "# blazing;blazing\n",
    "# the two lines above are redundant.\n",
    "\n",
    "# manually delete: asas\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# codecs if for read and write files with unicode, encoding 'utf-8'\n",
    "import codecs\n",
    "\n",
    "#connect to MongoDB\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client.dpdb  # databas: dpdb\n",
    "geweiDict = db.geweiDict201511 # collection (table): geweiDict201511\n",
    "#geweiDict = db.geweiDictTest\n",
    "\n",
    "fdict = codecs.open('E:\\\\1Now\\\\taglist\\\\mwlBenchmarkraw.txt', 'w', 'utf-8')\n",
    "    \n",
    "results = geweiDict.find({}, {\"_id\":0, \"hw\":1, \"infl\":1, \"subhw\":1}) #.limit(1000)\n",
    "# sort method will use much more memory\n",
    "#results = geweiDict.find({}, {\"_id\":0, \"hw\":1, \"prn\":1, \"alles\":1, \"idpvs\":1, \"sublist\":1}).sort(\"hw\", 1).limit(1000)\n",
    "\n",
    "\n",
    "hwcnt = 0 # number of head words (hws)\n",
    "# hwcapcnt = 0 # number of hws capitalized\n",
    "inflcnt = 0 # number of inflections\n",
    "subhwcnt = 0 # number of subhws\n",
    "subhw1cnt = 0 # number of subhws whose first letter is not same as hw\n",
    "onlyhwcnt = 0\n",
    "\n",
    "# subhw1hw = []\n",
    "\n",
    "for result in results:\n",
    "    inflflag = 0\n",
    "    subhwflag = 0\n",
    "    \n",
    "    word = result.get(\"hw\")    \n",
    "    if word:\n",
    "        #print word\n",
    "#         fdict.write(word + ';' + word + '\\n')\n",
    "        hwcnt += 1      \n",
    "    else:\n",
    "        print \"no head word\"\n",
    "        continue\n",
    "\n",
    "    # get items of result\n",
    "    subhws = result.get(\"subhw\")\n",
    "    infls = result.get(\"infl\")         \n",
    "    \n",
    "    if subhws:\n",
    "        for subhw in subhws:\n",
    "            #if subhw[0] != word[0]: continue       \n",
    "            if subhw.lower() == word.lower():\n",
    "                #print 'subhw == word', subhw\n",
    "                continue           \n",
    "            if infls:\n",
    "                if subhw in infls:\n",
    "                    #print '----subhw in infls:', subhw\n",
    "                    continue\n",
    "                    \n",
    "            if subhw[0] != word[0]:\n",
    "                #print 'subhw is not like word: ', subhw, '...', word\n",
    "                subhw1cnt += 1\n",
    "                #subhw1hw.append(subhw+';'+word)\n",
    "            fdict.write('2;' + subhw + ';' + word + '\\n')\n",
    "            subhwcnt += 1      \n",
    "            subhwflag = 1    \n",
    "    \n",
    "    \n",
    "    if infls:\n",
    "        for infl in infls:\n",
    "            if infl.lower() == word.lower():\n",
    "                #print 'infl == word', infl\n",
    "                continue\n",
    "            fdict.write('3;' + infl + ';' + word + '\\n')\n",
    "            inflcnt += 1   \n",
    "            inflflag = 1\n",
    "            \n",
    "            \n",
    "    # hw;hw (only when hw has no inflections and no subhws)\n",
    "    if inflflag == 0 and subhwflag == 0:\n",
    "        fdict.write('1;' + word + ';' + word + '\\n')\n",
    "        onlyhwcnt += 1\n",
    "    \n",
    "fdict.close()\n",
    "\n",
    "print '--- mwBen statistics ---'\n",
    "print \"total head words: \", hwcnt\n",
    "# print 'total hws capitalized: ', hwcapcnt\n",
    "print \"total inflections: \", inflcnt\n",
    "print 'total subhws: ', subhwcnt\n",
    "print 'total subhws whose 1st letters are different from hws: ', subhw1cnt\n",
    "print 'hw without any derivatives: ', onlyhwcnt\n",
    "\n",
    "\n",
    "with codecs.open('E:\\\\1Now\\\\taglist\\\\mwlBenchmarkraw.txt', 'r', 'utf-8') as f:\n",
    "    mwls = f.read().splitlines()\n",
    "print '\\n\\nnumber of lines in mwBen before adding 84en_fr.txt: ', len(mwls)\n",
    "mwls = sorted(set(mwls))\n",
    "print 'number of unique lines in mwBen before adding 84en_fr.txt: ', len(mwls)\n",
    "\n",
    "# read en_fr.txt\n",
    "with codecs.open('E:\\\\1Now\\\\taglist\\\\84en_fr.txt', 'r', 'utf-8') as f:\n",
    "    enfrs = f.read().splitlines()\n",
    "print 'number of lines in 84en_fr.txt: ', len(enfrs)\n",
    "enfrs = sorted(set(enfrs))\n",
    "print 'number of unique lines in 84en_fr.txt: ', len(set(enfrs))\n",
    "\n",
    "compareWordlist(l1=enfrs, l2=mwls)\n",
    "\n",
    "# sort and make unique\n",
    "lines = sorted(set(mwls + enfrs))\n",
    "print 'number of lines in mwBen after adding 84en_fr.txt: ', len(lines)\n",
    "\n",
    "fd = codecs.open('E:\\\\1Now\\\\taglist\\\\mwlBenchmark.txt', 'w', 'utf-8')\n",
    "for line in lines:\n",
    "    fd.write(line + '\\n')\n",
    "fd.close()\n",
    "\n",
    "\n",
    "# subhw1hw = sorted(set(subhw1hw))\n",
    "# fd = codecs.open('E:\\\\1Now\\\\taglist\\\\subhw1hw.txt', 'w', 'utf-8')\n",
    "# for x in subhw1hw:\n",
    "#     fd.write(x + '\\n')\n",
    "# fd.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- explore mwBen ---\n",
      "number of derivative column:  53972\n",
      "number of hw column:  53972\n",
      "unique number of hw column:  34398\n",
      "number of derivatives (inflections and subhws) whose 1st letter different from hws:  337\n",
      "number of capitalized hws:  1487\n"
     ]
    }
   ],
   "source": [
    "# explore mwBen\n",
    "\n",
    "import codecs\n",
    "import string\n",
    "\n",
    "with codecs.open('E:\\\\1Now\\\\taglist\\\\mwlBenchmark.txt', 'r', 'utf-8') as f:\n",
    "    lines = f.read().splitlines()\n",
    "\n",
    "deriv = [] # derivative\n",
    "benhw = [] # hw\n",
    "deriv1hw = [] # derivative (inflection, subhw) first letter different from its hw\n",
    "hwcap = [] # hw whose first letter is capitalized\n",
    "for line in lines:\n",
    "    x1 = line.split(';')[0]\n",
    "    x2 = line.split(';')[1]\n",
    "    deriv.append(x1)\n",
    "    benhw.append(x2)\n",
    "    if x1[0] != x2[0]: deriv1hw.append(line)\n",
    "    if x2[0] in string.uppercase[0:26]: hwcap.append(x2)\n",
    "derivS = sorted(deriv)\n",
    "benhwSU = sorted(set(benhw)) # Sorted, Unique\n",
    "hwcap = sorted(set(hwcap))\n",
    "\n",
    "print '--- explore mwBen ---'\n",
    "print 'number of derivative column: ', len(deriv)\n",
    "print 'number of hw column: ', len(benhw)\n",
    "print 'unique number of hw column: ', len(benhwSU)\n",
    "print 'number of derivatives (inflections and subhws) whose 1st letter different from hws: ', len(deriv1hw)\n",
    "print 'number of capitalized hws: ', len(hwcap)\n",
    "\n",
    "fout = codecs.open('E:\\\\1Now\\\\taglist\\\\mwlStat.txt', 'w', 'utf-8')\n",
    "fout.write('--- statistics ---\\n')\n",
    "fout.write('number of lines in mwBen: ' + str(len(deriv)) + '\\n')\n",
    "fout.write('unique number of hw: ' + str(len(benhwSU)) + '\\n')\n",
    "fout.write('number of derivatives (inflections and subhws) whose 1st letter different from hws: ' + str(len(deriv1hw)) + '\\n')\n",
    "fout.write('number of capitalized hws: ' + str(len(hwcap)) + '\\n')\n",
    "\n",
    "fout.write('Contents\\n--------\\n')\n",
    "fout.write(\"Q: Are there duplicate derivatives who aren't hws in mwBen?\\n\")\n",
    "fout.write(\"Q: List derivatives (inflections and subhws) whose first letter is different from the first letter of their hws\\n\")\n",
    "fout.write(\"Capitalized hws\\n\\n\")\n",
    "\n",
    "# Q: Are there duplicate derivatives who aren't hws in mwBen?\n",
    "dupderiv = [x for x in derivS if x not in benhwSU and derivS.count(x)>1]\n",
    "fout.write(\"--- Duplicate derivatives not being hws: ---\\n\")\n",
    "for x in dupderiv:\n",
    "    fout.write(x + '\\n')\n",
    "\n",
    "# Q: List subhws whose first letter is different from the first letter of their hws\n",
    "fout.write(\"\\n--- derivatives (inflections and subhws) whose 1st letter different from hws: ---\\n\")\n",
    "fout.write(\"derivatives (inflections and subhws);hw\\n\\n\")\n",
    "for x in subhw1hw:\n",
    "    fout.write(x + '\\n')\n",
    "\n",
    "fout.write(\"\\n--- Capitalized hws: ---\\n\")\n",
    "for x in hwcap:\n",
    "    fout.write(x + '\\n')\n",
    "           \n",
    "fout.close()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
