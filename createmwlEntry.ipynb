{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### tuneBymwBen(wlist=[], path='', wfile='')\n",
    "# tuneReport(wlist=[], path='', wfile='')\n",
    "# txt2wl(path='', wfile='')\n",
    "# hw4learn(wdict={}, wlist=[], path='', wfile='', excluf='E:\\\\1Now\\\\taglist\\\\2939exclu.txt')\n",
    "# compareWordlist(l1=[], l2=[], path='', f1='', f2='')\n",
    "\n",
    "\n",
    "# tuneBymwBen(path='E:\\\\1Now\\\\taglist\\\\', wfile='testmwBen.txt') \n",
    "# tuneReport(path='E:\\\\1Now\\\\taglist\\\\', wfile='testmwBen.txt')\n",
    "\n",
    "### A typcial usage example: create words to learn Anki search string from an article\n",
    "# wlraw = txt2wl('E:\\\\1Now\\\\mae\\\\article\\\\', 'pd1_18.txt')\n",
    "# rnt = tuneReport(wlist=wlraw)\n",
    "# # rnt = tuneReport(path='E:\\\\1Now\\\\taglist\\\\', wfile='46sounds2.txt')\n",
    "# sound4learn = hw4learn(wdict=rnt)\n",
    "\n",
    "\n",
    "# compareWordlist(path=\"E:\\\\1Now\\\\taglist\\\\\", f1=\"84en_fr.txt\", f2=\"mwlBenchmark.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- load 5 functions ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import codecs\n",
    "import re\n",
    "import string\n",
    "\n",
    "def tuneBymwBen(wlist=[], path='', wfile=''):        \n",
    "    \n",
    "    if wfile:\n",
    "        print '\\n\\n------', path+wfile, '------'\n",
    "        with codecs.open(path+wfile, 'r', 'utf-8') as f:\n",
    "            txtraw = f.read().splitlines()\n",
    "        txtraw = [x.strip() for x in txtraw]\n",
    "    elif wlist:\n",
    "        txtraw = [x.strip() for x in wlist]\n",
    "    else:\n",
    "        print 'function argumenents error'\n",
    "        return -1\n",
    "    \n",
    "    print '* has words : ', len(txtraw)\n",
    "    print '* has unique word number: ', len(set(txtraw))\n",
    "    dupinraw = set([x for x in txtraw if txtraw.count(x) > 1])\n",
    "    if dupinraw: print '* has duplicates: ', dupinraw\n",
    "   \n",
    "        \n",
    "    with codecs.open(\"E:\\\\1Now\\\\taglist\\\\mwlBenchmark.txt\", 'r', 'utf-8') as f:    \n",
    "        lines = f.read().splitlines()\n",
    "\n",
    "    # generate mwBen dictionary    \n",
    "    hws = [] # sorted unique hws\n",
    "    hwsC = [] # sorted unique capitalized hws\n",
    "#     mwBens = []\n",
    "    mwBenDerivs = []\n",
    "    mwBenInfls = []\n",
    "    \n",
    "    \n",
    "    for line in lines:\n",
    "#         if len(line) < 1:\n",
    "#             print 'len(line)<1', line \n",
    "#             return -1\n",
    "        hw = line.split(';')[2]\n",
    "        wtype = line.split(';')[0]\n",
    "                \n",
    "        entry = {}\n",
    "        if wtype == '2':            \n",
    "            entry['hw'] = hw\n",
    "            entry['deriv'] = line.split(';')[1] # derivative\n",
    "            mwBenDerivs.append(entry)\n",
    "        elif wtype == '3':            \n",
    "            entry['hw'] = hw\n",
    "            entry['infl'] = line.split(';')[1] # inflection\n",
    "            mwBenInfls.append(entry)\n",
    "                \n",
    "        hws.append(hw)\n",
    "        if hw[0] in string.lowercase[0:26]:\n",
    "            hwsC.append(hw.capitalize())\n",
    "        \n",
    "    hws = sorted(set(hws))\n",
    "    hwsC = sorted(set(hwsC))        \n",
    "\n",
    "\n",
    "    # begin to check the word list against mw benchmark dictionary\n",
    "    #  Word; Its-hw (Head Word)\n",
    "    #\n",
    "    # Three cases\n",
    "    # 1. word is exactly same as hw or is a capitalized hw (like 'Walk') or word.capitalize() is in hw (like 'leo')\n",
    "    # 2. word is a derivative or is a capitalized derivative (like 'Walks') or word.capitalize() is in derivate (like 'leos')\n",
    "    # 3. word is not in mwBen\n",
    "\n",
    "    \n",
    "    hwreturn = [] # hws returned by this function\n",
    "    \n",
    "    wordhw = [] # word is exactly same as hw\n",
    "    wordhwL = [] # word.lower() is a hw, like 'Walk'\n",
    "    wordhwC = [] # word.capitalize() is a hw, like 'leo'\n",
    "    \n",
    "    wordDeriv = [] # raw derivatives or capitalized derivatives or derivative.lower()\n",
    "    fineDeriv = [] # fine derivateivs are in mwBen\n",
    "    hwofDeriv = [] # hws of derivatives\n",
    "    \n",
    "    wordInfl = [] # raw inflections or capitalized inflections or inflection.lower()\n",
    "    fineInfl = [] # fine inflections are in mwBen\n",
    "    hwofInfl = [] # hws of inflections\n",
    "    \n",
    "    wordnotBen = [] # word is not in mwBen\n",
    "\n",
    "    for word in txtraw:\n",
    "        hwflag = 0 # suppose that word is not a hw\n",
    "        derivflag = 0 # suppose that word is not a derivative\n",
    "        inflflag = 0 # suppose that word is not a inflection\n",
    "        \n",
    "        # first check if word is a hw\n",
    "        if word in hws:\n",
    "            wordhw.append(word)\n",
    "            hwreturn.append(word)\n",
    "            hwflag = 1\n",
    "        elif word.capitalize() in hws: # like leo\n",
    "            wordhwC.append(word)\n",
    "            hwreturn.append(word.capitalize())\n",
    "            hwflag = 1            \n",
    "        elif word.capitalize() in hwsC: # like Walk, tAke\n",
    "            wordhwL.append(word)\n",
    "            hwreturn.append(word.lower())\n",
    "            hwflag = 1\n",
    "\n",
    "        # if word isn't a hw, then check if it's a derivative\n",
    "        if hwflag == 0:\n",
    "            dercnt = 0\n",
    "            for mwben in mwBenDerivs:                \n",
    "                if word == mwben['deriv'] or word == mwben['deriv'].capitalize() or word.capitalize() == mwben['deriv']:\n",
    "                    wordDeriv.append(word)\n",
    "                    fineDeriv.append(mwben['deriv'])\n",
    "                    hwofDeriv.append(mwben['hw'])\n",
    "                    derivflag = 1\n",
    "                    print '---derivative: ', word, '--- hw: ', mwben['hw']\n",
    "                    dercnt += 1\n",
    "            if dercnt > 1: print word, '--- derivate has multiple hws --- ', dercnt\n",
    "\n",
    "        if hwflag == 0 and derivflag == 0:\n",
    "            inflcnt = 0\n",
    "            for mwben in mwBenInfls:                \n",
    "                if word == mwben['infl'] or word == mwben['infl'].capitalize() or word.capitalize() == mwben['infl']:\n",
    "                    wordInfl.append(word)\n",
    "                    fineInfl.append(mwben['infl'])\n",
    "                    hwofInfl.append(mwben['hw'])\n",
    "                    inflflag = 1\n",
    "                    print 'inflection: ', word, '--- hw: ', mwben['hw']\n",
    "                    inflcnt += 1\n",
    "            if inflcnt > 1: print word, '--- inflection has multiple hws --- ', inflcnt                \n",
    "                \n",
    "                \n",
    "        if hwflag == 0 and derivflag == 0 and inflflag == 0:\n",
    "            if word.find(' ') == -1:\n",
    "                wordnotBen.append(word)\n",
    "                print '**************^^^^^^^!!@@@@@*************** is not in mwBen: ', word\n",
    "            else:\n",
    "                print '>>> >>> >>> >>> >> not a single word: ', word\n",
    "                for x in word.split(' '):\n",
    "                    if x in hws: hwreturn.append(x)\n",
    "                    elif x.capitalize() in hws: hwreturn.append(x.capitalize())\n",
    "                    elif x in hwsC: hwreturn.append(x.lower())\n",
    "                    else:\n",
    "                        wdflagx = 0 \n",
    "                        for mwben in mwBenDerivs:                \n",
    "                            if x == mwben['deriv'] or x == mwben['deriv'].capitalize() \\\n",
    "                            or x.capitalize() == mwben['deriv']:\n",
    "                                wordDeriv.append(word)\n",
    "                                fineDeriv.append(mwben['deriv'])\n",
    "                                hwofDeriv.append(mwben['hw'])\n",
    "                                wdflagx = 1\n",
    "                        if wdflagx == 0:\n",
    "                            for mwben in mwBenInfls:                \n",
    "                                if x == mwben['infl'] or x == mwben['infl'].capitalize() \\\n",
    "                                or x.capitalize() == mwben['infl']:\n",
    "                                    wordInfl.append(word)\n",
    "                                    fineInfl.append(mwben['infl'])\n",
    "                                    hwofInfl.append(mwben['hw'])\n",
    "                                    wdflagx = 1\n",
    "                        if wdflagx == 0:\n",
    "                            wordnotBen.append(x)\n",
    "                            print '**************^^^^^^^!!@@@@@*************** really is not in mwBen: ', x\n",
    "                                \n",
    "                            \n",
    "            \n",
    "    \n",
    "    if wordhw: print '* same as hw: ', len(wordhw)  #,' -- ', wordhw\n",
    "    if wordhwL: print '* capitalized hw: ', len(wordhwL)  #,' -- ', wordhwL\n",
    "    if wordhwC: print '* hw typo, should be capitalized: ', len(wordhwC)  #,' -- ', wordhwC\n",
    "    \n",
    "    if wordDeriv: print '* words are derivatives: ', len(wordDeriv) #,' -- ', wordDeriv\n",
    "    if wordInfl: print '* words are inflections: ', len(wordInfl) #,' -- ', wordInfl\n",
    "\n",
    "    if wordnotBen:\n",
    "        print '\\n**************##########***************** All not in mwBen: ', len(wordnotBen), '\\n', wordnotBen\n",
    "        \n",
    "#     if len(txtraw) == len(wordhw) + len(wordhwL) + len(wordhwC) + len(wordDeriv) + len(wordnotBen):         \n",
    "#     else: print \"--- words' numbers don't mattch, check ---\\n\"\n",
    "\n",
    "        \n",
    "    rntdic = {}    \n",
    "    rntdic['tunehw'] = sorted(set(hwreturn))\n",
    "    rntdic['hwofDeriv'] = sorted(set(hwofDeriv))\n",
    "    rntdic['tuneDeriv'] = sorted(set(fineDeriv))\n",
    "    rntdic['hwofInfl'] = sorted(set(hwofInfl))\n",
    "    rntdic['tuneInfl'] = sorted(set(fineInfl))\n",
    "    rntdic['rawhwderiv'] = sorted(set(wordhw + wordhwL + wordhwC + wordDeriv + wordInfl))\n",
    "    rntdic['notinben'] = sorted(set(wordnotBen))\n",
    "    \n",
    "    return rntdic\n",
    "    \n",
    "\n",
    "\n",
    "def tuneReport(wlist=[], path='', wfile=''):\n",
    "    if wlist: fname = 'tuneReport-list.txt'\n",
    "    elif wfile: fname = 'tuneReport-' + wfile\n",
    "    else:\n",
    "        print 'arguments error'\n",
    "        return -1\n",
    "    \n",
    "    rnt = tuneBymwBen(wlist, path, wfile)\n",
    "    \n",
    "    tunehw = rnt['tunehw']\n",
    "    hwofDeriv = rnt['hwofDeriv']\n",
    "    tuneDeriv = rnt['tuneDeriv'] \n",
    "    hwofInfl = rnt['hwofInfl']\n",
    "    tuneInfl = rnt['tuneInfl']\n",
    "    notinben = rnt['notinben']    \n",
    "    #rawhwderiv = rnt['rawhwderiv']\n",
    "    \n",
    "    fd = codecs.open('E:\\\\1Now\\\\mae\\\\report\\\\' + fname, 'w', 'utf-8')\n",
    "    if notinben:\n",
    "        fd.write('---not in mwBen---:' + str(len(notinben)) + '\\n')\n",
    "        for x in notinben: fd.write(x + '\\n')\n",
    "    if tunehw:\n",
    "        fd.write('\\n\\n--- tuned hws of raw hws which are in mwBen---: ' + str(len(tunehw)) + '\\n')\n",
    "        for x in tunehw: fd.write(x + '\\n')\n",
    "    if hwofDeriv:\n",
    "        fd.write('\\n\\n--- tuned hws of raw derivatives which are in mwBen---: ' + str(len(hwofDeriv)) + '\\n')\n",
    "        for x in hwofDeriv: fd.write(x + '\\n')\n",
    "    if tuneDeriv:\n",
    "        fd.write('\\n\\n--- all tuned derivatives which are in mwBen---: ' + str(len(tuneDeriv)) + '\\n')\n",
    "        for x in tuneDeriv: fd.write(x + '\\n') \n",
    "    if hwofInfl:\n",
    "        fd.write('\\n\\n--- tuned hws of raw inflections which are in mwBen---: ' + str(len(hwofInfl)) + '\\n')\n",
    "        for x in hwofInfl: fd.write(x + '\\n')\n",
    "    if tuneInfl:\n",
    "        fd.write('\\n\\n--- all tuned inflections which are in mwBen---: ' + str(len(tuneInfl)) + '\\n')\n",
    "        for x in tuneInfl: fd.write(x + '\\n')             \n",
    "\n",
    "    fd.close()\n",
    "    return rnt\n",
    "       \n",
    "\n",
    "def txt2wl(path='', wfile=''):\n",
    "    '''extract a word list from a text, return a sorted unqiue raw word list'''\n",
    "    if wfile:\n",
    "        with codecs.open(path + wfile, 'r', 'utf-8') as f:\n",
    "            parags = f.read().splitlines() # each paragraph as one line\n",
    "    else:\n",
    "        print 'argument error'\n",
    "        return -1\n",
    "    \n",
    "    wlraw = [] # raw word list from the text\n",
    "    for parag in parags:\n",
    "        regxp = re.compile(r'[^\\w\\'\\-]+', re.U) # regular expression pattern: ^\\w\\'\\- means not words ' -\n",
    "        parag = regxp.sub(' ', parag) # replace all not words ' - with a space\n",
    "        wlraw += parag.split(' ')\n",
    "    \n",
    "    return sorted(set(wlraw))\n",
    "\n",
    "\n",
    "\n",
    "def hw4learn(wdict={}, wlist=[], path='', wfile='', excluf='E:\\\\1Now\\\\taglist\\\\2939exclu.txt'):\n",
    "    '''This function only excludes hws and their derivatives exactly in mwl.\n",
    "    So it's better to use tuneBymwBen() first to get a fine word list'''\n",
    "    \n",
    "    dictflag = 0 # no dictionary input\n",
    "    \n",
    "    if wdict:\n",
    "        dictflag = 1\n",
    "        words = wdict['tunehw'] + wdict['hwofDeriv'] + wdict['hwofInfl']\n",
    "        sounds = wdict['tunehw'] + wdict['hwofInfl'] + wdict['tuneDeriv']\n",
    "    elif wlist:\n",
    "        words = [x.strip() for x in wlist]\n",
    "    elif wfile:\n",
    "        with codecs.open(path + wfile, 'r', 'utf-8') as f:\n",
    "            words = f.read().splitlines()\n",
    "        words = [x.strip() for x in words]    \n",
    "    else:\n",
    "        print 'argument error'\n",
    "        return -1\n",
    "    \n",
    "    \n",
    "    word4learn = []    \n",
    "    if excluf:\n",
    "        #print '--- will exclude words from', excluf\n",
    "        with codecs.open(excluf, 'r', 'utf-8') as f:\n",
    "            bexclus = f.read().splitlines()\n",
    "    \n",
    "        for word in words:\n",
    "            if word not in bexclus: word4learn.append(word)\n",
    "    else:\n",
    "        word4learn = words\n",
    "            \n",
    "    word4learn = sorted(set(word4learn))\n",
    "    \n",
    "    # generate Anki search string for filtered deck    \n",
    "    ankiSearchStr = 'deck:sPlay ('\n",
    "    for x in word4learn:\n",
    "        if x != word4learn[-1]: ankiSearchStr += ' hw:\"' + x + '\" or'\n",
    "        else: ankiSearchStr += ' hw:\"' + x + '\")'\n",
    "    print '\\n---words to learn---: ', len(word4learn)\n",
    "    print ankiSearchStr\n",
    "    \n",
    "    \n",
    "    if dictflag:\n",
    "        sound4learn = []\n",
    "        if excluf:\n",
    "            for x in sounds:\n",
    "                if x not in bexclus: sound4learn.append(x)\n",
    "        else:\n",
    "            sound4learn = sounds\n",
    "        sound4learn = sorted(set(sound4learn))\n",
    "    \n",
    "        ankiSearchStr = 'deck:soundPlay ('\n",
    "        for x in sound4learn:\n",
    "            if x != sound4learn[-1]: ankiSearchStr += ' hw:\"' + x + '\" or'\n",
    "            else: ankiSearchStr += ' hw:\"' + x + '\")'\n",
    "        print '\\n---sounds to learn---: ', len(sound4learn)\n",
    "        print ankiSearchStr    \n",
    "        \n",
    "        return sound4learn\n",
    "        \n",
    "#     return word4learn\n",
    "\n",
    "\n",
    "def compareWordlist(l1=[], l2=[], path='', f1='', f2=''):\n",
    "    '''get common and different parts of two lists or word lists of two files'''\n",
    "    \n",
    "    if l1:\n",
    "        words1 = l1\n",
    "#         words1 = [x.strip() for x in l1]\n",
    "        f1name = 'list-1'\n",
    "    if l2:\n",
    "        words2 = l2\n",
    "#         words2 = [x.strip() for x in l2]\n",
    "        f2name = 'list-2'\n",
    "    if f1:\n",
    "        with codecs.open(path+f1, 'r', 'utf-8') as f:\n",
    "            words1 = f.read().splitlines()\n",
    "#         words1 = [x.strip() for x in words1]\n",
    "        f1name = f1\n",
    "    if f2:\n",
    "        with codecs.open(path+f2, 'r', 'utf-8') as f:\n",
    "            words2 = f.read().splitlines()\n",
    "#         words2 = [x.strip() for x in words2]\n",
    "        f2name = f2\n",
    "            \n",
    "    comm = [x for x in words1 if x in words2]\n",
    "    only1 = [x for x in words1 if x not in words2]\n",
    "    only2 = [x for x in words2 if x not in words1]\n",
    "    \n",
    "    comm = sorted(set(comm))\n",
    "    \n",
    "    f = codecs.open('E:\\\\1Now\\\\taglist\\\\report\\\\compare_' + f1name + '_' + f2name + '.txt', 'w', 'utf-8')\n",
    "    \n",
    "    print '---common words of ' + f1name + ' and ' + f2name + '---: ' + str(len(comm))\n",
    "    f.write('---common words of ' + f1name + ' and ' + f2name + '---: ' + str(len(comm)) + '\\n')\n",
    "    for x in comm:\n",
    "        f.write(x + '\\n')\n",
    "    \n",
    "    print '---words only in ' + f1name + '---: ' + str(len(only1))\n",
    "    f.write('\\n\\n---words only in ' + f1name + '---: ' + str(len(only1)) + '\\n')\n",
    "    for x in only1:\n",
    "        f.write(x + '\\n')    \n",
    "    \n",
    "    print '---words only in ' + f2name + '---: ' + str(len(only2))\n",
    "    f.write('\\n\\n---words only in ' + f2name + '---: ' + str(len(only2)) + '\\n')\n",
    "    for x in only2:\n",
    "        f.write(x + '\\n')\n",
    "        \n",
    "    f.close()\n",
    "\n",
    "    \n",
    "print '--- load 5 functions ---'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique words :  134\n",
      "134\n",
      "number of notes in Anki:  134\n"
     ]
    }
   ],
   "source": [
    "# check number of words and notes in a filtered deck\n",
    "# first export the filted deck in Anki\n",
    "\n",
    "import codecs\n",
    "with codecs.open('E:\\\\1Now\\\\mae\\\\article\\\\filter_46sounds1.txt', 'r', 'utf-8') as f:\n",
    "    lines = f.read().splitlines()\n",
    "words = [x.split('\\t')[0] for x in lines]\n",
    "words = sorted(words)\n",
    "print 'number of unique words : ', len(set(words))\n",
    "\n",
    "b = {}\n",
    "for x in words:     \n",
    "    b[x] = words.count(x)\n",
    "#     print x, b[x]\n",
    "print len(b)\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "for x in b:\n",
    "    #print x, b[x]\n",
    "    cnt += b[x]\n",
    "print 'number of notes in Anki: ', cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of excluded hw:  2939\n",
      "total head words:  5011\n",
      "total words:  31600\n",
      "unique words: 9833\n"
     ]
    }
   ],
   "source": [
    "# Organize 'beautifulExcluHw.txt' and generate 'beautifulExclu.txt'\n",
    "# (note: words in beautifulExcluHw.txt are absolutely hws in 39195 of mwl)\n",
    "# directly from mwaled mongodb dpdict. words not being a hw in mwaled won't be added to the two lists\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# codecs if for read and write files with unicode, encoding 'utf-8'\n",
    "import codecs\n",
    "\n",
    "#connect to MongoDB\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client.dpdb  # databas: dpdb\n",
    "geweiDict = db.geweiDict201511 # collection (table): geweiDict201511\n",
    "#geweiDict = db.geweiDictTest\n",
    "\n",
    "\n",
    "with codecs.open(\"E:\\\\1Now\\\\taglist\\\\2939bw.txt\", 'r', 'utf-8') as f:\n",
    "    behws = f.read().splitlines()\n",
    "    f.close()    \n",
    "# sort and make unique words in beautifulExcluHw.txt\n",
    "behws = sorted(set(behws))\n",
    "print 'number of excluded hw: ', len(behws)\n",
    "\n",
    "# fd = codecs.open(\"E:\\\\1Now\\\\mae\\\\beautifulExcluHw.txt\", 'w', 'utf-8')\n",
    "# for behw in behws:\n",
    "#     fd.write(behw + '\\n')\n",
    "# fd.close()\n",
    "    \n",
    "fdict = codecs.open('E:\\\\1Now\\\\mae\\\\beautifulExcluraw.txt', 'w', 'utf-8')\n",
    "    \n",
    "results = geweiDict.find({}, {\"_id\":0, \"hw\":1, \"infl\":1, \"subhw\":1}) #.limit(1000)\n",
    "\n",
    "# total number of head words\n",
    "totalhw = 0\n",
    "totalcnt = 0\n",
    "\n",
    "for result in results:    \n",
    "    word = result.get(\"hw\")    \n",
    "\n",
    "    if word and word in behws:\n",
    "        #print word\n",
    "#         fdict.write(word + ';' + word + '\\n')\n",
    "        fdict.write(word + '\\n')\n",
    "        totalhw += 1\n",
    "    else:\n",
    "#         print \"no head word\"\n",
    "        continue\n",
    "\n",
    "    # get items of result\n",
    "    infls = result.get(\"infl\")\n",
    "    subhws = result.get(\"subhw\")     \n",
    "    \n",
    "    if infls:\n",
    "        for infl in infls:\n",
    "#             fdict.write(infl + ';' + word + '\\n')\n",
    "            fdict.write(infl + '\\n')\n",
    "            totalcnt += 1   \n",
    "            \n",
    "    if subhws:\n",
    "        for subhw in subhws:\n",
    "            if subhw[0] != word[0]: continue # check if subhw is a real sub hw of word by comparing first letter\n",
    "#             fdict.write(subhw + ';' + word  + '\\n')\n",
    "            fdict.write(subhw + '\\n')\n",
    "            totalcnt += 1        \n",
    "    \n",
    "fdict.close()\n",
    "print \"total head words: \", totalhw\n",
    "print \"total words: \", totalcnt + totalhw\n",
    "\n",
    "\n",
    "# sort out by head words and make them unique\n",
    "with codecs.open('E:\\\\1Now\\\\mae\\\\beautifulExcluraw.txt', 'r', 'utf-8') as f:\n",
    "    lines = f.read().splitlines()\n",
    "lines = sorted(set(lines))\n",
    "print 'unique words:', len(lines)\n",
    "#lines = sorted(lines)\n",
    "\n",
    "fd = codecs.open('E:\\\\1Now\\\\mae\\\\beautifulExclu.txt', 'w', 'utf-8')\n",
    "for line in lines:\n",
    "    fd.write(line + '\\n')\n",
    "fd.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- mwBen statistics ---\n",
      "total head words:  39195\n",
      "total inflections:  64355\n",
      "total subhws:  8493\n",
      "total subhws whose 1st letters are different from hws:  158\n",
      "hw without any derivatives:  11221\n",
      "\n",
      "\n",
      "number of lines in mwBen before adding 84en_fr.txt:  84069\n",
      "number of unique lines in mwBen before adding 84en_fr.txt:  53853\n",
      "number of lines in 84en_fr.txt:  84\n",
      "number of unique lines in 84en_fr.txt:  83\n",
      "---common words of list-1 and list-2---: 15\n",
      "---words only in list-1---: 68\n",
      "---words only in list-2---: 53838\n",
      "number of lines in mwBen after adding 84en_fr.txt:  53921\n"
     ]
    }
   ],
   "source": [
    "# output mwlBenchmark.txt (mwBen) (no duplicate lines)\n",
    "# 2015-11-28, 2015-11-30, 2015-12-01, 2015-12-08\n",
    "\n",
    "# sort and make every line unique\n",
    "# format: n;hw, derivative, or inflection;hw\n",
    "# 1 - head word; 2 - derivative; 3 - inflection\n",
    "\n",
    "# 1;truly;truly\n",
    "# 2;blazingly;blazing\n",
    "# 3;blazes;blaze\n",
    "# 3;blazing;blaze\n",
    "\n",
    "# By the lines above, I can know blaze and blazing are hws, the two lines below are not allowd \n",
    "# because hws have derivates or inflections:\n",
    "# blaze;blaze\n",
    "# blazing;blazing\n",
    "# the two lines above are redundant.\n",
    "\n",
    "# manually delete: asas\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# codecs if for read and write files with unicode, encoding 'utf-8'\n",
    "import codecs\n",
    "\n",
    "#connect to MongoDB\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client.dpdb  # databas: dpdb\n",
    "geweiDict = db.geweiDict201511 # collection (table): geweiDict201511\n",
    "#geweiDict = db.geweiDictTest\n",
    "\n",
    "fdict = codecs.open('E:\\\\1Now\\\\taglist\\\\mwlBenchmarkraw.txt', 'w', 'utf-8')\n",
    "    \n",
    "results = geweiDict.find({}, {\"_id\":0, \"hw\":1, \"infl\":1, \"subhw\":1}) #.limit(1000)\n",
    "# sort method will use much more memory\n",
    "#results = geweiDict.find({}, {\"_id\":0, \"hw\":1, \"prn\":1, \"alles\":1, \"idpvs\":1, \"sublist\":1}).sort(\"hw\", 1).limit(1000)\n",
    "\n",
    "\n",
    "hwcnt = 0 # number of head words (hws)\n",
    "# hwcapcnt = 0 # number of hws capitalized\n",
    "inflcnt = 0 # number of inflections\n",
    "subhwcnt = 0 # number of subhws\n",
    "subhw1cnt = 0 # number of subhws whose first letter is not same as hw\n",
    "onlyhwcnt = 0\n",
    "\n",
    "# subhw1hw = []\n",
    "\n",
    "for result in results:\n",
    "    inflflag = 0\n",
    "    subhwflag = 0\n",
    "    \n",
    "    word = result.get(\"hw\")    \n",
    "    if word:\n",
    "        #print word\n",
    "#         fdict.write(word + ';' + word + '\\n')\n",
    "        hwcnt += 1      \n",
    "    else:\n",
    "        print \"no head word\"\n",
    "        continue\n",
    "\n",
    "    # get items of result\n",
    "    subhws = result.get(\"subhw\")\n",
    "    infls = result.get(\"infl\")         \n",
    "    \n",
    "    if subhws:\n",
    "        for subhw in subhws:\n",
    "            #if subhw[0] != word[0]: continue       \n",
    "            if subhw.lower() == word.lower():\n",
    "                #print 'subhw == word', subhw\n",
    "                continue           \n",
    "            if infls:\n",
    "                if subhw in infls:\n",
    "                    #print '----subhw in infls:', subhw\n",
    "                    continue\n",
    "                    \n",
    "            if subhw[0] != word[0]:\n",
    "                #print 'subhw is not like word: ', subhw, '...', word\n",
    "                subhw1cnt += 1\n",
    "                #subhw1hw.append(subhw+';'+word)\n",
    "            fdict.write('2;' + subhw + ';' + word + '\\n')\n",
    "            subhwcnt += 1      \n",
    "            subhwflag = 1    \n",
    "    \n",
    "    \n",
    "    if infls:\n",
    "        for infl in infls:\n",
    "            if infl.lower() == word.lower():\n",
    "                #print 'infl == word', infl\n",
    "                continue\n",
    "            fdict.write('3;' + infl + ';' + word + '\\n')\n",
    "            inflcnt += 1   \n",
    "            inflflag = 1\n",
    "            \n",
    "            \n",
    "    # hw;hw (only when hw has no inflections and no subhws)\n",
    "    if inflflag == 0 and subhwflag == 0:\n",
    "        fdict.write('1;' + word + ';' + word + '\\n')\n",
    "        onlyhwcnt += 1\n",
    "    \n",
    "fdict.close()\n",
    "\n",
    "print '--- mwBen statistics ---'\n",
    "print \"total head words: \", hwcnt\n",
    "# print 'total hws capitalized: ', hwcapcnt\n",
    "print \"total inflections: \", inflcnt\n",
    "print 'total subhws: ', subhwcnt\n",
    "print 'total subhws whose 1st letters are different from hws: ', subhw1cnt\n",
    "print 'hw without any derivatives: ', onlyhwcnt\n",
    "\n",
    "\n",
    "with codecs.open('E:\\\\1Now\\\\taglist\\\\mwlBenchmarkraw.txt', 'r', 'utf-8') as f:\n",
    "    mwls = f.read().splitlines()\n",
    "print '\\n\\nnumber of lines in mwBen before adding 84en_fr.txt: ', len(mwls)\n",
    "mwls = sorted(set(mwls))\n",
    "print 'number of unique lines in mwBen before adding 84en_fr.txt: ', len(mwls)\n",
    "\n",
    "# read en_fr.txt\n",
    "with codecs.open('E:\\\\1Now\\\\taglist\\\\84en_fr.txt', 'r', 'utf-8') as f:\n",
    "    enfrs = f.read().splitlines()\n",
    "print 'number of lines in 84en_fr.txt: ', len(enfrs)\n",
    "enfrs = sorted(set(enfrs))\n",
    "print 'number of unique lines in 84en_fr.txt: ', len(set(enfrs))\n",
    "\n",
    "compareWordlist(l1=enfrs, l2=mwls)\n",
    "\n",
    "# sort and make unique\n",
    "lines = sorted(set(mwls + enfrs))\n",
    "print 'number of lines in mwBen after adding 84en_fr.txt: ', len(lines)\n",
    "\n",
    "fd = codecs.open('E:\\\\1Now\\\\taglist\\\\mwlBenchmark.txt', 'w', 'utf-8')\n",
    "for line in lines:\n",
    "    fd.write(line + '\\n')\n",
    "fd.close()\n",
    "\n",
    "\n",
    "# subhw1hw = sorted(set(subhw1hw))\n",
    "# fd = codecs.open('E:\\\\1Now\\\\taglist\\\\subhw1hw.txt', 'w', 'utf-8')\n",
    "# for x in subhw1hw:\n",
    "#     fd.write(x + '\\n')\n",
    "# fd.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- explore mwBen ---\n",
      "number of derivative column:  53972\n",
      "number of hw column:  53972\n",
      "unique number of hw column:  34398\n",
      "number of derivatives (inflections and subhws) whose 1st letter different from hws:  337\n",
      "number of capitalized hws:  1487\n"
     ]
    }
   ],
   "source": [
    "# explore mwBen\n",
    "\n",
    "import codecs\n",
    "import string\n",
    "\n",
    "with codecs.open('E:\\\\1Now\\\\taglist\\\\mwlBenchmark.txt', 'r', 'utf-8') as f:\n",
    "    lines = f.read().splitlines()\n",
    "\n",
    "deriv = [] # derivative\n",
    "benhw = [] # hw\n",
    "deriv1hw = [] # derivative (inflection, subhw) first letter different from its hw\n",
    "hwcap = [] # hw whose first letter is capitalized\n",
    "for line in lines:\n",
    "    x1 = line.split(';')[0]\n",
    "    x2 = line.split(';')[1]\n",
    "    deriv.append(x1)\n",
    "    benhw.append(x2)\n",
    "    if x1[0] != x2[0]: deriv1hw.append(line)\n",
    "    if x2[0] in string.uppercase[0:26]: hwcap.append(x2)\n",
    "derivS = sorted(deriv)\n",
    "benhwSU = sorted(set(benhw)) # Sorted, Unique\n",
    "hwcap = sorted(set(hwcap))\n",
    "\n",
    "print '--- explore mwBen ---'\n",
    "print 'number of derivative column: ', len(deriv)\n",
    "print 'number of hw column: ', len(benhw)\n",
    "print 'unique number of hw column: ', len(benhwSU)\n",
    "print 'number of derivatives (inflections and subhws) whose 1st letter different from hws: ', len(deriv1hw)\n",
    "print 'number of capitalized hws: ', len(hwcap)\n",
    "\n",
    "fout = codecs.open('E:\\\\1Now\\\\taglist\\\\mwlStat.txt', 'w', 'utf-8')\n",
    "fout.write('--- statistics ---\\n')\n",
    "fout.write('number of lines in mwBen: ' + str(len(deriv)) + '\\n')\n",
    "fout.write('unique number of hw: ' + str(len(benhwSU)) + '\\n')\n",
    "fout.write('number of derivatives (inflections and subhws) whose 1st letter different from hws: ' + str(len(deriv1hw)) + '\\n')\n",
    "fout.write('number of capitalized hws: ' + str(len(hwcap)) + '\\n')\n",
    "\n",
    "fout.write('Contents\\n--------\\n')\n",
    "fout.write(\"Q: Are there duplicate derivatives who aren't hws in mwBen?\\n\")\n",
    "fout.write(\"Q: List derivatives (inflections and subhws) whose first letter is different from the first letter of their hws\\n\")\n",
    "fout.write(\"Capitalized hws\\n\\n\")\n",
    "\n",
    "# Q: Are there duplicate derivatives who aren't hws in mwBen?\n",
    "dupderiv = [x for x in derivS if x not in benhwSU and derivS.count(x)>1]\n",
    "fout.write(\"--- Duplicate derivatives not being hws: ---\\n\")\n",
    "for x in dupderiv:\n",
    "    fout.write(x + '\\n')\n",
    "\n",
    "# Q: List subhws whose first letter is different from the first letter of their hws\n",
    "fout.write(\"\\n--- derivatives (inflections and subhws) whose 1st letter different from hws: ---\\n\")\n",
    "fout.write(\"derivatives (inflections and subhws);hw\\n\\n\")\n",
    "for x in subhw1hw:\n",
    "    fout.write(x + '\\n')\n",
    "\n",
    "fout.write(\"\\n--- Capitalized hws: ---\\n\")\n",
    "for x in hwcap:\n",
    "    fout.write(x + '\\n')\n",
    "           \n",
    "fout.close()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
